
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="F:\v_awjliu\BKDocs\ZH/default.css" rel="stylesheet">
    </head>
    <body>
    <h1 id="_1">产品简介</h1>
<p>监控平台是蓝鲸智云官方推出的一款监控平台产品，除了具有丰富的数据采集能力，大规模的数据处理能力，简单易用，还提供更多的平台扩展能力。依托于蓝鲸 PaaS，有别于传统的 CS 结构，在整个蓝鲸生态中可以形成监控的闭环能力。</p>
<p>致力于满足不同的监控场景需求和能力，提高监控的及时性、准确性、智能化，为在线业务保驾护航。</p><h2 id="_1">核心优势</h2>
<p><img alt="Advantage" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/media/Advantage.png" /></p>
<ol>
<li><strong>生态闭环：</strong> 依托蓝鲸 PaaS 深度整合了 CMDB，故障自愈，日志平台，作业平台，节点管理，数据平台，工单等能力。随着生态的完善监控的智能化将更加强大</li>
<li><strong>开箱即用：</strong> 默认的主机，进程采集展示，系统事件，策略配置，可以满足基本的开箱即用</li>
<li><strong>支持采集管理：</strong> 可以满足采集器的在线调试、安装和日常维护，避免了日常的采集器同步困扰</li>
<li><strong>告警能力：</strong> 灵活的策略配置满足单机，单实例，集群，多维度等告警需求；内置了 8 种检测算法；多种告警收敛等防止告警风暴等</li>
<li><strong>采集扩展：</strong> 支持通过 HTTP、SDK 自定义上报时序和事件数据，支持远程采集，解决不能部署监控 Agent 的需求</li>
<li><strong>支持 Exporter、等开源插件：</strong> 支持 Prometheus 的 Exporter 数据采集格式，可以简单的将 Exporter 迁移至监控平台的插件</li>
</ol><h1 id="_1">术语解释</h1>
<p>本文档主要是各种功能及名词的解释，方便查看和索引。另外是为了统一名词叫法，避免理解上的偏差。</p>
<h2 id="_2">监控核心概念</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15799998161447.jpg" /></p>
<h3 id="metric">指标 Metric</h3>
<ul>
<li><strong>指标：</strong> 行业里一般称为 Metric(s)、Item 或度量，即监控的内容，一般是坐标系中的纵坐标，比如 CPU 使用率、在线人数等，在 SQL 语句中一般是 <code>select 指标</code></li>
</ul>
<h3 id="dimension">维度 Dimension</h3>
<ul>
<li>
<p><strong>维度：</strong> 行业里一般称为 Dimension，区分指标的条件，比如 IP、主机名或平台(IOS、Andriod)，在 SQL 语句中一般是 <code>Group by 维度</code></p>
</li>
<li>
<p>示例：在仪表盘配置出图前设置</p>
</li>
</ul>
<p><img alt="2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/16003086275528.jpg" /></p>
<ul>
<li>配置后的视图展示(Panel)</li>
</ul>
<p><img alt="2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/16003085498859.jpg" /></p>
<h3 id="_3">监控/采集目标</h3>
<ul>
<li><strong>监控/采集目标：</strong> 采集或监控目标都是管理的目标范围，如集群，模块，IP 等。 等同于一个内置的维度范围<ul>
<li><strong>动态：</strong> 只能选择 CMDB 中的节点，采集目标按节点动态增删采集任务，监控目标按节点进行数据汇总和判断</li>
<li><strong>静态：</strong> 只能选择/手动输入主机 IP，目标不会变更，依赖人手工增删</li>
</ul>
</li>
<li><strong>采集器 IP 地址：</strong> 采集器/插件运行的位置</li>
<li><strong>云区域：</strong> 默认为 0，直连区域;当有多个云区域的时候蓝鲸会将多个云区域的数据和操作统一管理</li>
</ul>
<h3 id="_4">监控对象</h3>
<ul>
<li><strong>监控对象：</strong> 监控对象是贯穿整个监控平台和日志检索数据分层/分类，让管理的数据和采集的数据具有可识别性<ul>
<li><strong>应用</strong>： 指的是用户使用应用的情况，应用的运营数据。 如 移动端的使用情况， 业务应用的登陆数等</li>
<li><strong>服务</strong>： 指的是运行在服务器操作系统之上的服务模块。管理的最小粒度为服务实例， 如 数据库， 进程等。 对应 CMDB-服务拓扑</li>
<li><strong>主机</strong>： 指的主机系统和硬件的层面。 管理的最小粒度为主机 IP，如 CPU MEM 服务器硬件故障等。 对应 CMDB-主机拓扑</li>
<li><strong>数据中心</strong>： 指的是和数据中心相关的网络和设备相关内容。 对应 CMDB-设备管理</li>
<li>更多查看<a href="./datamodule.md">数据模型</a></li>
</ul>
</li>
</ul>
<h3 id="_5">告警级别</h3>
<p>告警分为三个级别</p>
<ul>
<li><strong>致命</strong>： Emergency 最严重，核心指标出现严重问题，将影响业务的稳定性，需要重点关注，红色</li>
<li><strong>预警</strong>： Critical 一般严重，需要关注，可能会导致更加严重的问题，橙色</li>
<li><strong>提醒</strong>： Warning 提示作用，需要了解，出现了问题的苗头，黄色</li>
</ul>
<h3 id="_6">采集方式</h3>
<ul>
<li><strong>采集器</strong>： 监控内置的采集器，像 Basereport 采集操作系统的指标，bkmonitorbeat 管理采集插件</li>
<li><strong>采集插件</strong>： 用户自定义的采集插件，可以基于标准要求进行无限扩展</li>
<li><strong>两者区间</strong>：<ul>
<li>采集器一般是默认自带的，部署并启动后不会销毁，并且支持一个进程多配置文件的管理方式，并且可以管理采集插件</li>
<li>采集插件： 主要是用户自定义，虽然也有内置的但也是由用户决定是否需要或者进行升级。 可以是进程，配置或者是脚本程序，都有一个共同特点，不用则会在原目标机器删除，进程类一个进程只支持一个配置文件</li>
</ul>
</li>
</ul>
<h3 id="_7">告警处理</h3>
<ul>
<li><strong>异常点</strong>： 时序数据通过算法检测判断有异常的点</li>
<li><strong>告警事件</strong>： 多个异常点为同一类为事件，一般具有持续性</li>
<li><strong>告警通知</strong>： 多个告警事件通过收敛规则，风暴抑制等手段汇总成告警通知</li>
</ul>
<h2 id="cmdb">CMDB 相关概念</h2>
<p>监控的元数据信息很多是依赖 CMDB，所以 CMDB 的一些概念需要明白，甚至要清楚相关的配置。</p>
<h3 id="_8">业务</h3>
<p>业务是监控平台工作的命名空间。</p>
<h3 id="_9">服务模块</h3>
<h3 id="instance">服务实例 instance</h3>
<ul>
<li><strong>服务实例：</strong> 服务模块的最小粒度，选择<code>服务</code>监控对象时最小粒度即为服务实例，而非 IP。 更多查看<a href="./README.md">设计理念</a></li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15744838270079.jpg" /></p>
<h3 id="_10">服务分类</h3>
<ul>
<li><strong>服务分类：</strong> 服务模块的类别 如： <code>数据库：Mysql</code> ， 监控可以基于服务分类进行管理，如配置的查看，导出导入，专业视图等</li>
</ul><h1 id="_1">产品架构</h1>
<p>监控平台致力于实现一站式监控平台，目标要做到<strong>快</strong>、<strong>稳</strong>、<strong>准</strong>、<strong>全</strong>。</p>
<ul>
<li>
<p><strong>快</strong>： 数据上报快、数据处理快、问题定位快、故障处理快</p>
</li>
<li>
<p><strong>准</strong>： 问题定位准确、信息准确、智能决策</p>
</li>
<li>
<p><strong>稳</strong>： 告警及时、不漏告、不多告、海量数据处理能力</p>
</li>
<li>
<p><strong>全</strong>： 数据全、管理齐、生态闭环</p>
</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15743941673730.jpg" /></p>
<h2 id="_2">架构图</h2>
<p>要了解监控平台主要掌握三条主线：</p>
<ul>
<li>
<p><strong>第一条：数据处理主线</strong></p>
<ul>
<li>从<code>监控对象</code>通过多样的<code>数据采集</code>，不管是何种<code>数据来源</code>都将进入监控平台的<code>数据链路/存储</code>，对数据进行<code>异常检测</code>和<code>分析定位</code>，确定要如何进行<code>告警通知</code>，对于产生的告警有完整的<code>告警跟踪</code>和<code>生态闭环</code>，并且将最后的数据反馈给监控做为判断的依据</li>
</ul>
</li>
<li>
<p><strong>第二条：数据可视化</strong></p>
<ul>
<li>日常工作中通过 <code>pc/移动端</code>来使用各种<code>监控场景</code>来进行巡检，在发现问题的时候还可以通过各种<code>视图报表</code>来进行问题的综合定位，提供了各种数据可视化的工具</li>
</ul>
</li>
<li>
<p><strong>第三条：配置管理</strong></p>
<ul>
<li>便利的<code>采集管理</code>减少采集配置繁琐，配套齐全的<code>监控配置管理</code>和<code>平台系统管理</code>让管理工作更加的容易</li>
</ul>
</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15743917685087.jpg" /></p>
<h2 id="_3">监控平台能力</h2>
<p>从下至上依次介绍：</p>
<ul>
<li><strong>管控平台</strong>：蓝鲸 PaaS 的优势，可以满足不同的云区域的需求，满足文件、命令、数据的基本需求。并且整个监控平台也是建立在蓝鲸的 PaaS 平台之上</li>
<li><strong>依赖服务</strong>：是在蓝鲸工作的过程中需要依赖的蓝鲸 SaaS。分为强依赖缺一不可，增强型有配套功能会更加的强大</li>
<li><strong>监控服务层</strong>：监控的核心服务能力，每个服务都可以独立配置和复用，满足上层监控场景和需求的复杂需求。每块能力都是可以不断的补充</li>
<li><strong>监控场景</strong>：针对不同的监控场景有更加专业的场景来满足用户的问题定位。当前主要是主机监控和服务拨测</li>
<li><strong>用户层</strong>：用户可以直接接触到监控的一些途径</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15743891014248.jpg" /></p>
<h2 id="_4">产品演变</h2>
<p>当前监控平台产品还在不断的演变过程中， 当前重点在<code>蓝色</code>的部分监控最核心的能力和<code>绿色</code>部分生态的建设。</p>
<p>当前已经有<code>主机监控</code>和<code>服务拨测</code>两个场景，对于其他监控场景的扩展还在不断的完善中，在这个监控平台的能力之上完全可以通过合作的方式来完成。</p>
<p><code>灰色</code>的部分依据上层的需求场景不断的完善，并建立一套以<code>事件</code>为驱动的智能监控体系。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15744111248853.jpg" /></p><h1 id="_1">数据模型</h1>
<p>数据模型主要是介绍监控的数据上报格式、存储格式和监控管理运作的关系。</p>
<h3 id="_2">用户关心的数据分层</h3>
<p>不管是以什么方式进行数据的采集，上报；不论数据是从哪上报上来；不论是时序数据，事件数据还是日志数据都是为用户关心的数据分层而服务。</p>
<ol>
<li><strong>用户体验</strong>：指的是用户使用应用的情况，应用的运营数据。 如 移动端的使用情况，业务应用的登陆数等</li>
<li><strong>服务</strong>：指的是运行在服务器操作系统之上的服务模块。 如 数据库，进程等。 对应 CMDB-服务拓扑</li>
<li><strong>主机</strong>：指的主机系统和硬件的层面。 如 CPU MEM 服务器硬件故障等。 对应 CMDB-主机拓扑</li>
<li><strong>数据中心</strong>：指的是和数据中心相关的网络和设备相关内容。 对应 CMDB-设备管理</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/concepts/media/15743267097583.jpg" /></p>
<h3 id="_3">监控实现逻辑解耦</h3>
<p>明白用户关心的数据分层，所有的实现手段都进行了解耦，简而言之所有的以下所有的方式都是为数据分层而服务。</p>
<ul>
<li>
<p><strong>数据上报来源</strong>：3 种</p>
<ul>
<li><strong>监控采集</strong><ul>
<li>默认采集：操作系统 Basereport， 进程 Process 都是默认安装和下发的。系统事件也是默认采集的一种</li>
<li>采集配置：通过采集配置下发的采集任务，如脚本，Exporter，DataDog，JMX，日志采集等</li>
<li>拨测任务：拨测是一种特定的场景任务，其实也属于采集配置中的一类</li>
</ul>
</li>
<li><strong>自定义上报</strong>：无需监控平台进行下发和管理的采集来源，只要符合监控平台的数据格式即可，包含自定义事件上报和自定义时序数据</li>
<li><strong>数据平台</strong>：是已经接入数据平台的[结果表]数据进行监控</li>
</ul>
</li>
<li>
<p><strong>采集方式</strong>： 8 种</p>
<ul>
<li>Script 脚本插件采集：插件管理中维护，Linux 支持 Bash,Python; Windows 支持 Powershell、vbs、Python</li>
<li>Exporter 插件采集：支持<a href="https://prometheus.io/docs/instrumenting/exporters/">Prometheus</a>的采集协议。可以很方便的将 Exporter 转为监控平台平台的插件</li>
<li>DataDog 插件采集：支持<a href="https://github.com/DataDog/datadog-agent">DataDog</a>的采集。 可以很方便的将 DataDog 转为监控平台平台的插件</li>
<li>JMX 插件采集：采集任何开启了 JMX 服务端口的 Java 进程的服务状态。用户可在插件管理中定义</li>
<li>basereport 基础采集器：默认安装的操作系统指标采集器</li>
<li>processbeat 进程采集器：默认的进程采集器，进程的信息依据 CMDB 的进程管理</li>
<li>bkunifylogbeat 日志采集器：蓝鲸默认的日志采集器，日志采集器支持 Linux 和 Windows</li>
<li>bkmonitorbeat 采集器：支持拨测服务相关的数据采集，如 TCP,UDP,HTTP(s)，不仅是拨测还负责其他插件的管理工作</li>
</ul>
</li>
<li>
<p><strong>数据目标范围</strong>：</p>
<ul>
<li>基于 CMDB 的主机拓扑：监控最小粒度为主机 IP，依据 CMDB 的拓扑结构进行配置</li>
<li>基于 CMDB 的服务拓扑：监控最小粒度为服务实例 instance，依据 CMDB 的拓扑结构进行配置</li>
<li>数据的维度：通过自定义上报或者数据平台来源的数据无法区别 CMDB 的拓扑结构</li>
</ul>
</li>
<li>
<p><strong>数据类型</strong>： 3 种</p>
<ul>
<li>时序数据：<a href="https://zh.wikipedia.org/wiki/%E6%99%82%E9%96%93%E5%BA%8F%E5%88%97">time series</a>监控最重要的数据类型，通过时序数据可以发现大部分的问题。 最重要的三要素就是指标，维度，时间。 并且时间上是连续的</li>
<li>事件数据：事件是已发生的一件事情记录，时间上连续，由多个连续异常点构成</li>
<li>日志数据：日志数据是由系统，应用产生的文本记录。 是重要的监控定位信息之一<ul>
<li>日志的产生方式：文件日志(行日志，段日志) 系统日志(设备日志，Windows Event 日志)</li>
<li>日志的内容格式：文本，json，二进制等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="_4">监控平台基本数据结构</h2>
<h3 id="_5">自定义事件数据</h3>
<pre class="codehilite"><code class="language-json">{
    # 数据通道标识，必需项
    &quot;data_id&quot;: 11223344,
    # 数据通道标识验证码，必需项
    &quot;access_token&quot;: &quot;d9007a0d11111111111118693c1a&quot;,
    &quot;data&quot;: [{
        # 事件标识名，最大长度128
                &quot;event_name&quot;: &quot;input_your_event_name&quot;,
                &quot;event&quot;: {
                    # 事件内容，必需项
                    &quot;content&quot;: &quot;user xxx login failed&quot;
                },
        # 来源标识如IP，必需项
        &quot;target&quot;: &quot;127.0.0.1&quot;,
        # 自定义维度，非必需项
        &quot;dimension&quot;: {
            &quot;module&quot;: &quot;db&quot;,
            &quot;location&quot;: &quot;guangdong&quot;
        },
        # 数据时间，精确到毫秒，非必需项
        &quot;timestamp&quot;: 1600308754824
    }]
}</code></pre>


<h3 id="_6">时序数据结构</h3>
<pre class="codehilite"><code class="language-json">{
    # 数据通道标识，必需项
    &quot;data_id&quot;: 11223344,
    # 数据通道标识验证码，必需项
    &quot;access_token&quot;: &quot;d9007a0d11111111111118693c1a&quot;,
    &quot;data&quot;: [{
        # 指标，必需项
        &quot;metrics&quot;: {
            &quot;http_request_total&quot;: 10
        },
        # 来源标识如IP，必需项
        &quot;target&quot;: &quot;127.0.0.1&quot;,
        # 自定义维度，非必需项
        &quot;dimension&quot;: {
            &quot;module&quot;: &quot;db&quot;,
            &quot;location&quot;: &quot;guangdong&quot;
        },
        # 数据时间，精确到毫秒，非必需项
        &quot;timestamp&quot;: 1600308839050
    }]
}</code></pre>


<h2 id="promtheus">Promtheus 的数据结构</h2>
<p>监控平台支持<a href="https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md">Promtheus 的数据结构</a></p>
<p>参考 Promtheus 的基本数据上报格式。</p>
<pre class="codehilite"><code class="language-bash">&lt;-----&lt;metric name&gt;{&lt;label name&gt;=&lt;label value&gt;, ...}-------&gt;&lt;--value--&gt;
http_request_total{status=&quot;200&quot;, method=&quot;GET&quot;, route=&quot;/api&quot;} 94355
http_request_total{status=&quot;404&quot;, method=&quot;POST&quot;, route=&quot;/user&quot;} 94334</code></pre>


<ul>
<li>
<p><strong>metric</strong>：指标的名称(metric name)可以反映被监控样本的含义(比如，http_request_total - 表示当前系统接收到的 HTTP 请求总量)。指标名称只能由 ASCII 字符、数字、下划线以及冒号组成并必须符合正则表达式<code>[a-zA-Z_:][a-zA-Z0-9_:]*</code></p>
</li>
<li>
<p><strong>label</strong>：标签(label)反映了当前样本的特征维度，通过这些维度 Prometheus 可以对样本数据进行过滤，聚合等。标签的名称只能由 ASCII 字符、数字以及下划线组成并满足正则表达式<code>[a-zA-Z_][a-zA-Z0-9_]*</code>。在监控平台平台中等同于 <strong>dimension</strong></p>
</li>
</ul><h1 id="_1">快速入门</h1>
<p>要快速的接触监控平台先通过快速入门会有一个基本的认识。</p>
<h2 id="_2">接入流程</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15800415288588.jpg" /></p>
<p>基本上接入流程有如下阶段：</p>
<ol>
<li><strong><a href="prepare.md">准备工作</a></strong>：监控平台的监控目标和进程信息主要是依赖 CMDB 的配置，监控的采集链路依赖蓝鲸 Agent 的部署，监控的功能使用依赖<a href="../functions/global/permissions.md">权限的设置</a></li>
<li><strong>数据采集</strong>：监控本身就是围绕数据来工作的，数据从何而来要么通过<a href="../functions/conf/plugins.md">监控插件</a>和<a href="../functions/conf/collect-tasks.md">采集配置</a>获取，要么通过<a href="../functions/conf/custom-report.md">自定义上报</a>主动上报上来，或者直接使用<a href="../guide/bigdata_monitor.md">数据平台</a>的结果表数据</li>
<li><strong>数据检查</strong>：数据是否采集成功，最终还是以是否可以查看相关的图形数据为主。每个采集任务都有一个 <strong>检查视图</strong> 可以查看当前主机/实例采集的数据情况。当然也可以从<a href="../functions/report/dashboard.md">Dashboard</a>去检索一个任意的指标</li>
<li><strong>策略配置</strong>：采集上来的数据要么看要么告警，想要告警的指标通过策略配置进行设置。可以提前规划下告警组在告警通知的时候需要使用</li>
<li><strong>告警处理</strong>：当策略生效并且触发了告警，我们可以通过<a href="../functions/analyze/event.md">事件中心</a>进行查看，也可以通过<a href="../functions/conf/rules.md">告警通知</a>接收到相应的告警内容，对于告警事件可以快速的进行<strong>告警确认</strong>或<a href="../functions/conf/block.md">告警屏蔽</a></li>
<li><strong>其他</strong>：还有很多其他的高级功能可以使用。 <a href="../functions/conf/import-export.md">导入导出</a>，<a href="../functions/global/admin-config.md">全局配置</a></li>
</ol>
<h2 id="_3">监控的四个阶段</h2>
<p>监控平台有这么多功能，有这么多的文档，如何循序渐进的使用监控平台呢？大致可以分为四个层面： </p>
<ul>
<li>第一层：开箱即用               -- <strong>适用于初级用户</strong> </li>
<li>第二层：扩展采集和告警自动处理   -- <strong>适用于高级用户</strong> </li>
<li>第三层：策略高级控制和配置分享   -- <strong>适用于专家级用户</strong></li>
<li>第四层：平台管理和插件开发   -- <strong>适用于管理员和二次开发者</strong></li>
</ul>
<h3 id="_4">第一层： 开箱即用</h3>
<ul>
<li>主机-操作系统监控 <ul>
<li>CMDB 中纳管的机器并且安装了 Agent 的机器会默认进行采集</li>
<li>默认采集的指标 <a href="../functions/addenda/host-metrics.md">主机-操作系统-指标</a></li>
<li>默认采集的事件 <a href="../functions/addenda/host-events.md">主机-操作系统-系统事件</a></li>
<li>主机监控 主机图表查看和对比等功能 <a href="../functions/scene/host-monitor.md">主机监控</a></li>
</ul>
</li>
<li>内置的默认策略 <a href="../functions/addenda/builtin-rules.md">内置策略</a></li>
<li>主机-进程监控<ul>
<li>CMDB 配置的进程默认就会进行采集</li>
<li>默认采集的进程指标和事件 <a href="../functions/addenda/process-metrics.md">主机-进程-指标</a></li>
</ul>
</li>
<li>官方插件： 内置 20 款官方插件，可直接在采集中使用，满足常用组件的监控需求。提供动态的采集需求，自动增删采集<ul>
<li><a href="../functions/addenda/builtin-plugins.md">内置官方插件</a></li>
<li><a href="../functions/conf/collect-tasks.md">采集配置</a></li>
</ul>
</li>
<li>策略配置：可满足 IP，服务实例，集群模块的监控需求，提供 8 种检测算法。并且支持数据平台的数据监控需求<ul>
<li><a href="../functions/addenda/algorithms.md">算法说明</a></li>
<li><a href="../functions/conf/rules.md">策略配置</a></li>
<li><a href="../functions/conf/alarm-group.md">告警组</a></li>
<li><a href="../guide/bigdata_monitor.md">如何监控数据平台的数据</a></li>
</ul>
</li>
<li>监控屏蔽：提供服务实例，IP，集群模块，策略，事件的屏蔽粒度<ul>
<li><a href="../functions/conf/block.md">告警屏蔽</a></li>
</ul>
</li>
<li>仪表盘：提供不同的图表配置，支持日志数据、数据平台数据、监控采集的指标数据画图需求<ul>
<li><a href="../functions/report/dashboard.md">仪盘表</a></li>
</ul>
</li>
<li>服务拨测：提供模拟用户请求的监控需求。 <ul>
<li><a href="../functions/scene/dial.md">服务拨测</a></li>
</ul>
</li>
<li>日志采集和监控<ul>
<li>通过日志平台可以进行日志采集和字段提取</li>
<li>方便的日志检索功能</li>
<li>日志关键字告警功能和日志的指标数据监控能力</li>
<li>日志的指标数据画图能力</li>
<li><a href="../guide/log_monitor.md">如何监控日志平台的数据</a></li>
</ul>
</li>
</ul>
<h3 id="_5">第二层： 扩展采集和告警自动处理</h3>
<ul>
<li>在线制作插件：通过在线插件制作来扩充采集能力，插件制作提供了脚本，Exporter，，JMX，BK-Pull 5 种便利的插件制作类型。可以几分种实现一个好用的采集插件。并且还提供远程采集的方式来满足不方便 Agent 部署的情况。<ul>
<li><a href="../functions/conf/plugins.md">插件制作</a></li>
<li><a href="../guide/script_collect.md">如何通过脚本进行监控</a></li>
<li><a href="../guide/multi_instance_monitor.md">如何实现多实例采集</a></li>
<li><a href="../guide/component_monitor.md">如何对开源组件进行监控</a></li>
<li><a href="../guide/import_exporter.md">如何在线制作 Exporter 插件</a></li>
<li><a href="../guide/import_datadog_online.md">如何在线制作  插件</a></li>
<li><a href="../guide/plugin_jmx.md">如何在线制作 JMX 插件</a></li>
<li><a href="../guide/noagent_monitor.md">无 Agent 如何实现采集</a></li>
</ul>
</li>
<li>自定义上报： 通过自定义上报来扩充采集能力，通过 HTTP 方式上报可以满足业务灵活的业务指标数据上报的能力。 <ul>
<li><a href="../functions/conf/custom-report.md">自定义上报</a></li>
</ul>
</li>
<li>告警回调能力：通过 HTTP 的告警回调，可以进行自动触发。    <a href="../guide/http_callback.md">如何设置告警回调</a></li>
<li>故障自愈能力：通过故障自愈对接对接监控打通处理动作。</li>
</ul>
<h3 id="_6">第三层： 策略高级控制和配置分享</h3>
<ul>
<li>精细化控制：无数据告警，告警恢复，告警收敛和汇总控制<ul>
<li><a href="../functions/addenda/coverge.md">通知收敛和汇总机制</a></li>
</ul>
</li>
<li>自定义告警通知模版：通过模版满足个性化需求<ul>
<li><a href="../guide/notify_case.md">如何自定义通知模版</a></li>
<li><a href="../functions/addenda/variables.md">变量列表</a></li>
</ul>
</li>
<li>策略抑制能力：小范围优先级大于大范围</li>
<li>主机运营字段：通过主机的运营字段来控制是否要进行监控，可与发布和故障处理相关操作打通</li>
<li>忽略进程端口范围端：某些进程端口范围不是用于监控的</li>
<li>导入和导出：可以通过采集，策略，插件的批量导入导出来满足配置的快速分享</li>
</ul>
<h3 id="_7">第四层： 平台管理和插件开发</h3>
<ul>
<li>插件程序开发：当市面上没有合适的插件时，可以自己制作开发。Python 和 Golang 两种语言可以选择自己更擅长的<ul>
<li><a href="../dev/plugin_exporter_dev.md">Exporter 插件开发</a></li>
<li><a href="../dev/plugin_datadog_dev.md">插件开发</a></li>
</ul>
</li>
<li>全局管理：有很多功能控制在全局配置，如磁盘的黑名单，告警风暴的阈值，通知渠道的设置<ul>
<li><a href="../functions/global/admin-config.md">全局配置</a></li>
</ul>
</li>
<li>自监控：监控的监控，保证平台的稳定性<ul>
<li><a href="../functions/global/self-monitor.md">自监控</a></li>
</ul>
</li>
</ul><h1 id="_1">准备工作</h1>
<p>在正式使用监控之前有些准备工作做好了会事半功倍。</p>
<h2 id="_2">了解监控平台</h2>
<p>基本的一个监控平台了解可以阅读下：</p>
<ul>
<li><a href="../concepts/architecture.md">架构图</a></li>
<li><a href="../concepts/datamodule.md">数据模型</a></li>
<li><a href="../concepts/glossary.md">术语解释</a></li>
</ul>
<h2 id="_3">创建一个业务或者申请一个业务</h2>
<p>监控平台的数据都是以<strong>业务</strong>为命名空间。所以要开始使用监控平台先需要申请一个已有业务，或者创建一个新业务。</p>
<p>创建一个业务：<a href="../../../配置平台/产品白皮书/快速入门/case1.md">如何创建业务并导入主机到业务中</a></p>
<p>申请一个业务：通过权限中心申请业务的查看或者编辑权限。</p>
<h2 id="_4">监控平台权限申请</h2>
<p>监控平台已经对接了权限中心，不再依赖配置平台的角色，需要根据提示去权限中心进行权限的申请，权限的粒度可以比以前更细。 </p>
<p>具体可以查看 <a href="perm.md">权限申请</a></p>
<h2 id="cmdb">CMDB 配置信息</h2>
<p>监控平台的主机监控，进程监控，多实例的监控都依赖 CMDB 的配置。配置好 CMDB 才能正确的使用监控平台。</p>
<ul>
<li><a href="../../../配置平台/产品白皮书/场景案例/CMDB_management_process.md">CMDB 如何管理进程</a></li>
<li><a href="../../../配置平台/产品白皮书/产品功能/Instance.md">CMDB 如何配置服务实例</a></li>
</ul>
<h2 id="_5">监控的数据采集器插件安装</h2>
<p>监控功能的数据采集依赖于插件，部分插件为默认开启，其他按需开启。 </p>
<table>
<thead>
<tr>
<th>功能</th>
<th>依赖插件</th>
<th>安装情况</th>
<th>操作方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>主机-操作系统</td>
<td>basereport</td>
<td>默认安装</td>
<td>如发现无数据上报需要在节点管理进行确认</td>
</tr>
<tr>
<td>主机-进程</td>
<td>processbeat</td>
<td>默认安装</td>
<td>节点管理安装</td>
</tr>
<tr>
<td>主机-系统事件</td>
<td>exceptionbeat</td>
<td>默认不安装</td>
<td>节点管理手动安装</td>
</tr>
<tr>
<td>自定义字符型</td>
<td>gsecmdline</td>
<td>默认安装</td>
<td></td>
</tr>
<tr>
<td>日志关键字事件， 插件和采集，服务拨测</td>
<td>bkmonitorbeat</td>
<td>默认不安装</td>
<td>节点管理手动安装</td>
</tr>
<tr>
<td>自定义上报(事件/指标)</td>
<td>bkmonitorproxy</td>
<td>直连不需要安装，云区域需要进行手动安装</td>
<td>云区域的通过节点管理手动安装</td>
</tr>
<tr>
<td>日志文件采集</td>
<td>bkunifylogbeat</td>
<td>默认不安装</td>
<td>节点管理手动安装</td>
</tr>
</tbody>
</table>
<p>节点管理 SaaS 安装插件界面</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/16044597491804.jpg" /></p><h1 id="_1">权限申请</h1>
<p>监控平台的权限申请接入了权限中心，所以需要申请监控平台的使用权限主要是通过权限中心操作。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/16044601082014.jpg" /></p>
<p>具体有两种申请方式：</p>
<ol>
<li>创建权限用户组，如 xx 业务运维组，可以由权限的管理员添加对应的人，或者申请加入该组。</li>
<li>申请自定义权限，可以直接在权限中心进入，也可以在监控产品的引导上进入。</li>
</ol>
<h2 id="_2">权限粒度</h2>
<p>按监控提供的功能进行查看和管理两种基本的划分，一般来说有如下几个用户场景：</p>
<ul>
<li>告警通知的接收者：如运维，开发，测试，产品等。适用申请查看类和屏蔽类操作。</li>
<li>监控的配置者：如运维。适用于申请查看+管理类操作。</li>
<li>监控平台的管理者：适用于全局的功能。 </li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/16044602044573.jpg" /></p><h1 id="_1">快速接入</h1>
<p>快速接入以一个简单的网站做为参考例子，演示如何实现监控的全面覆盖。借此对监控平台的使用也会有一个基本的认识。</p>
<p>大致的步骤：</p>
<ul>
<li>step 1 了解网站架构及确定监控点</li>
<li>step 2 CMDB 配置和准备工作</li>
<li>step 3 配置主机-操作系统和主机-进程监控</li>
<li>step 4 配置服务-组件监控</li>
<li>step 5 配置服务-服务模块的日志监控</li>
<li>step 6 配置应用-服务拨测监控</li>
<li>step 7 通过自定义上报补充业务监控</li>
<li>step 8 分享配置</li>
</ul>
<h2 id="step-1">step 1 了解网站架构及确定监控点</h2>
<p><img alt="快速接入案例截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15834003432759.jpg" /></p>
<table>
<thead>
<tr>
<th>用途</th>
<th>IP</th>
<th>进程</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>web1</td>
<td>10.0.15.239</td>
<td>nginx php-fpm</td>
<td>typecho blog 程序</td>
</tr>
<tr>
<td>web2</td>
<td>10.0.15.155</td>
<td>nginx php-fpm</td>
<td>typecho blog 程序</td>
</tr>
<tr>
<td>mysql master</td>
<td>10.0.15.96</td>
<td>mysql mysqld_safe</td>
<td>数据库主</td>
</tr>
<tr>
<td>mysql slave</td>
<td>10.0.15.138</td>
<td>mysql mysqld_safe</td>
<td>数据库从</td>
</tr>
</tbody>
</table>
<p>为了保证该 BLOG 网站的稳定性，进行一个全方位的监控至少需要满足如下的监控需求：</p>
<ol>
<li>4 台主机的操作系统数据 -- 监控主机的稳定性</li>
<li>4 台主机上的进程数据 -- 监控进程的运行数据和存活性</li>
<li>nginx，php-fpm，mysql 的组件运行数据 -- 监控组件的运行数据</li>
<li>blog 程序的日志数据  -- 采集日志定位和日志关键字告警</li>
<li>网站的拨测数据 -- 远程监控网站可用率</li>
</ol>
<blockquote>
<p>blog 程序选择了<a href="http://typecho.org/">typecho</a>这个轻量的程序做为示例。</p>
</blockquote>
<h2 id="step-2-cmdb">step 2 CMDB 配置和准备工作</h2>
<ul>
<li><a href="../../../配置平台/产品白皮书/产品功能/BusinessManagement.md">创建业务</a></li>
<li><a href="../../../配置平台/产品白皮书/产品功能/SetTemp.md">创建集群</a></li>
<li>
<p><a href="../../../配置平台/产品白皮书/产品功能/Model.md">创建模块</a></p>
<blockquote>
<p>如果进程配置在每台上面是一样的，是建议使用集群模版和服务模版的功能
如果进程配置在每台上面不一样的，建议查看 <a href="../guide/multi_instance_monitor.md">如何实现多实例监控</a></p>
</blockquote>
</li>
</ul>
<p>更多请查看 <a href="./prepare.md">准备工作</a></p>
<p>web 配置</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809126500018.jpg" /></p>
<p>mysql 配置</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809126100566.jpg" /></p>
<p>更多进程配置方法查看<a href="../guide/process_cases.md">进程配置种类</a></p>
<h2 id="step-3-">step 3 配置主机-操作系统和主机-进程监控</h2>
<p>当配置好了进程信息后，在“主机监控”将看到相应采集的数据。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809625239667.jpg" /></p>
<p>平台自带默认的策略详细查看<a href="../functions/addenda/builtin-rules.md">内置策略</a>，当内置策略不满足需求的时候可以增加监控策略。</p>
<p>配置进程端口监控：导航  →  监控配置  →  策略  →  新建</p>
<p><img alt="进程端口截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15833972925153.jpg" /></p>
<p>在事件中心查看告警信息：导航  →  事件中心</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809895919471.jpg" /></p>
<p>更多请查看场景案例：</p>
<ul>
<li><a href="../functions/scene/host-monitor.md">主机监控</a></li>
<li><a href="../guide/process_monitor.md">如何对进程进行监控</a></li>
<li><a href="../guide/os_monitor.md">如何对操作系统进行监控</a></li>
</ul>
<h2 id="step-4-">step 4 配置服务-组件监控</h2>
<p>对于 MySQL、Nginx 使用监控平台官方内置的组件就可以快速的实现组件监控的需求。 更多内置组件查看“导航  →  监控配置  →  插件”</p>
<ul>
<li><a href="../functions/addenda/builtin-plugins.md">内置插件</a></li>
<li><a href="../functions/conf/plugins.md">插件管理</a></li>
</ul>
<p>使用的时候直接在“导航  →  监控配置  →  采集”中直接使用插件能力即可。按插件的配置方法进行设置。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809632369678.jpg" /></p>
<p>采集的数据可在“检查视图”和“仪表盘”中查看，更多的使用方法查看 <a href="../functions/conf/collect-tasks.md">采集配置</a></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809774652787.jpg" /></p>
<p>策略配置具体查看 <a href="../functions/conf/rules.md">策略配置</a></p>
<p>像 PHP-FPM 没有内置的官方插件可以直接使用，可以查看 <a href="../guide/component_monitor.md">如何对开源组件进行监控</a>。</p>
<h2 id="step-5-">step 5 配置服务-服务模块的日志监控</h2>
<p>采集程序的访问日志</p>
<p>日志采集： 导航  →  监控配置  →  采集  →  日志采集  →  新建</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809715128894.jpg" /></p>
<ul>
<li>字段提取-格式化数据</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809846202210.jpg" /></p>
<p>数据检索-查看日志采集的数据，更多的使用方法查看 <a href="../functions/analyze/data-search.md">数据检索</a>。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809845810410.jpg" /></p>
<p>配置日志告警-日志关键字包含 login.php 每分钟超过 10 进行告警。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809852566515.jpg" /></p>
<p>更多日志监控配置查看 <a href="../guide/log_monitor.md">如何通过日志数据进行监控</a></p>
<h2 id="step-6-">step 6 配置应用-服务拨测监控</h2>
<p>增加远程的首页检测，通过服务拨测判断网站的稳定性。</p>
<ul>
<li>新建拨测任务</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809864515258.jpg" /></p>
<ul>
<li>查看拨测结果</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809863857690.jpg" /></p>
<p>还可以设置可用率，响应时长的监控策略，更多请查看。</p>
<ul>
<li><a href="../functions/scene/dial.md">服务拨测</a></li>
</ul>
<h2 id="step-7">step 7 通过自定义上报补充业务监控</h2>
<p>业务代码里面想直接将监控数据上报，有 SDK，命令行工具，HTTP 等方式。</p>
<p>具体查看<a href="../functions/conf/custom-report.md">自定义上报功能</a></p>
<h2 id="step-8">step 8 分享配置</h2>
<p>如果每个业务的网站架构都是差不多，每次都配置一遍 step3-step6 是不是很繁琐。 那么将他们做成一个模版直接导出和导入吧。</p>
<p>导航 →  监控配置 →  导入导出</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/quickstart/media/15809898304165.jpg" /></p>
<p>更多请查看<a href="../functions/conf/import-export.md">导入和导出功能介绍</a></p><h1 id="_1">如何通过脚本进行监控</h1>
<p>脚本的是一种灵活和快速的监控采集方式，不同层的监控对象都可以用脚本来完成。当默认的开箱即用的功能不能满足个性化需求时，脚本是一个非常高效的办法。</p>
<h2 id="_2">前置步骤</h2>
<p>通过脚本进行监控，大致分为如下步骤：</p>
<ul>
<li>第一步：脚本插件定义，调试</li>
<li>第二步：采集配置，检查视图</li>
<li>第三步：配置策略，事件中心</li>
<li>第四步：配置仪表盘视图</li>
</ul>
<h2 id="_3">第一步： 脚本插件定义</h2>
<p><strong>导航位置</strong>：导航  →  监控配置  →  插件  →  新建</p>
<p>脚本采集插件直接在线就可以进行各种脚本的编写和调试，能快速的满足监控采集的需求。</p>
<p><strong>脚本插件工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15769080736217.jpg" /></p>
<p><strong>脚本插件定义步骤</strong>：</p>
<ul>
<li>(1) 插件定义<ul>
<li>【必要】插件基本信息</li>
<li>【必要】选择系统并编写脚本内容</li>
<li>【可选】配置参数</li>
<li>【可选】补充 logo 和描述信息</li>
</ul>
</li>
<li>(2) 插件调试<ul>
<li>参数填写</li>
<li>调试机器选择</li>
<li>调试过程</li>
<li>保存</li>
</ul>
</li>
</ul>
<p>接下来以 <code>磁盘使用率为例</code> 为例实现脚本采集以及指标监控。</p>
<p><img alt="磁盘使用率插件截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833951960344.jpg" /></p>
<p>脚本内容：</p>
<pre class="codehilite"><code class="language-bash">#!/bin/bash

#获取磁盘使用率
disk_name=&quot;$1&quot;
diskUsage=`df -h | grep ${disk_name} | awk -F '[ %]+' '{print $5}'`

echo &quot;disk_usage{disk_name=\&quot;${disk_name}\&quot;} ${diskUsage}&quot;</code></pre>


<p>设置参数：</p>
<p>参数为位置参数 如 shell 的 <code>$1</code>。</p>
<p><img alt="参数定义截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795359812413.jpg" /></p>
<h3 id="_4">插件调试：选择服务器并填写参数</h3>
<blockquote>
<p>注意：这里的服务和下发都是测试联调。填写的内容在后面的采集配置是一样的，主要就是为了验证插件制作是否合理，结果是否如预期。</p>
</blockquote>
<p><img alt="插件调试截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833954908600.jpg" /></p>
<h3 id="_5">确认联调结果并设置指标和维度</h3>
<p>当联调获取到数据后会进行指标维度的设置确认。</p>
<p><img alt="设置指标维度截l图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833956164126.jpg" /></p>
<ul>
<li><strong>指标分组</strong>：指标比较多的时候可以进行分组方便后续的使用</li>
<li><strong>单位设置</strong>：可以设置单位，单位是上报的数值的基础单位，后续的展示会根据单位进制进行动态的显示</li>
<li><strong>数据预览</strong>：可以非常方便的看到调试获取的数据值是否符合预期</li>
</ul>
<blockquote>
<p>注意：当保存后指标维度还可以继续进行设置 (在调试窗口的左下角)
<img alt="调试窗口截lt图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833958304147.jpg" />
注意：整个调试过程超时时间为 600 秒，如果 600 秒内没有保存就会关闭这个调试过程，保证服务器上不会有残留的调试进程。</p>
</blockquote>
<h3 id="_6">保存插件</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795333851539.jpg" /></p>
<blockquote>
<p>注意：做了每次修改都需要进行联调成功才能真正的保存。</p>
</blockquote>
<h2 id="_7">第二步： 添加采集配置</h2>
<p>正常新建一个插件后就可以直接点击“新增采集配置”，自动创建一些内容。如果返回列表页了，还可以从如下导航进入。</p>
<p><strong>导航位置</strong>：导航  →  监控配置  →  采集  →  新建</p>
<p>采集步骤：</p>
<ul>
<li>1） 插件选择和参数填写</li>
<li>2） 选择目标</li>
<li>3） 采集下发</li>
<li>4） 完成</li>
</ul>
<h3 id="1">1）采集参数填写</h3>
<p>选择好插件就可以进行参数的内容填写。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795335324256.jpg" /></p>
<h3 id="2">2）选择目标</h3>
<p>选择目标可以是静态和动态两种方式。建议使用动态的方式。</p>
<ul>
<li>静态：只有操作系统基于 IP 选择能基于静态 IP 选择，静态 IP 支持手动输入和服务拓扑的方式选择</li>
<li>动态：最小只能选择到模块级别。基于任意节点，就可以满足扩缩容后自动实现采集的扩缩容</li>
</ul>
<h3 id="3">3）采集下发</h3>
<p>采集下发，可以查看采集下发的过程，当失败的时候还可以进行重试。当然直接离开还是会异常执行完成。最后可以在列表页的“状态”查看最终的结果。</p>
<h3 id="4">4）完成</h3>
<p>完成后会引导去“检查视图”和“策略配置”。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795343310324.jpg" /></p>
<h3 id="_8">检查视图</h3>
<p>检查视图验证采集的正确性。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795345126810.jpg" /></p>
<h2 id="_9">第三步： 策略配置</h2>
<p>策略配置步骤：</p>
<ul>
<li>1） 基本信息：<ul>
<li>策略名称：在告警通知里面会显示。</li>
<li>监控对象：影响指标的影响范围。</li>
</ul>
</li>
<li>2） 监控项：<ul>
<li>监控指标的选择</li>
<li>监控统计方法： 监控维度，条件，周期，公式选择</li>
<li>检测算法选择和配置</li>
<li>高级选项：收敛规则，通知模版。</li>
</ul>
</li>
<li>3） 通知设置：<ul>
<li>通知间隔</li>
<li>通知时间段</li>
<li>通知方式：告警组设置</li>
</ul>
</li>
<li>4） 监控目标范围选择</li>
</ul>
<h3 id="_10">基本信息和监控项</h3>
<p><img alt="基础信息填写" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833966792804.jpg" /></p>
<blockquote>
<p>注意：监控对象选择影响指标选择的范围，也决定了当前策略的分类。</p>
</blockquote>
<h3 id="_11">指标项设置</h3>
<p><img alt="指标选择截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833967379533.jpg" /></p>
<h4 id="_12">监控目标范围选择</h4>
<p>同样分为静态和动态，建议使用动态方式。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795355374829.jpg" /></p>
<p><img alt="指标项设置截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833967895707.jpg" /></p>
<h3 id="_13">通知设置</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833968260066.jpg" /></p>
<h3 id="_14">事件中心</h3>
<p>在事件中心查看策略命中的告警事件。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795356641882.jpg" /></p>
<p>查看告警详情：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795356836020.jpg" /></p>
<h2 id="_15">第四步： 仪表盘视图配置</h2>
<p>把常用的指标视图设置到仪表盘中。</p><h1 id="_1">如何实现多实例采集</h1>
<p>多实例指的是同样的一个服务，部署在相同服务器或者不同服务器的不同的配置情况。如：redis 在同一台服务器部署了 6379 和 6380 两个实例，并且两个实例的密码还不一样。</p>
<p>配置方法：</p>
<ul>
<li>1) CMDB 配置多服务实例</li>
<li>2) 采集配置使用 CMDB 变量</li>
</ul>
<h2 id="cmdb">CMDB 配置多服务实例</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15782889239728.jpg" /></p>
<p><strong>配置路径</strong>：导航  →  业务  →  业务拓扑  →  模块设置  →  服务实例设置  →  进程设置  →  标签设置(可选)</p>
<p>服务实例的配置在服务拓扑(标识 1)</p>
<blockquote>
<p><strong>注意</strong>： 如果在同一个模块(标识 2)下面有多实例的情况使用不了模版功能。需要使用自由的配置模式。</p>
</blockquote>
<p>如图设置了两个 redis 服务实例，端口分别是 6379 和 6380(标识 3)。服务实例的概念具体查看<a href="../concepts/glossary.md">术语解释</a>。</p>
<p>并且设置了<code>标签</code>功能(标识 4)，因为两个 redis 实例的密码不一样。标签： <code>redis_password</code>。</p>
<blockquote>
<p><strong>注意</strong>： 从安全性的解决来说，一般是不建议密码存储在标签中的。</p>
</blockquote>
<h2 id="_2">采集配置使用变量参数</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15782891786421.jpg" /></p>
<ul>
<li>标识 1：运行参数填写的变量可查看<code>点击查看推荐变量</code></li>
<li>标识 2：选择不同的绑定 ip 和端口。 <code>{{target.process["redis-server"].bind_ip}}</code>   <code>{{target.process["redis-server"].port}}</code></li>
</ul>
<blockquote>
<p>注意：redis-server 是进程名称。</p>
</blockquote>
<ul>
<li>标识 3：获取对应的密码，使用标签的功能 <code>{{target.service.labels['redis_password']}}</code></li>
</ul>
<p>更多的变量列表查看<a href="../functions/addenda/variables.md">变量列表</a>。</p>
<h2 id="_3">动态采集和监控</h2>
<p>采集的目标选择动态的方式，基于某个服务模块甚至是任意的节点。</p>
<p>监控的目标也选择动态的方式。</p><h1 id="_1">如何对开源组件进行监控</h1>
<p>如何使用监控平台快速对开源组件、中间件服务进行监控，保障业务的应用服务运行正常。</p>
<h2 id="_2">前置步骤</h2>
<p>开源的服务模块常被称为 <strong>『组件』</strong> <strong>『中间件』</strong>，是被人所熟知的一些常用服务模块，所以有很多现成的监控采集方式，其实真正要满足组件的监控，不仅仅有这些方式，也完全可以自定义脚本等等。</p>
<h2 id="_3">组件监控的方案</h2>
<h3 id="_4">方法一：使用内置的官方插件</h3>
<p>目前覆盖 Apache、Nginx、Tomcat、MySQL、Redis 等常用组件的性能指标监控，具体配置请参照 APP 上的接入指引。具体查看<a href="../functions/addenda/builtin-plugins.md">内置官方插件列表</a>。</p>
<blockquote>
<p><strong>注意</strong>： 如果想监控的组件不在此列，或者是组件提供的接入提示说明不清晰/按说明无法成功接入，请联系蓝鲸助手 QQ： <a href="http://wpa.b.qq.com/cgi/wpa.php?ln=1&amp;key=XzgwMDgwMjAwMV80NDMwOTZfODAwODAyMDAxXzJf">800802001</a> 反馈给监控平台团队。（文档中心反馈功能也可以接入这个反馈）</p>
</blockquote>
<h3 id="_5">方法二：使用其他人制作的监控平台插件导入</h3>
<p>可以通过导入功能，把其他人制作的或者分享的插件导入到插件管理中。</p>
<p><strong>导入功能位置</strong>：导航  →  监控配置  →  插件  →  导入</p>
<h3 id="exporter">方法三：使用开源的 Exporter 在线定义插件</h3>
<p>具体查看<a href="import_exporter.md">如何使用开源的 Exporter</a>。</p>
<h3 id="exporter_1">方法四：开发 Exporter 采集插件</h3>
<p>当市面上没有开源的，或者不满足需求是。开发一个 Exporter 也是非常简单的事件。具体查看<a href="../dev/plugin_exporter_dev.md">如何开发一个 Exporter 采集插件</a>。</p><h1 id="exporter">如何在线制作 Exporter 插件</h1>
<p>监控平台兼容 <a href="https://prometheus.io/docs/instrumenting/exporters/">Prometheus Exporter</a>的导入能力，从 Github 获取源码编译二进制或直接获取 release，按照监控平台的插件规范，可以让监控采集变得非常的简单。</p>
<h2 id="_1">环境准备</h2>
<ol>
<li>Golang 编译环境</li>
<li>找到开源的 Exporter <a href="https://prometheus.io/docs/instrumenting/exporters/">Exporter 列表</a></li>
</ol>
<blockquote>
<p>以下内容以 redis_exporter 为例， <a href="https://github.com/oliver006/redis_exporter">redis_exporter</a></p>
</blockquote>
<h2 id="exporter_1">编辑 Exporter</h2>
<ol>
<li>按 readme 进行编译。</li>
</ol>
<pre class="codehilite"><code class="language-bash">$ go get github.com/oliver006/redis_exporter
$ cd $GOPATH/src/github.com/oliver006/redis_exporter
$ go build
$ ./redis_exporter &lt;flags&gt;</code></pre>


<h2 id="_2">定义监控平台插件</h2>
<ol>
<li>新增插件填写相关信息并且上传编译好的二进制程序。</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767570044182.jpg" /></p>
<ol>
<li>
<p>查看命令行参数，选择常用的参数并且设置</p>
<ul>
<li>查看参数内容<code>redis-exporter -h</code></li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767577083458.jpg" /></p>
<ul>
<li>设置参数</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767571025818.jpg" /></p>
<ul>
<li>1) 绑定端口：指的是插件运行的默认端口，如果默认端口被占用会自动自增一个可用的端口</li>
<li>2) 绑定主机：默认是 127.0.0.1 ， 暂不支持其他，主要提供给</li>
</ul>
<blockquote>
<p>注意：这里不是 redis 服务的端口，而是 Exporter 运行的端口。绑定的主机也是 Exporter 运行的主机。</p>
<p><code>${port}</code>和<code>${host}</code> 是内置的两个变量为了让 <code>bkmonitorbeat</code> 知道监听的端口和位置。</p>
</blockquote>
<ul>
<li>
<p>3) 定义需要的参数</p>
<ul>
<li>必要参数：为了让 <code>bkmonitorbeat</code> 可以发现 Exporter 需要使用 <code>${port}</code>和<code>${host}</code></li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767575157482.jpg" /></p>
<ul>
<li>常用参数：指定服务的地址 如 redis</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767575571477.jpg" /></p>
<ul>
<li>常用参数：redis 服务连接的方式需要密码时</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767576097853.jpg" /></p>
</li>
</ul>
</li>
<li>
<p>查看采集的指标，并进行设置</p>
</li>
</ol>
<p>查看指标的方法：</p>
<p>1) readme 文件</p>
<p>2) 本地启动 Exporter 命令行 <code>curl http://127.0.0.1:9121/metrics</code></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767583017506.jpg" /></p>
<ol>
<li>补充其他信息 LOGO 说明</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767586573043.jpg" /></p>
<h3 id="_3">插件调试和验证</h3>
<ol>
<li>下一步进入调试</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15767587464484.jpg" /></p>
<h3 id="_4">插件采集数据</h3>
<ol>
<li>开始正式采集</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15768471720714.jpg" /></p>
<blockquote>
<p><strong>注意</strong>：因为 redis 是绑定在内网 IP 上面，所以需要使用 CMDB 变量参数来解决采集。<code>redis://{{target.host.bk_host_innerip}}:6379</code></p>
</blockquote>
<ol>
<li>查看<strong>检查视图</strong>来确认数据是否已经上报.</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15768473016337.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15768473224875.jpg" /></p>
<blockquote>
<p><strong>注意</strong>：因为数据采集有一定的周期性，至少等待两分钟才可以看到相应的数据点。</p>
</blockquote>
<h3 id="_5">策略配置和视图配置</h3>
<ol>
<li>配置策略</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15768474423021.jpg" /></p>
<ol>
<li>查看<strong>告警事件</strong></li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15768476909056.jpg" /></p>
<ol>
<li>在仪表盘中添加视图</li>
</ol>
<h3 id="_6">插件导出并分享</h3>
<p>制作好的插件还可以导出给其他人或者其他业务使用。如果是管理员还可以将插件共享给整个平台使用。</p><h1 id="prometheus">如何直接获取 Prometheus 的数据</h1>
<p>监控平台支持了 Prometheus 的数据上报格式，并且也提供一些便利的工具，但并不代表监控平台是可以完全兼容的，因为整个架构和 Prometheus 是不一样的，存储也不一样，所以直接获取 Prometheus 的数据只是获取 Exporter 暴露出来的数据。</p>
<p>服务器已经运行了 Prometheus 的 Exporter 或者 pushgateway 或者 服务暴露出来的 metrics 接口，此时，无需对原有的采集插件进行任何改动，只需要按照如下的步骤操作即可接入到监控平台。</p>
<h2 id="_1">前置步骤</h2>
<p><strong>工作原理</strong></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003126158054.jpg" /></p>
<p><strong>操作步骤</strong></p>
<ul>
<li>第一步：制作 BK-Pull 插件</li>
<li>第二步：下发采集</li>
<li>第三步：查看数据</li>
<li>第四步：配置告警</li>
</ul>
<h2 id="bk-pull">第一步： 制作 BK-Pull 插件</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003127689460.jpg" /></p>
<p>制作插件，选择 BK-Pull 方式</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003128089807.jpg" /></p>
<p>调试插件</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003128803887.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003129004634.jpg" /></p>
<h2 id="_2">第二步： 下发采集任务</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003129894876.jpg" /></p>
<h2 id="_3">第三步： 查看采集数据</h2>
<p>通过采集任务的“检查视图”查看数据。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16003130464749.jpg" /></p>
<h2 id="_4">第四步： 配置告警</h2>
<p>配置告警参考<a href="../functions/conf/rules.md">策略配置功能说明</a></p><h1 id="_1">如何在线制作插件</h1>
<p>在监控平台的插件管理里面可以非常方便的制作一个的插件。</p>
<h2 id="_2">第一步：准备工作</h2>
<ol>
<li>获取 BK-Plugin  Framework</li>
</ol>
<p><code>bash
   git clone https://xxx.com/datadog_plugin_framework.git</code></p>
<ol>
<li>获取   Integrations(6.15x 分支代码)</li>
</ol>
<p>官方 </p>
<p><code>bash
   git clone https://github.com/DataDog/integrations-core.git</code></p>
<p>社区</p>
<p><code>bash
   git clone https://github.com/DataDog/integrations-extras.git</code></p>
<p>将上面的仓库 clone 下来，看是否有需要的组件，如果没有，需要根据 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/">官方规范</a> 自行开发。每个  Integrations 包都是一个完整的 Python 包，里面包含了一种组件的采集逻辑。</p>
<ol>
<li>
<p>准备两种操作系统，并确定已安装 <code>python 2.7</code> 和 <code>pip</code></p>
</li>
<li>
<p>Windows 64 位</p>
</li>
<li>Mac OS/Linux 64 位</li>
</ol>
<h2 id="_3">第三步：生成基础包</h2>
<p>以 <code>consul</code> 组件为例</p>
<ol>
<li>在本地 <code>integrations-core</code> 仓库中找到名为 <code>consul</code> 文件夹，记录路径</li>
</ol>
<p><code>bash
   ~/Projects/integrations-core/consul</code></p>
<ol>
<li>进入 <code>datadog_plugin_framework</code> 目录，执行构建命令</li>
</ol>
<p><code>bash
   python build.py consul ~/Projects/integrations-core/consul -o ~/Desktop/datadog_plugins</code></p>
<p>稍等片刻后，<code>~/Desktop/datadog_plugins</code> 路径下会创建一个名为 <code>bkplugin_consul</code> 的文件夹，根据你使用的操作系统，会生成对应 os 的目录</p>
<ol>
<li>将生成的 <code>bkplugin_consul</code> 的目录压缩为 <code>tgz</code> 格式，即可在插件编辑页面进行上传</li>
</ol>
<h2 id="_4">第三步：在插件管理中创建插件</h2><h1 id="_1">如何线下定义插件</h1>
<p>线下定义  插件是不必经过 web 界面就可以在线下完成  的插件的制作，制作完成后通过导入功能上传到插件管理。</p>
<h2 id="_2">准备工作</h2>
<ol>
<li>获取 BK-Plugin  Framework</li>
</ol>
<p><code>bash
   git clone https://xxx.com/datadog_plugin_framework.git</code></p>
<ol>
<li>获取   Integrations(6.15x 分支代码)</li>
</ol>
<p>官方</p>
<p><code>bash
   git clone https://github.com/DataDog/integrations-core.git</code></p>
<p>社区</p>
<p><code>bash
   git clone https://github.com/DataDog/integrations-extras.git</code></p>
<p>将上面的仓库 clone 下来，看是否有需要的组件，如果没有，需要根据 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/">官方规范</a> 自行开发。每个  Integrations 包都是一个完整的 Python 包，里面包含了一种组件的采集逻辑。</p>
<ol>
<li>
<p>准备两种操作系统，并确定已安装 <code>Python 2.7</code> 和 <code>pip</code></p>
</li>
<li>
<p>Windows 64 位</p>
</li>
<li>Mac OS/Linux 64 位</li>
</ol>
<h2 id="_3">生成基础包</h2>
<p>以 <code>consul</code> 组件为例。</p>
<ol>
<li>在本地 <code>integrations-core</code> 仓库中找到名为 <code>consul</code> 文件夹，记录路径</li>
</ol>
<p><code>bash
   ~/Projects/integrations-core/consul</code></p>
<ol>
<li>进入 <code>datadog_plugin_framework</code> 目录，执行构建命令</li>
</ol>
<p><code>bash
   python build.py consul ~/Projects/integrations-core/consul -o ~/Desktop/datadog_plugins</code></p>
<p>稍等片刻后，<code>~/Desktop/datadog_plugins</code> 路径下会创建一个名为 <code>bkplugin_consul</code> 的文件夹，根据你使用的操作系统，会生成对应 os 的目录。</p>
<h2 id="_4">包测试</h2>
<ol>
<li>进入基础包目录(如果上个步骤打的是 Linux 包)</li>
</ol>
<p><code>bash
   ~/Desktop/datadog_plugins/bkplugin_consul/external_plugins_linux_x86_64/bkplugin_consul</code></p>
<ol>
<li>拷贝配置模板</li>
</ol>
<p><code>bash
   cp etc/conf.yaml.example etc/conf.yaml</code></p>
<ol>
<li>
<p>修改 <code>etc/conf.yaml</code> ，根据实际情况填写</p>
</li>
<li>
<p>执行启动脚本</p>
</li>
</ol>
<p><code>bash
   ./start.sh</code></p>
<ol>
<li>若输出类似于以下格式，则说明能够正常运行。但是指标的正确性仍需人工检查</li>
</ol>
<p><code>bash
   consul_check{check="service:rabbitmq-1",consul_datacenter="dc",consul_service_id="rabbitmq-1",service="rabbitmq"} 1
   consul_check{check="service:redis-1",consul_datacenter="dc",consul_service_id="redis-1",service="redis"} 1</code></p>
<h2 id="_5">制作标准包</h2>
<ol>
<li>清理测试步骤所产生的多余文件</li>
</ol>
<p><code>bash
   find . -name "*.pyc" -delete
   rm -rf logs
   rm -f conf.yaml</code></p>
<p>此时，目录结构应该长这样子</p>
<p><code>bash
   ├── VERSION
   ├── etc
   │   ├── conf.yaml
   │   ├── conf.yaml.example
   │   ├── env.yaml
   │   └── env.yaml.tpl
   ├── info
   │   ├── config.json
   │   ├── description.md
   │   ├── meta.yaml
   │   ├── metrics.json
   │   ├── release.md
   │   └── signature.yaml
   ├── lib
   │   ├── __init__.py
   │   ├── collector.py
   │   ├── data_formatter.py
   │   ├── log.py
   │   ├── main.py
   │   ├── patch
   │   │   ├── __init__.py
   │   │   └── aggregator_base.py
   │   └── site-packages
   ├── logs
   │   └── consul.log
   ├── main.py
   ├── parse_yaml.sh
   ├── project.yaml
   └── start.sh</code></p>
<ol>
<li>制作配置模板</li>
</ol>
<p><code>bash
   cp etc/conf.yaml.example etc/conf.yaml.tpl</code></p>
<p>查看配置，并使用占位符 <code>{{ var }}</code> 将变量标记起来。注意，完整的配置可能有非常多的参数，但只需标记使用频率高的参数，如用户名、密码等变量。</p>
<p>例如，在 consul 的 <code>conf.yaml.example</code> 中，有以下配置：</p>
<p>```yaml
   init_config:</p>
<p>instances:
       ## @param url - string - required
       ## Where your Consul HTTP Server Lives
       ## Point the URL at the leader to get metrics about your Consul Cluster.
       ## Remind to use https instead of http if your Consul setup is configured to do so.
       #
     - url: http://localhost:8500
   ```</p>
<p>可在 <code>conf.yaml.tpl</code> 中，将 <code>url</code> 的值使用占位符代替。</p>
<p>```yaml
   init_config:</p>
<p>instances:
       ## @param url - string - required
       ## Where your Consul HTTP Server Lives
       ## Point the URL at the leader to get metrics about your Consul Cluster.
       ## Remind to use https instead of http if your Consul setup is configured to do so.
       #
     - url: {{ instance_url }}
   ```</p>
<p><code>instance_url</code> 这个名称先记住，后面完善 <code>config.json</code> 会用到。</p>
<ol>
<li>完善 meta.yaml</li>
</ol>
<p><code>info/meta.yaml</code> 里面有些字段需要手动填写：</p>
<p><code>yaml
   # 插件ID，通常为 bkplugin_{组件名称}
   plugin_id: bkplugin_consul
   # 插件显示名称
   plugin_display_name: Consul
   # 插件类型，不要改动
   plugin_type: DataDog
   # 标签，置空即可
   tag:
   # 插件类型，不要改动
   label: component
   # 是否支持远程采集
   is_support_remote: True
   # 固定字段，不要改动
   datadog_check_name: consul</code></p>
<ol>
<li>完善 metrics.json</li>
</ol>
<p>请根据实际上报指标和维度，定义 <code>info/metrics.json</code>，格式参考插件规范。样例如下：</p>
<p><code>json
   {
    "fields": [{
        "description": "数据中心",
        "type": "string",
        "monitor_type": "dimension",
        "unit": "",
        "name": "consul_datacenter"
    }, {
        "description": "节点ID",
        "type": "string",
        "monitor_type": "dimension",
        "unit": "",
        "name": "consul_node_id"
    }, {
        "description": "关键服务总数",
        "type": "double",
        "monitor_type": "metric",
        "unit": "",
        "name": "consul_catalog_services_critical"
    }],
    "table_name": "node_metrics",
    "table_desc": "节点相关指标"
   }]</code></p>
<ol>
<li>
<p>完善 config.json</p>
<p><code>info/config.json</code> 根据步骤 2 中模板预留的占位符定义参数，格式参考插件规范。样例如下，其中：</p>
</li>
<li>
<p><code>python_path</code> 必须提供</p>
</li>
<li>其他参数为 <code>conf.yaml.tpl</code>中提供的占位符，mode 请填写 <code>opt_cmd</code> ，其余按实际情况填写</li>
</ol>
<p><code>json
   [
       {
           "description": "Python 程序路径",
           "default": "python",
           "visible": false,
           "mode": "collector",
           "type": "text",
           "name": "python_path"
       },
       {
           "default": "http://localhost:8500",
           "mode": "opt_cmd",
           "type": "text",
           "description": "实例 URL",
           "name": "instance_url"
       }
   ]</code></p>
<ol>
<li>完善 description.md</li>
</ol>
<p><code>info/description.md</code> 描述这个插件。包括插件的用途、插件的参数列表及填写示例、插件的依赖等。</p>
<p><strong>配置说明</strong></p>
<p>请确认目标机器已安装<code>python 2.7</code>或更高版本，并正确填写 Python 程序所在路径。</p>
<p>配置信息：
   - <code>实例 URL</code>：Consul 的 HTTP 服务地址，例如 <code>http://localhost:8500</code></p>
<ol>
<li>
<p>插入 logo.png</p>
</li>
<li>
<p>完善 project.yaml</p>
</li>
</ol>
<p>以下三个字段需要自行完善：</p>
<ul>
<li>name</li>
<li>description</li>
<li>description_en</li>
</ul>
<p><code>yaml
   name: bkplugin_consul
   version: 1.1
   description: Consul
   description_en: Consul
   category: external
   auto_launch: false
   launch_node: all
   upstream:
      bkmonitorbeat
   dependences:
      gse_agent: "1.2.0"
      bkmonitorbeat: "1.7.0"
   control:
      start: "./start.sh"
      version: "cat VERSION"
      debug: "./debug.sh"
   config_templates:
      - plugin_version: "*"
        name: env.yaml
        version: 1
        file_path: etc
        format: yaml
        source_path: etc/env.yaml.tpl
      - plugin_version: "*"
        name: conf.yaml
        version: 1
        file_path: etc
        format: yaml
        source_path: etc/conf.yaml.tpl</code></p>
<h2 id="_6">制作多操作系统的插件包</h2>
<p>将 4 中的步骤在不同操作系统上再操作一次，然后将这些目录合并，最终得到一个这样的目录结构。</p>
<pre class="codehilite"><code class="language-bash">bkplugin_consul  --  根目录
└── external_plugins_linux_x86_64
    └── bkplugin_consul
└── external_plugins_windows_x86_64
    └── bkplugin_consul</code></pre>


<p>进入到根目录下打包。</p>
<pre class="codehilite"><code class="language-bash">tar cvzf bkplugin_consul-1.1.tgz external_plugins_*</code></pre>


<p>至此，一个完整的插件包诞生了，可以在监控平台的插件管理页面进行导入。</p><h1 id="jmx">如何在线制作 JMX 插件</h1>
<p>JMX 插件工作原理：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15769074528725.jpg" /></p>
<h1 id="jmx_1">自定义一个 JMX 插件</h1>
<h2 id="jmx_2">开启 JMX 远程访问功能</h2>
<p>java 默认自带的了 JMX RMI 的连接器。所以，只需要在启动 java 程序的时候带上运行参数，就可以开启 Agent 的 RMI 协议的连接器。</p>
<h3 id="java">自研 java 程序</h3>
<p>例如 java 程序为 <code>app.jar</code>，其启动命令为：</p>
<pre class="codehilite"><code class="language-bash">java -jar app.jar</code></pre>


<p>若要开启 JMX 远程访问功能，需要添加如下启动参数：</p>
<pre class="codehilite"><code class="language-bash">java -jar app.jar \
-Dcom.sun.management.jmxremote \
-Dcom.sun.management.jmxremote.port=9999 \
-Dcom.sun.management.jmxremote.authenticate=false \
-Dcom.sun.management.jmxremote.ssl=false</code></pre>


<p>参数说明：</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-Dcom.sun.management.jmxremote</code></td>
<td>布尔</td>
<td>是否支持远程 JMX 访问，默认 true。<strong>此项必须开启才能正常进行监控采集</strong></td>
</tr>
<tr>
<td><code>-Dcom.sun.management.jmxremote.port</code></td>
<td>数值</td>
<td>监听端口号，用于远程访问</td>
</tr>
<tr>
<td><code>-Dcom.sun.management.jmxremote.authenticate</code></td>
<td>布尔</td>
<td>是否需要开启用户认证，默认 <code>true</code>。开启后需要提供用户名与密码才能进行采集</td>
</tr>
<tr>
<td><code>-Dcom.sun.management.jmxremote.ssl</code></td>
<td>布尔</td>
<td>是否对连接开启 SSL 加密，默认<code>true</code>。<strong>当前版本暂不支持 SSL 加密，请将此项设置为 false</strong></td>
</tr>
<tr>
<td><code>-Dcom.sun.management.jmxremote.access.file</code></td>
<td>字符串</td>
<td>用户权限配置文件的路径，默认为 <code>JRE_HOME/lib/management/ jmxremote.access</code>。当 <code>-Dcom.sun.management.jmxremote.authenticate</code> 配置为 <code>true</code> 时，该配置才会生效</td>
</tr>
<tr>
<td><code>-Dcom.sun.management.jmxremote. password.file</code></td>
<td>字符串</td>
<td>用户密码配置文件的路径，默认为 <code>JRE_HOME/lib/management/ jmxremote.password</code>。当 <code>-Dcom.sun.management.jmxremote.authenticate</code> 配置为 <code>true</code> 时，该配置才会生效</td>
</tr>
</tbody>
</table>
<p><code>jmxremote.password</code> 文件样例：</p>
<pre class="codehilite"><code class="language-bash"># specify actual password instead of the text password
monitorRole password
controlRole password</code></pre>


<p><code>jmxremote.access</code> 文件样例：</p>
<pre class="codehilite"><code class="language-bash"># The &quot;monitorRole&quot; role has readonly access.
# The &quot;controlRole&quot; role has readwrite access.
monitorRole readonly
controlRole readwrite</code></pre>


<p>更多 JMX 配置参数详情，可参考 <a href="https://docs.oracle.com/javase/7/docs/technotes/guides/management/agent.html#gdeum">官方文档</a></p>
<h3 id="_1">第三方组件</h3>
<p>各个组件的远程 JMX 开启方式，请参考各组件文档。</p>
<h3 id="_2">检查是否启动成功</h3>
<p>客户端可以通过以下 URL 去远程访问 JMX 服务。其中，<code>hostName</code> 为目标服务的主机名/IP，<code>portNum</code> 为以上配置的 <code>jmxremote.port</code>。</p>
<pre class="codehilite"><code class="language-bash">service:jmx:rmi:///jndi/rmi://${hostName}:${portNum}/jmxrmi</code></pre>


<p>可通过以下两种方式检查是否已经配置成功：</p>
<ol>
<li>简单地可通过检查端口是否存在，以及 PID 是否匹配，来确认 JMX 远程访问是否已经成功启动</li>
</ol>
<pre class="codehilite"><code class="language-bash">netstat -anpt | grep ${portNum}</code></pre>


<ol>
<li>如果安装了 JConsole，也可直接连接测试</li>
</ol>
<p><img alt="image-20200210135132015" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210135132015.png" /></p>
<p>连接成功后，即可进入管理页面。</p>
<p><img alt="image-20200210135228009" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210135228009.png" /></p>
<h2 id="_3">采集配置</h2>
<p>监控平台中的 JMX 采集是基于 <a href="https://github.com/prometheus/jmx_exporter">Prometheus JMX Exporter</a> 实现的。插件定义页面的“采集配置”对应了 JMX Exporter 的 <code>config.yaml</code> 配置文件。它决定了该插件将会采集哪些指标，以及决定以何种格式输出。配置文件的定义方式有两种：</p>
<h3 id="_4">使用配置模板</h3>
<p>JMX Exporter 官方提供了常用组件的 <a href="https://github.com/prometheus/jmx_exporter/tree/master/example_configs">配置模板</a> ，可直接使用</p>
<h3 id="_5">手动配置</h3>
<p>若配置模板不能满足需求，也可通过手动配置，以下是一个配置样例：</p>
<pre class="codehilite"><code class="language-yaml">startDelaySeconds: 0
lowercaseOutputName: false
lowercaseOutputLabelNames: false
whitelistObjectNames: [&quot;Catalina:*&quot;, &quot;java.lang:*&quot;]
blacklistObjectNames: [&quot;Catalina:j2eeType=Servlet,*&quot;]

rules:
  - pattern: 'Catalina&lt;type=ThreadPool, name=&quot;(\w+-\w+)-(\d+)&quot;&gt;&lt;&gt;(currentThreadCount|currentThreadsBusy|keepAliveCount|pollerThreadCount|connectionCount):(.*)'
    name: tomcat_threadpool_$3
    value: $4
    valueFactor: 1
    labels:
      port: &quot;$2&quot;
      protocol: &quot;$1&quot;</code></pre>


<ul>
<li>字段说明</li>
</ul>
<table>
<thead>
<tr>
<th>字段名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>startDelaySeconds</td>
<td>启动延迟。延迟期内的任何请求都将返回空指标</td>
</tr>
<tr>
<td>lowercaseOutputName</td>
<td>小写输出指标名称。适用于 name。默认为 false</td>
</tr>
<tr>
<td>lowercaseOutputLabelNames</td>
<td>小写输出指标的标签名称。适用于 labels。默认为 false</td>
</tr>
<tr>
<td>whitelistObjectNames</td>
<td>要查询的 ObjectNames 列表。默认为所有 mBeans</td>
</tr>
<tr>
<td>blacklistObjectNames</td>
<td>要查询的 ObjectNames 列表。优先级高于 whitelistObjectNames。默认为 none</td>
</tr>
<tr>
<td>rules</td>
<td>要按顺序应用的规则列表，在第一个匹配到的规则处停止处理。不收集不匹配的属性。如果未指定，则默认以默认格式收集所有内容</td>
</tr>
<tr>
<td>pattern</td>
<td>用正则表达式模式匹配每个 bean 属性。匹配值(用小括号标识一个匹配值)可被其他选项引用，引用方式为$n(表示第 n 个匹配值)。默认为匹配所有内容</td>
</tr>
<tr>
<td>name</td>
<td>指标名称。可以引用来自 pattern 的匹配值。如果未指定，将使用默认格式：<code>domain_beanPropertyValue1_key1_key2_…keyN_attrName</code></td>
</tr>
<tr>
<td>value</td>
<td>指标的值。可以使用静态值或引用来自 pattern 的匹配值。如果未指定，将使用 mBean 值</td>
</tr>
<tr>
<td>valueFactor</td>
<td>用于将指标的值 value 乘以该设置值，主要用于将 mBean 值从毫秒转换为秒。默认为 1</td>
</tr>
<tr>
<td>labels</td>
<td>标签名称到标签值的映射。可以引用来自 pattern 的匹配值。使用该参数必须先设置 name。如果使用了 name 但未指定该值，则不会输出任何标签</td>
</tr>
</tbody>
</table>
<ul>
<li>pattern 格式说明</li>
</ul>
<pre class="codehilite"><code class="language-bash">domain&lt;beanpropertyName1=beanPropertyValue1, beanpropertyName2=beanPropertyValue2, ...&gt;&lt;key1, key2, ...&gt;attrName: value</code></pre>


<table>
<thead>
<tr>
<th>Part</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>domain</td>
<td>Bean 名称，JMX object name 中冒号之前的部分</td>
</tr>
<tr>
<td>beanProperyName/Value</td>
<td>Bean 属性，JMX object name 中冒号后面的键/值；多个之间用<strong>逗号+空格</strong>分割</td>
</tr>
<tr>
<td>keyN</td>
<td>当遇到复合或表格数据的属性时，将该属性的名称添加到此列表中；多级之间用逗号+空格分割；一般很少用到，留空即可</td>
</tr>
<tr>
<td>attrName</td>
<td>属性的名称，即监控指标</td>
</tr>
<tr>
<td>value</td>
<td>属性的指，即监控指标的值，一般很少使用</td>
</tr>
</tbody>
</table>
<p>说明：对于上述各个 part，均支持正则表达式，指标字段(attrName)维度字段(beanProperyName)两个 part 常用正则匹配。</p>
<ul>
<li>pattern 变量引用说明：</li>
</ul>
<p>pattern 参数中的正则匹配的结果支持通过 <code>$</code> 引用，用于 <code>name</code>、<code>value</code>、<code>labels</code> 等参数的自定义，被引用的正则需用括号 <code>()</code> 标识，根据顺序号进行引用。</p>
<p>在上述的 pattern： <code>Catalina&lt;type=ThreadPool, name="(\w+-\w+)-(\d+)"&gt;&lt;&gt;(currentThreadCount|currentThreadsBusy|keepAliveCount|pollerThreadCount|connectionCount):(.*)</code> 中，变量引用含义如下：</p>
<table>
<thead>
<tr>
<th>变量名</th>
<th>代表匹配的字符串</th>
</tr>
</thead>
<tbody>
<tr>
<td>$1</td>
<td><code>(\w+-\w+)</code></td>
</tr>
<tr>
<td>$2</td>
<td><code>(\d+)</code></td>
</tr>
<tr>
<td>$3</td>
<td><code>(currentThreadCount|currentThreadsBusy|keepAliveCount|pollerThreadCount|connectionCount)</code></td>
</tr>
<tr>
<td>$4</td>
<td><code>(.*)</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>请注意，无论是何种配置方式，配置文件都必须严格包含以下属性</strong>。否则监控平台将无法正确地进行指标采集。</p>
</blockquote>
<pre class="codehilite"><code class="language-yaml">username: {{ username }}
password: {{ password }}
jmxUrl: {{ jmx_url }}
ssl: false</code></pre>


<p>结合上述例子，一个完整的 JMX 采集配置如下。将以下配置输入到插件配置页面中即可。</p>
<pre class="codehilite"><code class="language-yaml"># ==== 固定配置开始 ====
username: {{ username }}
password: {{ password }}
jmxUrl: {{ jmx_url }}
ssl: false
# ==== 固定配置结束 ====

# ==== 自定义配置开始 ====
startDelaySeconds: 0
lowercaseOutputName: false
lowercaseOutputLabelNames: false
whitelistObjectNames: [&quot;Catalina:*&quot;, &quot;java.lang:*&quot;]
blacklistObjectNames: [&quot;Catalina:j2eeType=Servlet,*&quot;]

rules:
  - pattern: 'Catalina&lt;type=ThreadPool, name=&quot;(\w+-\w+)-(\d+)&quot;&gt;&lt;&gt;(currentThreadCount|currentThreadsBusy|keepAliveCount|pollerThreadCount|connectionCount):(.*)'
    name: tomcat_threadpool_$3
    value: $4
    valueFactor: 1
    labels:
      port: &quot;$2&quot;
      protocol: &quot;$1&quot;
# ==== 自定义配置结束 ====</code></pre>


<h2 id="_6">定义参数</h2>
<p>JMX 插件不支持自定义参数，均为固定参数，这些固定参数将用于渲染采集配置中形如 <code>{{ username }}</code> 的占位符。各固定参数含义如下：</p>
<ul>
<li>
<p>监听端口：JMX Exporter 启动时监听的 HTTP 端口，注意不是 JMX 端口</p>
</li>
<li>
<p>连接字符串：JMX RMI 的 URL，格式为 <code>service:jmx:rmi:///jndi/rmi://${hostName}:${portNum}/jmxrmi</code>。<code>hostName</code> 为目标服务的主机 IP，<code>portNum</code> 为 JMX 监听的端口号。将替换采集配置中的 <code>{{ jmx_url }}</code></p>
</li>
<li>用户名：若开启了用户认证，则需要输入，否则置空。将替换采集配置中的 <code>{{ username }}</code></li>
<li>密码：若开启了用户认证，则需要输入，否则置空。将替换采集配置中的 <code>{{ passowrd }}</code></li>
</ul>
<h2 id="_7">指标维度</h2>
<p>在插件调试获取到结果后，根据实际需要定义指标和维度。</p>
<h1 id="kafka">Kafka 插件定义示例</h1>
<h2 id="jmx_3">开启 JMX 远程访问功能</h2>
<ol>
<li>导入以下环境变量</li>
</ol>
<pre class="codehilite"><code class="language-bash">export JMX_PORT=9999</code></pre>


<ol>
<li>
<p>启动 kafka</p>
</li>
<li>
<p>使用 JConsole 连接，可观察到已经获取到一系列的 MBean</p>
</li>
</ol>
<p><img alt="image-20200210135541888" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210135541888.png" /></p>
<h2 id="_8">定义配置文件</h2>
<p>例如，需要采集 <code>kafka.server</code> ，<code>type=BrokerTopicMetrics</code>的 MBean。如下图。具体 MBean 的含义信息可以查看 kafka 组件文档： <a href="http://kafka.apache.org/documentation/#remote_jmx">JMX 指标信息</a>。</p>
<p><img alt="image-20200210141212180" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210141212180.png" /></p>
<h3 id="mbean">查看 MBean 详情</h3>
<p>先从 <code>ByteInPerSec</code> 入手，点击查看 MBeanInfo，其中 <code>objectName</code> 和 <code>attrName</code> 需要关注。</p>
<p><img alt="image-20200210142016954" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210142016954.png" /></p>
<h3 id="rules">定义最简化 rules</h3>
<p>假设要获取 <code>MeanRate</code> 这个属性，根据上述 pattern 规则，可以写成以下形式：</p>
<pre class="codehilite"><code class="language-bash">kafka.server&lt;type=BrokerTopicMetrics, name=BytesInPerSec&gt;&lt;&gt;MeanRate</code></pre>


<p><code>objectName</code> 以冒号为分割，可拆分两部分，domain 和 beanPropery，在上述例子中 <code>kafka.server</code> 为 domain，<code>type=BrokerTopicMetrics, name=BytesInPerSec</code> 为 beanPropery。最后面的 <code>MeanRate</code> 则是属性名。请注意，<strong>两个 beanPropery 之间必须使用 逗号 + 空格 进行分割，空格不可缺少</strong>。</p>
<p>最后得出的 rules 配置如下，<code>name</code> 字段作为数据上报的指标名。</p>
<pre class="codehilite"><code class="language-yaml">rules:
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=BytesInPerSec&gt;&lt;&gt;MeanRate
   name: kafka_server_bytesinpersec</code></pre>


<h3 id="_9">在页面上填写完整配置</h3>
<pre class="codehilite"><code class="language-yaml">username: {{ username }}
password: {{ password }}
jmxUrl: {{ jmx_url }}
ssl: false
# 以上内容无需修改，下面为自定义配置
# 配置说明请参考 https://github.com/prometheus/jmx_exporter#configuration
startDelaySeconds: 0
lowercaseOutputName: true
lowercaseOutputLabelNames: true

rules:
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=BytesInPerSec&gt;&lt;&gt;MeanRate
   name: kafka_server_bytesinpersec</code></pre>


<h3 id="_10">进入调试页面</h3>
<p><img alt="image-20200210143511678" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210143511678.png" /></p>
<p>填写相关参数，然后点击“开始调试”，稍等片刻后可查看调试输出。</p>
<p>可查看到包含类似以下的 json 数据，说明配置成功。</p>
<pre class="codehilite"><code class="language-json">{
    &quot;key&quot;:&quot;kafka_server_bytesinpersec&quot;,
    &quot;labels&quot;:{

    },
    &quot;value&quot;:691816711161
}</code></pre>


<h3 id="labels">配置 labels</h3>
<p>除了 <code>MeanRate</code> 外，如果想要在一张图表内同时展示 <code>OneMinuteRate</code>，<code>FiveMinuteRate</code>，<code>FifteenMinuteRate</code>，则需要配置 labels。</p>
<p>根据 pattern 规则，配置如下：</p>
<pre class="codehilite"><code class="language-yaml">rules:
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=BytesInPerSec&gt;&lt;&gt;(MeanRate|OneMinuteRate|FiveMinuteRate|FifteenMinuteRate)
   name: kafka_server_bytesinpersec
   labels:
     type: $1</code></pre>


<p><code>MeanRate|OneMinuteRate|FiveMinuteRate|FifteenMinuteRate</code> 代表匹配以上几个属性，外层使用<code>()</code>，则可以被下面的字段所引用，由于在这个 pattern 只有一组括号，因此 <code>$1</code> 就可以匹配。</p>
<p><code>labels</code> 对应了监控的维度，key-value 分别代表维度名和维度值，在这里<code>type</code>是维度名，<code>$1</code> 是维度值。</p>
<p>调试结果：</p>
<pre class="codehilite"><code class="language-json">[
    {
        &quot;key&quot;:&quot;kafka_server_bytesinpersec&quot;,
        &quot;labels&quot;:{
            &quot;type&quot;:&quot;MeanRate&quot;
        },
        &quot;value&quot;:297575.117976
    },
    {
        &quot;key&quot;:&quot;kafka_server_bytesinpersec&quot;,
        &quot;labels&quot;:{
            &quot;type&quot;:&quot;OneMinuteRate&quot;
        },
        &quot;value&quot;:361639.591095
    },
    {
        &quot;key&quot;:&quot;kafka_server_bytesinpersec&quot;,
        &quot;labels&quot;:{
            &quot;type&quot;:&quot;FiveMinuteRate&quot;
        },
        &quot;value&quot;:312505.738508
    },
    {
        &quot;key&quot;:&quot;kafka_server_bytesinpersec&quot;,
        &quot;labels&quot;:{
            &quot;type&quot;:&quot;FifteenMinuteRate&quot;
        },
        &quot;value&quot;:304602.237208
    }
]</code></pre>


<h3 id="_11">配置更多指标</h3>
<p>继续配置 <code>ByteOutPerSec</code> 等指标，根据上面的例子，直接新增一条 rules 即可。</p>
<pre class="codehilite"><code class="language-yaml">rules:
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=BytesInPerSec&gt;&lt;&gt;(MeanRate|OneMinuteRate|FiveMinuteRate|FifteenMinuteRate)
   name: kafka_server_bytesinpersec
   labels:
     type: $1
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=BytesOutPerSec&gt;&lt;&gt;(MeanRate|OneMinuteRate|FiveMinuteRate|FifteenMinuteRate)
   name: kafka_server_bytesoutpersec
   labels:
     type: $1</code></pre>


<h3 id="pattern">使用 pattern 变量定义指标</h3>
<p>配置了更多的指标后会发现，很多 rule 除了某个字段有区别，其他的都一致，因此可以将存在差异的部分抽象为变量，减少配置成本。</p>
<pre class="codehilite"><code class="language-yaml">rules:
-  pattern: kafka.server&lt;type=BrokerTopicMetrics, name=(\w+)&gt;&lt;&gt;(MeanRate|OneMinuteRate|FiveMinuteRate|FifteenMinuteRate)
   name: kafka_server_$1
   labels:
     type: $2</code></pre>


<h2 id="_12">定义指标</h2>
<p>根据上述配置，可得出以下指标与维度：</p>
<ul>
<li><code>kafka_server_bytesoutpersec</code>： 包含维度 <code>type</code></li>
<li><code>kafka_server_bytesinpersec</code>： 包含维度 <code>type</code></li>
</ul>
<p>维度组合相同的指标，可以将其归到同一个分类，如下图。</p>
<p><img alt="image-20200210161144256" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/image-20200210161144256.png" /></p>
<h2 id="_13">调试并保存插件</h2>
<p>调试并确认数据上报正常后，可进入下一步对插件进行保存。自此，一个 JMX 插件即制作完成。</p>
<h1 id="tomcat">tomcat 插件使用</h1>
<h2 id="manager">添加 manager 角色并设置用户名和密码</h2>
<p>编辑 <code>conf</code> 目录下的 <code>tomcat-user.xml</code> 文件，添加 manager 角色并设置用户名和密码：</p>
<p>配置示例：</p>
<pre class="codehilite"><code class="language-java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;tomcat-users&gt;
&lt;role rolename=&quot;manager-jmx&quot;/&gt;
&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;manager-jmx&quot;/&gt;
&lt;/tomcat-users&gt;</code></pre>


<h2 id="jmx_4">增加 JMX 的启动参数</h2>
<p>编辑  <code>bin/catalina.sh</code> 在 JAVA_OPTS 后面增加。</p>
<pre class="codehilite"><code class="language-java">CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote&quot;
CATALINA_OPTS=&quot;$CATALINA_OPTS -Djava.rmi.server.hostname=127.0.0.1&quot;
CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote.port=9011&quot;
CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote.ssl=false&quot;
CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;</code></pre>


<ul>
<li><code>-Dcom.sun.management.jmxremote</code>： 启用 jmxremote 功能；</li>
<li><code>-Dcom.sun.management.jmxremote.port=9011</code>：jmxremote 监听端口，用于客户端连接，样例设为 9011；</li>
<li><code>-Dcom.sun.management.jmxremote.ssl=false</code>：是否启用 SSL 连接，样例设为 false；</li>
<li><code>-Dcom.sun.management.jmxremote.authenticate=true</code>：开启用户认证连接；</li>
<li><code>-Dcom.sun.management.jmxremote.password.file=/usr/share/tomcat/conf/jmxremote.password</code>：认证用户密码文件，样例设为 <code>/usr/share/tomcat/conf/jmxremote.password</code>；</li>
<li><code>-Dcom.sun.management.jmxremote.access.file=/usr/share/tomcat/conf/jmxremote.access</code>：认证用户权限配置文件，样例设为 <code>/usr/share/tomcat/conf/jmxremote.access</code>。</li>
<li>如果不启用用户认证，将选项 <code>Dcom.sun.management.jmxremote.authenticate</code> 的值设为 false，也无需再设置选项 <code>Dcom.sun.management.jmxremote.password.file</code> 和 <code>Dcom.sun.management.jmxremote.access.file</code>。</li>
</ul>
<h2 id="_14">参数说明</h2>
<table>
<thead>
<tr>
<th>参数名</th>
<th>含义</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>port</td>
<td>Exporter 监听的端口，提供给采集器使用</td>
<td>9110</td>
</tr>
<tr>
<td>username</td>
<td>采集目标认证用户名，没有就为空</td>
<td>test</td>
</tr>
<tr>
<td>password</td>
<td>采集目标认证密码，没有就为空</td>
<td>test123</td>
</tr>
<tr>
<td>jmx_url</td>
<td>采集目标的 jmx 连接字符串</td>
<td>service:jmx:rmi:///jndi/rmi://localhost:9011/jmxrmi</td>
</tr>
</tbody>
</table>
<p>如上配置所示，采集器将会根据你配置的内容，定期在本地访问 localhost:9011 的 tomcat jvm 以获取 Tomcat 的指标数据。</p><h1 id="agent">无 Agent 如何实现监控</h1>
<p>有时因为一些原因目标机器不能安装蓝鲸的 Agent。如：</p>
<ul>
<li>不能使用 root 安装</li>
<li>不允许安装其他 Agent</li>
<li>没有安装权限</li>
</ul>
<p>但是运维依旧要保证其服务的稳定性，要增加监控，监控平台有如下解决方案：</p>
<h2 id="1">方案 1 服务拨测</h2>
<p>服务拨测本身就是模拟用户的请求情况来看服务的状态，通过连通性，response 的内容进行判断。是站在集群整体服务的角度来看问题。 </p>
<p>具体使用查看： <a href="../functions/scene/dial.md">服务拨测功能介绍</a></p>
<h2 id="2">方案 2 自定义上报</h2>
<p>自定义上报可以是自定义时序或者自定义事件上报，可以由服务的自身监控程序或者服务程序本身向监控上报数据。</p>
<p>具体使用查看： <a href="../functions/conf/custom-report.md">自定义上报功能介绍</a></p>
<h2 id="3">方案 3 远程采集插件</h2>
<h3 id="_1">远程插件定义</h3>
<p>当远程暴露的是服务的状态信息时，如 nginx status ，可以制作一个插件，设置为<code>远程插件</code>，就可以具备远程采集的能力。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15769100952860.jpg" /></p>
<h3 id="bk-pull">BK-Pull 定义</h3>
<p>当远程暴露的是 Exporter 的数据格式时，如 pushgayway， 就可以制作一个 bk-pull 的插件来满足数据的拉取能力。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15769101086174.jpg" /></p>
<h3 id="4">方案 4 基于数据平台监控</h3>
<p>可以将数据通过其他手段，或者是数据库同步的手段到数据平台，监控就可以使用数据平台的数据进行监控配置。</p>
<p>具体使用查看： <a href="bigdata_monitor.md">如何基于数据平台的数据进行监控</a></p><h1 id="_1">日志关键字监控</h1>
<p>日志关键字监控指的是通过日志的里面关键字匹配出来的数量进行告警判断是否有问题，是一种比较常见的监控需求。在监控平台有两种日志关键字配置方法。 </p>
<h2 id="_2">前置步骤</h2>
<p>先了解两种日志关键字的工作原理：</p>
<h3 id="_3">第一种：基于日志平台数据的日志关键字</h3>
<p>日志平台的数据不敢是自采集的，第三方 ES 的还是数据平台的最终都是存储在 ES 的存储里面。所以这类数据的日志关键字都是基于 ES 查询语法日志关键。</p>
<ul>
<li>
<p><strong>优点</strong>：日志集中存储，当接到日志关键字告警后可以直接在日志平台进行查询和定位</p>
</li>
<li>
<p><strong>缺点</strong>：如果日志量很大将占用大量的带宽和存储资源。另外就是查询方法是依据分词原理。像 I/O 默认会拆分 I 和 O 来进行匹配</p>
</li>
</ul>
<p>具体配置方法： <a href="log_monitor.md">如何监控日志平台的数据</a></p>
<h3 id="agent">第二种：在 Agent 端进行日志匹配生成事件</h3>
<p>在日志所在的服务器进行日志关键字的匹配，将周期内的统计值和样本数据进行上报。再通过告警策略生成告警事件达到告警的目的。</p>
<ul>
<li><strong>优点</strong>：在日志量很大，存储资源不够的情况下也可以满足日志关键字的需求。匹配方法为正则方式更容易配置和理解。满足及时告警需求不受日志传输的延迟影响</li>
<li><strong>缺点</strong>：只有一条最新的采样数据，如果需要更多信息需要通过其他方式去查看</li>
</ul>
<p>接下来就主要介绍第二种日志关键字事件的配置方法</p>
<h2 id="_4">依赖</h2>
<p>确保采集进程已经启动</p>
<ul>
<li>
<p>Linux</p>
<p><code>bash
ps -ef | grep bkmonitorbeat</code></p>
</li>
<li>
<p>Windows</p>
<p><code>bat
tasklist | findstr bkmonitorbeat</code></p>
</li>
<li>
<p>如果没有，则需要通过<strong>节点管理</strong>应用安装，并托管启动。并且确保是最新的版本。</p>
</li>
</ul>
<h2 id="_5">第一步：配置采集</h2>
<p>导航：监控配置  →  采集  →  新建  →  采集方式(Log)</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15909118691554.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15909118752709.jpg" /></p>
<h3 id="_6">日志路径</h3>
<p>填写轮转的日志绝对路径就可以。如：</p>
<pre class="codehilite"><code class="language-bash">/var/log/nginx/nginx.log </code></pre>


<pre class="codehilite"><code class="language-bash">/var/log/xxxx/error.%Y%m%d.log</code></pre>


<h3 id="_7">维度提取</h3>
<p>关键字不单可以匹配正则还可以从行日志中提取出维度信息，来细化关键字的内容，可以使用正则提取，例如：</p>
<pre class="codehilite"><code class="language-bash">    # 假如我的日志文本是这样的
    &quot;2020-05-22 11:13:16 ERROR    28276   access.data             processor.py[172] strategy(503),item(504) query records error, System Request 'metadata_v3' error&quot;

    # 那么可以填如下正则，匹配上ERROR的同时，将我的代码模块、文件名信息提取出来
    &quot;ERROR[ 0-9]+(?P&lt;module&gt;[a-z\.]+) +(?P&lt;filename&gt;[^\[]+).*&quot;</code></pre>


<h3 id="_8">关键字正则规则</h3>
<p>正则使用的是 Golang 的正则语法，如果是有复杂的需求建议先进行调试得到正确的正则表达式， <a href="https://www.debuggex.com/">在线正则调试地址</a>。</p>
<p>正则参考语法样例：</p>
<pre class="codehilite"><code class="language-bash">([^\s]*)              # 匹配 $http_host
(\d+\.\d+\.\d+\.\d+)  # 匹配 $server_addr,$remote_addr
(\&quot;\d+\.\d+\.\d+\.\d+\,\s\d+\.\d+\.\d+\.\d+\&quot;|\&quot;\d+\.\d+\.\d+\.\d+\&quot;) #匹配 &quot;$http_x_forwarded_for&quot;
(\[[^\[\]]+\])     #匹配[$time_local]
(\&quot;(?:[^&quot;]|\&quot;)+|-\&quot;)  # 匹配&quot;$request&quot;,&quot;$http_referer&quot;，&quot;$http_user_agent&quot;
(\d{3})               # 匹配$status
(\d+|-)               # 匹配$body_bytes_sent
(\d*\.\d*|\-)         # 匹配$request_time,$upstream_response_time'
^                     # 匹配每行数据的开头
$                     # 匹配每行数据的结局</code></pre>


<h2 id="_9">第二步：检查数据</h2>
<p>通过采集下一步选择监控目标后，当前匹配的日志关键字后在“检查视图将看到相关的数据”。</p>
<p>检测视图查看采集数据（配置完后，需要等待 2 分钟左右）。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15909127206617.jpg" /></p>
<h2 id="_10">第三步：配置告警策略</h2>
<p>导航：监控配置  →  策略 →  新建  →  添加日志关键字</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15909129966137.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15909131308756.jpg" /></p>
<p>PS：当没有发现你的采集项时，注意下是不是监控对象选择错误了。</p>
<h2 id="_11">使用建议</h2>
<ul>
<li>单行日志大小：单行太长，会导致正则匹配性能较差，建议 &lt; 1k 字节</li>
<li>日志每秒产生速率：建议 &lt; 5w 每秒</li>
<li>日志文件大小速率：建议 &lt; 50M 每秒</li>
<li>正则数量限制：即页面配置的规则数：建议 &lt; (50M / 实际产生大小速率)每秒<ul>
<li>假如当前机器所有需要监听的日志文件，日志产生速率为 1M/s。则建议规则数 &lt; 50 个</li>
<li>假如当前机器所有需要监听的日志文件，日志产生速率为 2M/s。则建议规则数 &lt; 25 个</li>
</ul>
</li>
<li>正则表达式，尽可能的精确，减少".*"这种用法，提高效率。</li>
</ul>
<p>超过上面限制，会导致处理不过来，队列积压。 每个周期上报的统计数值会不准确。</p><h1 id="_1">自定义上报工具</h1>
<p>自定义上报可以通过命令行工具进行上报， 实现发送自定义事件/自定义时序等自定义数据。</p>
<p>支持通过 gse agent 和 bkmonitorporxy(http 接口)两种方式实现自定义上报， 上报之前会在本地进行 jsonschema 校验。</p>
<h2 id="id">第一步： 申请数据 ID</h2>
<p><strong>导航位置</strong>：导航  →  监控配置  →  自定义上报</p>
<p>选择是指标还是事件。</p>
<h2 id="_2">第二步： 命令行使用方法</h2>
<pre class="codehilite"><code class="language-bash"># 输出帮助信息(实际输出更多，发送自定义数据相关参数带有report关键字)
:!./bkmonitorbeat -h
Usage of ./bkmonitorbeat:
  -report
    Report event to time series to bkmonitorproxy
  -report.agent.address string
    agent ipc address, default /var/run/ipc.state.report (default &quot;/var/run/ipc.state.report&quot;)
  -report.bk_data_id int
    bk_data_id, required
  -report.event.content string
    event content
  -report.event.name string
    event name
  -report.event.target string
    event target
  -report.event.timestamp int
    event timestamp
  -report.http.server string
    http server address, required if report type is http
  -report.http.token string
    token, , required if report type is http
  -report.message.body string
    message content that will be send, json format
  -report.message.kind string
    message kind, event or timeseries
  -report.type http
    report type http or `agent`</code></pre>


<h3 id="_3">使用样例</h3>
<p>基本使用部分提供通用的使用方法，适用于自定义事件和自定义时序数据上报，由于事件内容涉及到较多特殊字符处理，后面单独介绍针对自定义事件的上报方法。
如下代码演示用于发送自定义事件的数据（其中 json 内容来自监控插件配置右侧的帮助信息）。</p>
<pre class="codehilite"><code class="language-bash"># 通过gse agent发送自定义事件， 无返回
./bkmonitorbeat -report -report.bk_data_id 1500512 \
-report.type agent \
-report.message.kind event \
-report.message.body '{
    &quot;data_id&quot;:1500512,
    &quot;access_token&quot;:&quot;991146b7e97b409f8952d59355b5f5c7&quot;,
    &quot;data&quot;:[{
        &quot;event_name&quot;:&quot;input_your_event_name&quot;,
        &quot;target&quot;:&quot;127.0.0.1&quot;,
        &quot;event&quot;:{
            &quot;content&quot;:&quot;user xxx login failed&quot;
        },
        &quot;dimension&quot;:{
            &quot;amodule&quot;:&quot;db&quot;,
            &quot;aset&quot;:&quot;guangdong&quot;
        },
        &quot;metrics&quot;:{
            &quot;field1&quot;:1.1
        },
        &quot;timestamp&quot;:1591067660370
        }
    ]}'

 # 通过http方式发送自定义事件，成功返回code200，result true
./bkmonitorbeat -report -report.bk_data_id 1500512 -report.type http -report.http.server 10.0.1.36:10205 -report.message.kind event -report.message.body '{
    &quot;data_id&quot;:1500512,
    &quot;access_token&quot;:&quot;991146b7e97b409f8952d59355b5f5c7&quot;,
    &quot;data&quot;:[{
        &quot;event_name&quot;:&quot;input_your_event_name&quot;,
        &quot;target&quot;:&quot;127.0.0.1&quot;,
        &quot;event&quot;:{
            &quot;content&quot;:&quot;user xxx login failed&quot;
        },
        &quot;dimension&quot;:{
            &quot;amodule&quot;:&quot;db&quot;,
            &quot;aset&quot;:&quot;guangdong&quot;
        },
        &quot;metrics&quot;:{
            &quot;field1&quot;:1.1
        },
        &quot;timestamp&quot;:1591067660370
        }
    ]}'
{&quot;code&quot;:&quot;200&quot;,&quot;message&quot;:&quot;success&quot;,&quot;request_id&quot;:&quot;4a6b1b1e-0af0-4834-87c5-6443662df7d3&quot;,&quot;result&quot;:&quot;true&quot;}</code></pre>


<h3 id="gse-agent">通过 gse agent 上报自定义事件数据</h3>
<p>本示例采用单独指定各个上报字段的方式，用于解决拼装 json 麻烦的问题。</p>
<pre class="codehilite"><code class="language-bash"># 通过指定各个字段的方式发送自定义事件数据，采用默认时间
./bkmonitorbeat -report \
-report.type agent \
-report.message.kind event \
-report.bk_data_id 1500512 \
-report.event.target 127.0.0.1 \
-report.event.name xxxxxxxxx \
-report.event.target yyyyyyyyy \
-report.event.content zzzzzz</code></pre>


<pre class="codehilite"><code class="language-bash"># 通过指定各个字段的方式发送自定义事件数据，指定上报时间
./bkmonitorbeat -report \
-report.type agent \
-report.message.kind event \
-report.bk_data_id 1500512 \
-report.event.target 127.0.0.1 \
-report.event.name xxxxxxxxx \
-report.event.target yyyyyyyyy \
-report.event.content zzzzzz \
-report.event.timestamp 1595944620000</code></pre>


<h3 id="bkmonitorproxy">通过 bkmonitorproxy 上报自定义事件数据</h3>
<pre class="codehilite"><code class="language-bash">./bkmonitorbeat -report \
-report.type http \
-report.http.server 10.0.1.10:10205 \
-report.http.token 991146b7e97b409f8952d59355b5f5c7 \
-report.message.kind event \
-report.bk_data_id 1500512 \
-report.event.target 127.0.0.1 \
-report.event.name xxxxxxxxx \
-report.event.target yyyyyyyyy \
-report.event.content zzzzzz</code></pre>


<h3 id="_4">效果查看</h3>
<p><strong>导航位置</strong>：导航  →  监控配置  →  自定义上报  →  检查视图</p><h1 id="_1">进程与端口监控</h1>
<p>当前进程和端口的监控依赖 CMDB 的配置，CMDB 配置好后就可以自动采集进程相关的数据和事件。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15782901072262.jpg" /></p>
<blockquote>
<p>注意：CMDB 配置了进程信息后会主动下发到服务器上，监控就是利用该配置进行的进程采集。所以需要确保 CMDB 的配置正确。</p>
</blockquote>
<p><strong>配置步骤</strong>：</p>
<ul>
<li>第一步：配置平台注册进程 &amp; 自动下发进程配置信息</li>
<li>第二步：主机监控查看进程信息</li>
<li>第三步：设定策略</li>
<li>第四步：设定仪表盘</li>
</ul>
<p>接入下来以 druid-broker 进程为例</p>
<h2 id="_3">第一步： 配置平台注册进程</h2>
<p><strong>配置路径</strong>： 导航  →  业务  →  1)业务拓扑  →  2)模块设置  →  4)服务实例设置  →  5)进程设置  →  6)标签设置(可选)</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795785325657.jpg" /></p>
<ul>
<li>
<p>进程信息配置</p>
</li>
<li>
<p>进程别名(必填)：对外显示的服务名，用户自定义，一般与进程实际服务名称对应，会在监控平台-主机监控-主机详情-进程服务中用于区分不同进程</p>
</li>
<li>
<p>进程名(必填)：程序的二进制名称，比如 Kafka 的二进制是 java ，就填写 java</p>
</li>
<li>
<p>启动参数匹配规则(非必填、重点)：实现精确匹配进程的重要规则，主要应用于如 Java 或 Python 等二进制名重复的进程，Agent 端采集器会通过该规则去识别进程 <code>cmdline</code> 符合参数的唯一进程。如果填入的参数不唯一就会识别到多个进程，如果进程二进制名本身唯一，可不填</p>
</li>
<li>
<p>绑定 IP(非必填)：进程实际监听的 IP 地址，可不填，如果填必须是准确对应 IP 的 地址，如 IP 错误，采集器会无法匹配进程导致数据上报异常</p>
</li>
<li>
<p>端口(非必填)：同“绑定 IP”</p>
</li>
<li>
<p>协议(非必填)：同“绑定 IP”</p>
</li>
</ul>
<p>如 durid-broker 这个 java 程序：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795784620319.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795779439325.jpg" /></p>
<p>更多其他进程配置方法请查看<a href="../functions/addenda/process_cases.md">各种进程配置方法</a></p>
<h3 id="_4">服务模版</h3>
<blockquote>
<p>服务实例： 如果进程的端口，路径等信息都是一样的，建议使用服务模版，并且设置服务分类。方便后面的管理工作。如果是端口路径不一致也可以自动添加实现。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795766656745.jpg" /></p>
<p><strong>自动下发</strong>：</p>
<p>在配置平台上对进程的修改，会通过配置平台的事件推送功能自动下发至 Agent 上的 <code>/etc/gse/host/hostid</code> ，监控的进程端口采集器会捕获文件变化，做异常检测，并且将内容更新到采集器中，下发时间预计在 2 分钟内，页面进程端口更新信息在 5 分钟内。</p>
<h2 id="_5">第二步： 主机监控查看进程监控</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795765869730.jpg" /></p>
<ul>
<li>
<p>进程：正常时标绿显示</p>
</li>
<li>
<p>端口：点击进程，正常时标绿显示，端口不存在以红色显示，被占用则是黄色，灰色说明采集器未上报数据，需要按照数据未上报流程检查</p>
</li>
<li>
<p>资源/性能：正常时图表有连续不断的数据</p>
</li>
<li>
<p>检查进程是否精确匹配：</p>
</li>
<li>如果是二进制为 Java 或 Python 的服务，检查进程端口资源是否只上报了配置的进程，如果配置的进程是唯一的，上报进程出现复数，说明精确匹配失败，需要确认匹配参数是否唯一</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795794947955.jpg" /></p>
<h3 id="_6">无数据定位</h3>
<p><strong>配置平台事件推送设置</strong>：</p>
<ul>
<li>修改进程管理信息后，该推送会在 1 分钟内将修改的配置推送到 Agent 端，因此每次修改完进程管理信息后，可到此处确认推送数是否有新增。</li>
</ul>
<p><strong>配置更新确认</strong>：</p>
<pre class="codehilite"><code class="language-bash">    # Linux Agent 配置文件路径
    /var/lib/gse/host/hostid
    # Windows Agent 配置文件路径
    /gse/data/host/hostid
    # 检查文件内容是否相符

    # 确认hostid更新正常后，切换到以下目录检查 processbeat.conf 是否跟随 hostid 更新配置内容
    # Linux
    /usr/local/gse/plugins/etc/processbeat.conf
    # Windows
    C:/gse/plugins/etc/processbeat.conf</code></pre>


<blockquote>
<p>注意：Agent 的安装路径可以进行修改，具体位置可以查看“节点管理”。</p>
</blockquote>
<p><strong>processbeat 的日志查看</strong></p>
<p>如果前面配置都正确，但是依旧没有数据，这个时候就需要打开 processbeat 的 debug 模式查看日志的信息，来进行定位。</p>
<h2 id="_7">第三步： 配置告警策略</h2>
<p>配置一个端口的策略</p>
<p>监控对象选择：主机-进程</p>
<p>添加监控指标：选择系统事件-进程端口</p>
<p>高级选项：设置触发条件 3/5</p>
<p><img alt="进程存活策略截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833975896530.jpg" /></p>
<p>如果监控进程的指标，默认会采集如下进程的指标<a href="../functions/addenda/process-metrics.md">主机-进程-指标</a></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795777521305.jpg" /></p>
<p>告警组：设置一个运维组</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795797350812.jpg" /></p>
<p>监控目标选择：动态-druid_broker</p>
<blockquote>
<p>信息：建议使用动态方式，这样可以随着节点进行动态监控。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15795777925754.jpg" /></p>
<h2 id="_8">第四步： 仪表盘添加视图</h2>
<p>当需要把关注的指标不同进程，不同主机等放置到一起查看的时候，就可以去设置一个仪表盘。</p>
<p>具体查看仪表盘的使用<a href="../functions/report/dashboard.md">仪表盘功能</a></p>
<h2 id="_9">其他</h2>
<p>更多进程相关的采集查看场景 <a href="multi_instance_monitor.md">如何实现多实例采集</a></p><h1 id="_1">如何监控日志平台的数据</h1>
<p>日志是发现问题和定位问题非常有用的一类数据，基本上任何监控对象都有日志，操作系统，进程模块，服务模块等会有相应的日志数据。</p>
<p>有效的使用日志数据不仅可以达到监控的目的也可以满足问题定位的有需求。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15766742025410.jpg" /></p>
<p>日志采集是监听日志文件内容变化进行实时的日志流采集，采集过程中可以进行“日志提取”格式化日志内容。</p>
<p>日志采集和处理基于日志平台服务。可以直接“日志平台”进行采集和配置，也可以直接在监控平台进行。</p>
<p><strong>采集导航路径</strong>：导航  →  监控配置  →  采集  →  日志采集</p>
<p><strong>策略配置导航路径</strong>：导航  →  监控配置  →  策略  →  新建  →  日志关键字/监控项(日志采集)</p>
<p><strong>问题定位导航路径</strong>：导航  →  日志检索</p>
<p><strong>视图配置导航路径</strong>：导航  →  仪表盘  →  新建  →  指标选择(日志采集)</p>
<h2 id="_3">日志采集&amp;字段提取</h2>
<p>具体查看日志平台<a href="../../../日志平台/产品白皮书/functions/manager/collect_log.md">采集接入</a></p>
<h2 id="_4">日志监控策略</h2>
<p>日志监控有两类：</p>
<ol>
<li>日志关键字监控，最常见也是最常用的监控方法</li>
<li>日志时序数据监控，就是将日志转化为时序数据进行监控</li>
</ol>
<h3 id="_5">日志关键字监控</h3>
<blockquote>
<p>注意：当前的日志检索语句是基于 ES 的分词语法。具体查看<a href="../../../日志平台/产品白皮书/functions/addenda/query_string.md">query string</a>。</p>
</blockquote>
<h3 id="_6">日志时序数据监控</h3>
<p>经过字段提取的数据会变进入到监控的指标选择器中。</p>
<ul>
<li>指标：<strong>聚合类型</strong>并且是数值类型的，如 int/long。</li>
<li>维度：<strong>聚合类型</strong>并且为 string 类型的。</li>
</ul>
<blockquote>
<p>注意：当不需要进行监控，也不需要进行整体查询的时候可以使用分词。可以节省存储空间，提高效率。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15799535228554.jpg" /></p>
<p>在监控的指标选择器中将出现两个指标项 <code>code</code>和<code>sendbytes</code>。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15799537658711.jpg" /></p>
<p>其他都会变成维度</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15799539578734.jpg" /></p>
<h2 id="_7">日志视图</h2>
<p>在仪表盘中可以选择日志平台采集的数据进行视图的创建。</p><h1 id="_1">如何监控数据平台的数据</h1>
<blockquote>
<p>仅限企业版</p>
</blockquote>
<p>进入到数据平台的数据一般有如下情况：</p>
<ol>
<li>很多数据是监控无法直接采集和获取到</li>
<li>原始的数据需要进行大量的数据计算</li>
<li>一份数据有多种用途</li>
</ol>
<p>在这种情况下又想增加监控的需求，监控平台平台就可以满足告警的需求。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>配置过程</strong>：</p>
<ol>
<li>数据接入</li>
<li>数据清洗</li>
<li>数据入库</li>
<li>数据计算</li>
<li>告警配置</li>
<li>监控仪表盘</li>
</ol>
<blockquote>
<p>说明：1-4 都是数据平台的功能，5-6 是属于监控平台的功能。本篇文档就是在说明两个平台之间的一些数据关系。</p>
</blockquote>
<h2 id="_3">具体配置方法</h2>
<p>以下具体配置方法介绍以<code>TcaplusAPI</code>统计指标为例。</p>
<h3 id="_4">需求背景</h3>
<p>Tcaplus 是一个平台类服务，希望在 API 调用的代码里面添加运营数据统计，比如：指标为请求数，时延；维度是集群，业务，游戏区，表，机器，进程等</p>
<ul>
<li>Q：为什么不能通过日志或者采集插件主动采集上来？<ul>
<li>一个机器上的进程实例启动是动态变化的，如：游戏的开房</li>
</ul>
</li>
<li>Q：为什么一定要先入数据平台，而不是直接通过监控进行上报？<ul>
<li>因为一个业务采集的数据就有 150 个指标，但用于告警的只有 30 个，其他指标还有运营分析的需求。</li>
<li>数据是海量数据，通过 TCP 进行上报保证海量数据的接入和存储。</li>
</ul>
</li>
</ul>
<p>以下是 Tcaplus 基于 xml 定义的结构化统计指标信息：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816615915057.jpg" /></p>
<ul>
<li>统计指标有三类：<ul>
<li>OverallRunStatus 总体统计数据</li>
<li>AccessStatistic 各接入点统计数据</li>
<li>TableStatistic 表的统计数据</li>
</ul>
</li>
</ul>
<p>api 实例中每 <strong>周期（1min）</strong> 统计好各个指标的值，通过 TCP 上报给 iData。以下是 OverallRunStatus 上报的数据示例（AccessStatistic 跟 TableStatistic 类似，这里取小部分数据来例）：</p>
<pre class="codehilite"><code class="language-html">dataId=17140&amp;tm=1581397544622&amp;dt=1581397544013&amp;
cnt=1&amp;NodeIP=11.51.211.22&amp;rt=1581397544391&amp;
m=5&amp;messageId=11.51.211.22#1912#1581397544354&amp;bid=b_ieg_tcaplusapi|__tablename=OverallRunStatus&amp;
Timestamp=1581397544&amp;Buzid=0&amp;Logid=0&amp;
AppID=70&amp;ZoneID=2&amp;iIP=11.51.211.33&amp;
CalComplexReadAverageLatencyResCount=234&amp;SimpleWriteRespSuccLatencyHighNumPerMin=0&amp;SimpleWriteRespSuccLatencyCustomizedNumPerMin=0&amp;
SimpleWriteTimeoutNumPerMin=0&amp;ReqSucNumPerMin=247&amp;ApiFieldNotExistErrNumPerMin=0&amp;
ComplexReadRespSuccLatencyLowNumPerMin=234&amp;TcapsvrSystemErrNumPerMin=0&amp;WriteRespWarnNumPerMin=0&amp;
ApiConnectTcaproxyCount=4&amp;WriteReqErrNumPerMin=0&amp;ReadRespWarnNumPerMin=0&amp;</code></pre>


<ul>
<li>指标：如 CalComplexReadAverageLatencyResCount  ApiConnectTcaproxyCount</li>
<li>维度信息包括用户自定义：SetID，AppID，ZoneID，ProcessInfo</li>
<li>维度信息包括默认自带：NodeIP，bid，iIP</li>
</ul>
<h3 id="_5">数据接入</h3>
<p>将原始的数据通过 TCP 上报到 iData 之后，先在数据平台创建业务 TcaplusAPI：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816617117290.jpg" /></p>
<p>再在数据平台数据接入数据源(具体接入方法查看数据平台的白皮书)。TcaplusAPI 接入后的数据源：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816617832838.jpg" /></p>
<h3 id="_6">数据清洗</h3>
<p>接下来分别对 TcaplusAPI 的 3 个数据源上报的做数据清洗，数据清洗的目的是将原来文本的内容变成格式化的数据。例如： <strong>OverallRunStatus</strong> 数据清洗：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816618584419.jpg" /></p>
<p>数据清洗的结果数据：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816619194681.jpg" /></p>
<h3 id="_7">数据入库</h3>
<p>然后分别对 TcaplusAPI 的 3 个数据源数据清洗的结果配置数据入库，例如：OverallRunStatus 的数据入库：</p>
<blockquote>
<p>注意：当前监控只支持 MySQL 和 Tspider 的入库数据。Druid 还在适配中。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816619757486.jpg" /></p>
<p>可以查看数据入库详情：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816620239404.jpg" /></p>
<p>检查数据入库结果，看看是否成功入库了：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816620879225.jpg" /></p>
<h3 id="_8">数据计算</h3>
<p>要如何才可以被监控发现指标和维度呢?有两个办法：</p>
<p>第一：清洗表，简单的指标和维度辩识原则： 数据型为指标，字符串型为维度</p>
<blockquote>
<p>注意：如果清洗表设置维度可以满足需求，就可以跳过数据计算环节。
清洗表如果数据有延迟并且需要汇聚就建立使用数据计算
数据索引：数据平台的是否有索引影响是查询效率 </p>
</blockquote>
<p>第二：通过数据计算转换成结果表，默认 group by 的字段为维度 。</p>
<p>数据计算对于一些复杂的计算需求也可以通过数据计算来满足数据汇聚的一些需求。</p>
<p>TcaplusAPI 分别为 3 张原始数据表配置了数据计算任务，计算结果存入结果表，用于后面告警计算。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816621529712.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816622131979.jpg" /></p>
<blockquote>
<p>注意：在窗口示例往下有一个<strong>统计频率</strong> 默认 60 秒，就是数据计算的汇聚周期，该<strong>统计频率</strong>在监控里面的<strong>监控周期</strong>是对应的。</p>
</blockquote>
<pre class="codehilite"><code class="language-SQL">select SetID, AppID, ZoneID, iIP, Pid,
  SUM(ApiMaxOnUpdateIntervalPerMin) as ApiMaxOnUpdateIntervalPerMin,
  SUM(AvailableTcapdirNum) as AvailableTcapdirNum,
  SUM(ApiConnectTcaproxyCount) as ApiConnectTcaproxyCount,
  SUM(ApiConnectTcaproxyErrNumPerMin) as ApiConnectTcaproxyErrNumPerMin,
  SUM(ReqSucNumPerMin) as ReqSucNumPerMin,
  SUM(RespSucNumPerMin) as RespSucNumPerMin,
  SUM(RespWarnNumPerMin) as RespWarnNumPerMin,
  SUM(RespErrNumPerMin) as RespErrNumPerMin,
 from 399_OverallRunStatus_Data
GROUP BY SetID, AppID, ZoneID, iIP, Pid</code></pre>


<p>数据计算后：group by 的字段默认成为维度。如： <code>SetID, AppID, ZoneID, iIP, Pid</code> 会成为维度，其他的 <code>ApiMaxOnUpdateIntervalPerMin,AvailableTcapdirNum</code> 等这些是指标</p>
<blockquote>
<p>注意：注意语法格式，同 MYSQL 的 SQL 一致。</p>
</blockquote>
<p>检查数据计算的结果表有没有数据：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816623104340.jpg" /></p>
<p><strong>注意事项</strong>：</p>
<ol>
<li>dataflow 的数据处理模式选择从<strong>尾部</strong>，可以快速的拿到最新的数据，一旦历史数据过多将很难产生最新的数据，这时当前配置的告警策略可能没有告警，视图没有图表。</li>
<li>注意 SQL 语法格式。</li>
<li>考虑<code>group by</code>维度的选择，像 Time 或者随机的 hash 值，无意义的自增 ID，都不适用于维度。维度是会在告警的通知里面显示的，所以选择有意义的维度是帮助快速定位和视图查看，如 区域，系统这类维度。</li>
<li>不需要考虑原始数据中的时间字段，如上报添加的<code>TimeST</code>字段,在数据计算的时候是以<code>dtEventTime</code>进行周期汇聚和计算等。</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816691186957.jpg" /></p>
<h3 id="_9">告警配置</h3>
<p>打开监控应用</p>
<p>在以下路径配置告警：导航  →  监控配置  →  策略  →  新建，先配置要告警的指标项：</p>
<ul>
<li>监控对象：选择其他</li>
<li>添加监控指标，并在数据平台中选择对应的结果表数据和指标项</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816692057602.jpg" /></p>
<blockquote>
<p>注意：监控识别指标维度是两种途径：
第一：清洗表设置维度，long 类型会出现在指标列表，其他出现在维度列表
第二：通过数据计算转换成结果表，默认 group by 的字段为维度</p>
</blockquote>
<p>更多操作查看<a href="../functions/conf/rules.md">策略配置功能介绍</a></p>
<p>配置好告警策略，告警计算符合策略后会产生告警事件，更多查看<a href="../functions/analyze/event.md">事件中心功能介绍</a></p>
<p>产生告警消息：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15816844773497.jpg" /></p>
<h3 id="_10">监控的仪表盘视图</h3>
<p>通过计算后的结果表数据在监控仪表盘也可以进行图表的展示。</p>
<p>更多查看<a href="../functions/report/new_dashboard.md">仪盘表功能介绍</a></p><h1 id="_1">如何添加新的通知渠道</h1>
<p>通知渠道使用 PaaS 的通知 ESB 组件，在蓝鲸的独立部署版本（企业版、社区版）需要在开发者中心后台设置。</p>
<h2 id="esb">在通知 ESB 组件中配置通知渠道</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/media/15366583245319.jpg" />
<center>蓝鲸集成平台（PaaS）的消息管理通知设置</center></p>
<p>详细设置请访问蓝鲸 PaaS 提供的设置文档</p>
<ul>
<li><a href="../../../PaaS平台/产品白皮书/场景案例/noticeWay.md">如何配置通知渠道，如邮件、微信、短信等?</a></li>
<li><a href="http://bk.tencent.com/s-mart/community/question/95#/">经验分享-测试邮件服务是否正常</a></li>
</ul>
<h2 id="_2">在全局配置中确定通知方法</h2>
<p>在监控中确认消息通知的渠道。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/16051505458005.jpg" /></p>
<h2 id="_3">告警通知设置入口</h2>
<p>全局配置影响通知方式的选择这块。通过告警组的配置可以满足策略的告警。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15773279204886.jpg" /></p>
<h2 id="_4">微信注意开通事项</h2>
<p>当微信没有接受到告警的时候，注意查看是否已经开启。</p>
<p><img alt="WeChatWorkScreenshot" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/WeChatWorkScreenshot_dfed1d6a-63d0-48bd-8dc4-f9d59d677cb4.png" /></p><h1 id="_1">如何自定义通知模版</h1>
<h2 id="_2">告警通知模版设置位置</h2>
<p>在策略配置中，我们可以在<strong>高级选项</strong>  -&gt;  <strong>告警通知模板</strong>中配置当这条策略被触发后发出的通知内容的<strong>可自定义</strong>部分。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15809932187482.jpg" /></p>
<p>监控平台提供了一份默认的告警通知模板，它能在不同的通知中显示不同的样式，可以使用<strong>模板预览</strong>功能看看它们会被渲染成什么样。当然，模板预览功能只是提供了一些<strong>示例数据</strong>，真正的效果需要考虑实际情况。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15809932675311.jpg" /></p>
<h2 id="_3">模板语法说明</h2>
<p>由于发送类型有文本、邮件、语音等多种形式，为了方便用户定义出在不同通知渠道都能正常显示的通知模板，监控平台提供了一种行模板语法。</p>
<pre class="codehilite"><code class="language-bash">#label#content</code></pre>


<p>必须由#号开头，分为标签和内容两部分，由#号分隔。不符合行模板的内容将会当成普通文本进行显示。</p>
<p>为了保证邮件内容的正常显示，建议用户自定义的通知模板都使用行模板语法。</p>
<h3 id="_4">模板变量</h3>
<p>关于本次告警通知的相关信息以模板变量的形式提供，可以在模板变量中直接引用，它们会在通知时被渲染对应的信息。</p>
<p>可以通过<strong>变量列表</strong>查看有哪些能用的变量。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15809934446872.jpg" /></p>
<p><strong>CMDB 变量</strong>：部分变量仅在监控对象为主机、进程、服务实例等时才能成功取值，如果取值失败则会返回空值。</p>
<p><strong>内容变量</strong>：供默认模板使用内置变量，会在不同的通知方式中显示不同的值，不需要添加行模板。</p>
<p><strong>告警变量</strong>：告警内容相关信息。</p>
<p><strong>策略变量</strong>：产生本次告警的策略相关的信息。</p>
<h2 id="_5">配置示例</h2>
<p>只需要使用行模板加模板变量，就可以配置出个性化的通知模板。</p>
<h3 id="_6">示例一： 更改顺序符合阅读习惯</h3>
<p>调整默认通知模板的变量顺序，需要注意的是，content 中的部分变量只在特定通知方式中显示。</p>
<p>{{content.content}}变量被我挪到了下面。</p>
<pre class="codehilite"><code class="language-html">{{content.level}}
{{content.time}}
{{content.duration}}
{{content.target_type}}
{{content.data_source}}
{{content.current_value}}
{{content.biz}}
{{content.target}}
{{content.dimension}}
{{content.content}}
{{content.detail}}</code></pre>


<p>微信</p>
<pre class="codehilite"><code class="language-bash">[致命] 磁盘使用率
时间: 1970-01-01 00:00:00
目标: 蓝鲸[2] 127.0.0.1，127.0.0.2 (2)
维度: 磁盘=C
内容: 已持续10分钟， sum(in_user) &gt; 10
详情: http://example.com/</code></pre>


<p>短信</p>
<pre class="codehilite"><code class="language-bash">监控通知，[致命]磁盘使用率
目标: 蓝鲸[2] 127.0.0.1，127.0.0.2 (2)
维度: 磁盘=C
内容: 已持续10分钟， sum(in_user) &gt; 10
告警ID: 12345</code></pre>


<h3 id="_7">示例二：裁减多余的内容</h3>
<p>删除不需要的信息，精简通知内容。</p>
<pre class="codehilite"><code class="language-html">{{content.time}}
{{content.content}}
{{content.detail}}</code></pre>


<p>微信</p>
<pre class="codehilite"><code class="language-bash">[致命] 磁盘使用率
时间: 1970-01-01 00:00:00
内容: 已持续10分钟， sum(in_user) &gt; 10
详情: http://example.com/</code></pre>


<p>短信</p>
<pre class="codehilite"><code class="language-bash">监控通知，[致命]磁盘使用率
内容: 已持续10分钟， sum(in_user) &gt; 10
告警ID: 12345</code></pre>


<h3 id="_8">示例三： 增加相关主机的信息</h3>
<p>通过变量可以获取主机的相关信息。</p>
<pre class="codehilite"><code class="language-html">{{content.time}}
{{content.content}}
#操作系统#{{target.host.bk_os_name}}
{{content.detail}}</code></pre>


<p>微信</p>
<pre class="codehilite"><code class="language-bash">[致命] 磁盘使用率
时间: 1970-01-01 00:00:00
内容: 已持续10分钟， sum(in_user) &gt; 10
操作系统: linux centos
详情: http://example.com/</code></pre>


<p>短信</p>
<pre class="codehilite"><code class="language-bash">监控通知，[致命]磁盘使用率
内容: 已持续10分钟， sum(in_user) &gt; 10
操作系统: linux centos
告警ID: 12345</code></pre>


<h3 id="url">示例四： 通知内容生成特定的一个 URL 链接</h3>
<p>告警内容中生成一个 URL，点击即可访问指定内容。</p>
<pre class="codehilite"><code class="language-html">{{content.time}}
{{content.content}}
{{content.detail}}
#xx系统#http://xxxx.demo.com?control=3&amp;host={{target.host.bk_host_innerip}}</code></pre>


<p>微信</p>
<pre class="codehilite"><code class="language-bash">[致命]
时间: 1970-01-01 00:00:00
内容: 已持续10分钟， sum(in_user) &gt; 10
详情: http://example.com/
xx系统: http://xxxx.demo.com?control=3&amp;host=127.0.0.1</code></pre>


<p>短信</p>
<pre class="codehilite"><code class="language-bash">监控通知，[致命]
内容: 已持续10分钟， sum(in_user) &gt; 10
告警ID: 12345
xx系统: http://xxxx.demo.com?control=3&amp;host=127.0.0.1</code></pre>


<h3 id="_9">示例五： 关键字监控增加原始的日志内容</h3>
<p>待完善</p><h1 id="_1">如何设置告警回调</h1>
<p>为了方便其他应用接入告警消息，告警通知提供回调功能，用户可以在告警组中注册一个回调地址，每次告警通知都会调用这个地址，发送相应通知消息。</p>
<h2 id="_2">功能说明</h2>
<h3 id="_3">设置入口</h3>
<p>位置：导航  →  监控配置  →  告警组  →  回调地址</p>
<p><img alt="告警组设置截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15833979854386.jpg" /></p>
<h3 id="_4">回调确认</h3>
<p>为了保证接收方接收到了通知消息，我们要求请求的返回值是 200，否则认为请求失败。</p>
<h3 id="_5">消息重试</h3>
<p>为了接收方不会因为短暂的网络波动而收不到消息，我们有重试机制。有两次重试的机会，每次的时间间隔加大。</p>
<ol>
<li>第一次请求失败后，隔 5 秒重试</li>
<li>第二次请求失败后，隔 10 秒重试</li>
<li>第三次请求失败后，不再重试</li>
</ol>
<h3 id="_6">超时</h3>
<p>为了保证不会因为接收方的异常而导致回调处理进程被阻塞，回调请求显示了请求时间，超时请求一律认为请求失败。</p>
<p>超时时间由全局变量 <strong>Webhook 超时时间</strong> 控制，默认为 3 秒。</p>
<h3 id="_7">回调消息</h3>
<p>POST 消息</p>
<pre class="codehilite"><code class="language-json">{
  &quot;bk_biz_id&quot;: 2, # 业务ID
  &quot;bk_biz_name&quot;: &quot;蓝鲸&quot;, # 业务名称
  &quot;latest_anomaly_record&quot;:{ # 最新异常点信息
    &quot;origin_alarm&quot;:{
      &quot;anomaly&quot;:{ # 异常信息
        &quot;1&quot;:{ # 告警级别
          &quot;anomaly_message&quot;:&quot;avg(使用率) &gt;= 0.0, 当前值46.17&quot;, # 异常消息
          &quot;anomaly_time&quot;:&quot;2020-03-03 04:10:02&quot;, # 异常产生事件
          &quot;anomaly_id&quot;:&quot;48af047a4251b9f49b7cdbc66579c23a.1583208540.144.147.1&quot; # 异常数据ID
        }
      },
      &quot;data&quot;:{ # 数据信息
        &quot;record_id&quot;:&quot;48af047a4251b9f49b7cdbc66579c23a.1583208540&quot;, # 数据ID
        &quot;values&quot;:{  # 数据值
          &quot;usage&quot;:46.17,
          &quot;time&quot;:1583208540
        },
        &quot;dimensions&quot;:{ # 数据维度
          &quot;bk_topo_node&quot;:[
            &quot;module|6&quot;
          ],
          &quot;bk_target_ip&quot;:&quot;10.0.1.10&quot;,
          &quot;bk_target_cloud_id&quot;:&quot;0&quot;
        },
        &quot;value&quot;:46.17,  # 指标值
        &quot;time&quot;:1583208540 # 时间
      }
    },
    &quot;create_time&quot;:&quot;2020-03-03 04:10:02&quot;, # 产生事件
    &quot;source_time&quot;:&quot;2020-03-03 04:09:00&quot;, # 数据事件
    &quot;anomaly_id&quot;:6211913 # 异常ID
  },
  &quot;type&quot;:&quot;ANOMALY_NOTICE&quot;, # 通知类型 ANOMALY_NOTICE异常通知，RECOVERY_NOTICE恢复通知
  &quot;event&quot;:{ # 事件信息
    &quot;create_time&quot;:&quot;2020-03-03 03:09:54&quot;, # 产生时间
    &quot;end_time&quot;:&quot;2020-03-03 04:19:00&quot;, # 结束时间
    &quot;begin_time&quot;:&quot;2020-03-03 03:08:00&quot;, # 开始时间
    &quot;event_id&quot;:&quot;48af047a4251b9f49b7cdbc66579c23a.1583204880.144.147.1&quot;,
    &quot;level&quot;:1, # 告警级别
    &quot;level_name&quot;: &quot;致命&quot;, # 级别名称
    &quot;id&quot;:8817 # 事件ID
  },
  &quot;strategy&quot;:{
        &quot;item_list&quot;:[
            {
                &quot;metric_field_name&quot;:&quot;使用率&quot;, # 指标名称
                &quot;metric_field&quot;:&quot;usage&quot; # 指标
            }
        ],
        &quot;id&quot;:144, # 策略ID
        &quot;name&quot;:&quot;测试策略&quot; # 策略名称
    }
}</code></pre><h1 id="_1">导航说明</h1>
<p>简单了解下导航的功能说明，能够快速的了解监控平台的功能分布。</p>
<h2 id="_2">基本功能</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/media/16046485032608.jpg" /></p>
<ul>
<li>标号 1) 业务下拉选择，获取有权限的列表，CMDB 中有权限的业务。</li>
<li>标号 2)<ul>
<li>产品文档地址：本白皮书的文档</li>
<li>版本日志：可以查看到每个版本迭代的说明</li>
<li>问题反馈：对于监控的问题或者需求可以快速的进行反馈。</li>
</ul>
</li>
<li>标号 3) 导航的固定方式</li>
</ul>
<h3 id="_3">报表视图</h3>
<p>主要是通过视图和报表的呈现方式来解决日常的<strong>巡检</strong>和潜在问题发现的途径。未来还会增加告警报表，事件报表等能力。</p>
<ul>
<li><a href="report/home.md">首页</a>：展示本业务的统计信息，监控配置情况，快速了解需要处理的事项</li>
<li><a href="report/dashboard.md">仪表盘</a>：通过指标生成视图，替换自定义监控的场景</li>
</ul>
<h3 id="_4">监控场景</h3>
<p>基于不同场景会订制出不同的场景信息和视角来帮助在这个场景下的用户可以快速的掌握相应的信息。未来可以扩展更多的场景，如网络，硬件，容器等。</p>
<ul>
<li><a href="scene/host-monitor.md">主机监控</a>：查看主机和进程相关信息的场景</li>
<li><a href="scene/dial.md">服务拨测</a>：通过远程拨测服务判断服务是否正常。提供在这个场景在的各种视角和信息<ul>
<li>拨测任务：服务拨测任务的管理</li>
<li>拨测节点：服务拨测需要的源节点设置</li>
</ul>
</li>
</ul>
<h3 id="_5">分析定位</h3>
<p>在收到告警后进行一个快速的问题定位，将提供各种定位工具，如事件、日志的检索，还会有数据检索，trace 链路，应用拓扑等。</p>
<ul>
<li><a href="analyze/event.md">事件中心</a>：记录所有的告警事件和告警通知的内容，可以进行告警详情的查看和处理，如告警确认和告警的事件屏蔽</li>
<li><a href="analyze/data-search.md">数据检索</a>：查看采集的日志原始内容</li>
</ul>
<h3 id="_6">监控配置</h3>
<p>所有和监控配置相关的内容都是在监控配置中定义，报表视图，监控场景和分析定位都是查看类不存在监控配置的修改。</p>
<ul>
<li><a href="conf/plugins.md">插件制作</a>：所有的采集配置都需要先定义插件(除了内置插件 如日志)，插件包含内置插件和自定义插件， 业务私有插件和公共插件，插件的本地采集和远程采集模式，支持不同的操作系统</li>
<li><a href="conf/collect-tasks.md">采集任务</a>：所有的采集时序和日志类都是从采集来实现目标机器的采集过程。满足动态和静态的采集</li>
<li><a href="conf/rules.md">告警策略</a>：所有监控策略的配置入口，可以配置监控采集的时序数据，系统事件数据，自定义上报的事件和时序数据，数据平台接入，日志关键字监控等。有相应的算法支撑</li>
<li><a href="conf/alarm-group.md">告警组</a>：设置常用的一组人和通知方式</li>
<li><a href="conf/block.md">告警屏蔽</a>：屏蔽告警通知， 有基于范围屏蔽，基于策略，基于事件屏蔽</li>
<li><a href="conf/service-class.md">分类管理</a>：CMDB 的服务模块分类，基于服务分类来管理数据内容</li>
<li><a href="conf/import-export.md">配置导入导出</a>：批量的进行配置的导入和导出操作</li>
<li><a href="conf/custom-report.md">自定义上报</a>：支持自定义事件和自定义时序数据的上报设置</li>
</ul>
<h3 id="_7">平台配置</h3>
<p>是影响整个监控平台的配置，也可以看到平台的运行状况。</p>
<ul>
<li><a href="global/admin-config.md">全局配置</a>：监控系统的全局开关，如数据的保存周期，水印开关，消息队列设置等</li>
<li><a href="global/self-monitor.md">自监控</a>：监控平台自身的运行状态信息： 存活状态，运行状态，业务运营信息等</li>
</ul><h1 id="_1">首页</h1>
<p>进入监控后默认的页面，展示整体的业务状况和当前急需关注的事项。 可以理解首页是一个简单的报表统计。</p>
<h2 id="_2">前置步骤</h2>
<p>在还未使用监控的功能，或者在 CMDB 未导入任何主机的情况下。首页的数据都是空的或者是样例数据。</p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>未恢复告警分布</li>
<li>监控状态总览</li>
<li>实时告警事件</li>
<li>告警类型分布</li>
<li>主机性能状态分布</li>
<li>拨测可用率</li>
</ul>
<h2 id="_4">功能说明</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15754445566825.jpg" /></p>
<ul>
<li><strong>未恢复告警分布</strong>：快速查看当前业务未恢复的告警。</li>
<li><strong>业务监控状态总览</strong>：展示主机，进程，服务，拨测四个层级的监控状况。如果有告警将显示告警的内容，如果没有配置监控将显示配置方法。</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15755441928170.jpg" /></p>
<ul>
<li><strong>实时告警事件</strong>：刷新最近的 6 条告警事件。</li>
<li><strong>告警类型触发次数分布图</strong>：简单的一个统计来发现当前告警的分布情况。</li>
<li><strong>主机核心指标负载占比</strong>：对所有管理的主机有一个整体的统计。 80%~0%从黄绿色(代表健康但频临危险区)渐变到红色。 如果变红了就需要关注下整体的主机资源状况了。</li>
<li><strong>拨测站点可用率趋势对比</strong>：默认展示最近的 5 条拨测任务，可以设置关心的拨测任务。</li>
</ul><h1 id="_1">新仪表盘</h1>
<p>新仪表盘非常的灵活，意味着也有很多实用的功能，接下来一一介绍这些功能。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909151125720.jpg" /></p>
<h3 id="_2">新建视图和分组</h3>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909151841007.jpg" /></p>
<ol>
<li>新建视图，可以先选数据也可以先选图</li>
<li>如果想实现分组，使用 Convert to row 就可以实现类似的分组功能</li>
</ol>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909152553607.jpg" /></p>
<h3 id="_3">视图种类</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909152982065.jpg" /></p>
<h3 id="query">Query 数据面板说明</h3>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909154784863.jpg" /></p>
<ul>
<li>监控对象：数据的分类，当找不到你的数据时可能是监控对象选错了</li>
<li>指标选择：选择正确的指标</li>
<li>汇聚方法：当一个汇聚周期内有多个数据点时，这个时候要注意选择汇聚方法。当采集的数据是 1 分钟，汇聚周期也是 1 分钟时，并且数据点也只有一个，那么汇聚方法不论是 SUM MAX MIN 其实都是一样的</li>
<li>维度：类似 Group by </li>
<li>条件：类似 Where 用于过滤数据</li>
<li>目标选择：是快捷的 IP/实例选择方法</li>
<li>功能：里面包含 排序(top bottom)，还有时间偏移用于时间对比数据</li>
<li>别名：一般默认的示例名称都很长，那么就可以好好利用别名功能让图表更好看</li>
</ul>
<h3 id="_4">别名功能</h3>
<p>别名语法：以<code>$</code>开头，<code>$表头_字段名</code></p>
<p>比如：指标 id. 表头为<code>metric</code> ， 字段名为<code>id</code> . 所以整个变量为： <code>$metric_id</code> 如果是要显示指标名就是. <code>$metric_name</code></p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909158599688.jpg" /></p>
<p>比如：维度名 . 表头为<code>tag</code>，字段名为<code>device_name</code>，所以整个变量为：<code>$tag_device_name</code> 。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909159867716.jpg" /></p>
<h3 id="top-bottom">TOP 或 Bottom 功能</h3>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909161037141.jpg" /></p>
<p>使用功能里面有 TOP 和 Bottom 设置一个 limit 的数字就可以实现 TOP 的数据查询。</p>
<h3 id="_5">时间对比</h3>
<p>与过去某天数据对比，就可以使用时间偏移功能。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909162545529.jpg" /></p>
<p>时间格式：</p>
<table>
<thead>
<tr>
<th>key</th>
<th>shorthand</th>
</tr>
</thead>
<tbody>
<tr>
<td>years</td>
<td>y</td>
</tr>
<tr>
<td>quarters</td>
<td>Q</td>
</tr>
<tr>
<td>months</td>
<td>M</td>
</tr>
<tr>
<td>weeks</td>
<td>w</td>
</tr>
<tr>
<td>days</td>
<td>d</td>
</tr>
<tr>
<td>hours</td>
<td>h</td>
</tr>
<tr>
<td>minutes</td>
<td>m</td>
</tr>
<tr>
<td>seconds</td>
<td>s</td>
</tr>
</tbody>
</table>
<p>如：<code>1d 1day 1days</code></p>
<h3 id="_6">变量功能</h3>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909166728713.jpg" /></p>
<p>在仪表盘的设置里面有一个变量功能，设置了变量再配合查询的条件就可以实例变量的联动效果。接下来配置一个集群模块对应的主机查询为例。</p>
<h4 id="_7">配置集群和模块的联动变量</h4>
<p>先配置集群<code>cluster</code>。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909167828079.jpg" /></p>
<p>再配置模块<code>module</code>，模块里面的查询条件以集群 ID 做为条件。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909168115182.jpg" /></p>
<h4 id="_8">配置主机</h4>
<p>设置变量<code>host</code>。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909169050479.jpg" /></p>
<p>可以开启多主机选择和 all 条件 </p>
<p>就可以看到如下的效果。</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909169503835.jpg" /></p>
<h4 id="_9">配置查询条件关联</h4>
<p>在条件里面使用 host 变量，就可以达到联动查询的效果</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909170041853.jpg" /></p>
<h3 id="_10">数据下钻</h3>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909170724714.jpg" /></p>
<p>如该图配置了数据下钻，点击了该 IP 通过“主机详情”就可以跳转到主机监控对应的页面。</p>
<p>配置方法：在视图配置里面，使用<code>Add link</code>功能，在 URL 里面使用相关变量</p>
<p><img alt="-w2020" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/report/media/15909171979647.jpg" /></p><h1 id="_1">主机监控</h1>
<p>主机监控是专门为查看主机和进程相关信息订制的一个场景，这个场景里面可以快速的获取到主机相关的信息。</p>
<h2 id="_2">前置步骤</h2>
<p>当该业务下的 CMDB 没有主机的时候，主机监控的数据是空的。 所以先要学会如何在 CMDB 里面添加主机和增加进程信息，服务实例信息等。</p>
<ul>
<li><a href="../../../../配置平台/产品白皮书/快速入门/case1.md">如何创建业务并导入主机到业务中</a></li>
<li><a href="../../../../配置平台/产品白皮书/场景案例/CMDB_management_process.md">CMDB 如何管理进程和服务实例</a></li>
</ul>
<p><strong>工作原理</strong>：</p>
<p>操作系统的指标采集流程</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/16046499751434.jpg" /></p>
<p>进程信息采集流程</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/16046499586323.jpg" /></p>
<p>系统事件采集流程</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/16046500239629.jpg" /></p>
<blockquote>
<p>信息：系统事件，指监控默认采集的操作系统事件。</p>
</blockquote>
<p><strong>主配置流程</strong>：</p>
<ul>
<li>(1) 配置平台增加机器，配置业务拓扑和进程信息</li>
<li>(2) 下发采集配置(自动)</li>
<li>(3) 主机监控页面查看是否有数据上报</li>
</ul>
<h2 id="_3">主功能一览</h2>
<ul>
<li>主机信息概览</li>
<li>主机视角(操作系统指标)</li>
<li>进程视角(进程指标)</li>
<li>产生系统事件</li>
</ul>
<h2 id="_4">功能说明</h2>
<h3 id="_5">主机列表页</h3>
<p><img alt="image-20210421150136059" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/image-20210421150136059.png" /></p>
<ul>
<li>【1】<strong>基本的汇总信息</strong>：告警未恢复的主机数量，CPU 使用率超 80%的数量，应用内存使用率超 80%的主机数量，磁盘 IO 超 80%的主机数量</li>
<li>【2】<ul>
<li><strong>采集下发</strong>：对于 Agent 未安装的需要从节点管理或 CMDB 先安装 Agent，如果『无数据上报』情况可以使用采集下发按钮来触发采集器的下发和安装。</li>
<li><strong>指标对比</strong>：选择不同的主机快速对比相同的指标。</li>
<li><strong>复制 IP</strong>：可以批量复制 IP，复制的 IP 也可以在搜索条件里面使用格式是保持一致的。</li>
</ul>
</li>
<li>【3】搜索条件和字段选择： 有多种搜索条件可以使用。</li>
</ul>
<blockquote>
<p>注意：想要通过业务拓扑来查主机么？在搜索里面选择集群模块可以达到按业务拓扑查询的效果。</p>
</blockquote>
<ul>
<li>【4】<strong>置顶功能</strong>：可以将自己关注主机进行置顶，后面的排序也是在置顶内的排序。</li>
<li>【5】<strong>采集状态</strong>：有如下几种状态：<ul>
<li>正常 ：数据采集正常</li>
<li>Agent 未安装： Agent 都没有就更不会有数据了，可以在 CMDB 和节点管理上安装好 Agent 监控的采集功能才可以使用。</li>
<li>未知：判断不了的状态，就要联系管理员了。较少看到</li>
<li>无数据上报：代表 Agent 安装了，可能 basereport 未安装或者异常，可以尝试再『采集下发』来重新安装主机-操作系统的默认采集器安装。</li>
</ul>
</li>
<li>【6】<strong>未恢复告警</strong>：未恢复告警是当前事件中心中未恢复的相关主机的告警事件。</li>
<li>【7】<strong>应用内存使用率</strong>：除了内存使用率，还有其他的字段可以选择</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15761393519097.jpg" /></p>
<ul>
<li>【8】<strong>进程信息</strong>：在 CMDB 里面配置的进程名称及简单的一个状态，红色代表的是有异常，点击进入可以查看。</li>
</ul>
<h4 id="_6">场景一： 查看某个集群下的机器磁盘空间使用情况进行排序</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15840812567108.jpg" /></p>
<h4 id="_7">场景二： 主机的监控指标对比</h4>
<p><img alt="image-20210421150429200" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/image-20210421150429200.png" /></p>
<h3 id="_8">主机详情页</h3>
<p><img alt="大图-数据对比-搜索-排序-分组" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/%E5%A4%A7%E5%9B%BE-%E6%95%B0%E6%8D%AE%E5%AF%B9%E6%AF%94-%E6%90%9C%E7%B4%A2-%E6%8E%92%E5%BA%8F-%E5%88%86%E7%BB%84.gif" /></p>
<ul>
<li>【1】<strong>主机视角</strong>：主要是查看主机-操作系统层面的指标。如 CPU MEM DISK 等。 详情查看 <a href="../addenda/host-metrics.md">主机-操作系统-指标</a></li>
<li>【2】<strong>进程视角</strong>：主要是查看进程层面的指标。详情查看<a href="../addenda/process-metrics.md">主机-进程-指标</a></li>
<li>【3】<strong>视图控制</strong>：主机场景的视图都相对比较简单，主要是满足开箱即用的需求，如果要做复杂的图表可以直接收藏到仪表盘中。</li>
<li>【4】<strong>关联信息</strong>：主机相关的信息，关联的告警事件和策略信息。</li>
<li>【5】<strong>进程监控配置指标</strong>：因为进程监控依赖 CMDB 的进程配置信息，所以需要熟悉 <a href="../../../../配置平台/产品白皮书/场景案例/CMDB_management_process.md">CMDB 如何管理进程</a></li>
</ul>
<h3 id="_9">高级</h3>
<p>basereport 采集器除了操作系统的指标和进程的指标采集，还会上报系统事件，当前内置 7 种系统事件 <a href="../addenda/host-events.md">主机-操作系统-系统事件</a></p>
<p><img alt="image-20210421150618223" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/image-20210421150618223.png" /></p><h1 id="_1">服务拨测</h1>
<p>服务拨测是探测服务（应用）可用性的监控方式，通过拨测节点对目标服务进行周期性探测，主要通过可用性和响应时间来度量服务（应用）的状态。</p>
<p>服务拨测通过模拟用户的登陆/查询，实现从被动投诉到主动发现的运维方式转变，当前支持的拨测协议有 HTTP(包含 HTTPS，GET 和 POST 方法）、TCP、UDP。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15769111230760.jpg" /></p>
<ul>
<li><strong>Remote Object 远程监控对象</strong>： 可以是 HTTP(s)，TCP，UDP，ICMP</li>
<li><strong>拨测节点</strong>： 也就是 bkmonitorbeat 部署的位置， 就是要设置探测的源头，多个不同的位置节点检测同一个目标更能体现服务在地域上面的可用性。</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15754459844425.jpg" /></p>
<p><strong>配置主流程</strong>：</p>
<ul>
<li>(1) 配置拨测节点</li>
<li>(2) 新建拨测任务</li>
<li>(3) 选择协议</li>
<li>(4) 填写目标地址</li>
<li>(5) 设置策略</li>
<li>(6) 查看拨测任务</li>
</ul>
<h2 id="_3">主功能一览</h2>
<ul>
<li>拨测节点和拨测任务管理</li>
<li>批量拨测任务导入</li>
<li>支持的协议：TCP、UDP、HTTP(s)，ICMP</li>
<li>支持目标：CMDB 的主机、 外网 IP 、域名</li>
<li>衡量服务的指标：可用率、响应时间、期望响应码、期望响应内容<ul>
<li>可用率：一个拨测周期内，正常的节点数/总拨测节点数 * 100% (正常判断条件： 预期返回状态码，预期返回内容，超时时间)</li>
<li>响应时间：请求耗时，超时设置</li>
<li>期望响应码：200 3xx 4xx 5xx</li>
<li>期望响应内容：响应的内容是否匹配</li>
</ul>
</li>
<li>支持的图表类型：趋势图、地图</li>
<li>其他：支持导入、任务分组</li>
</ul>
<h2 id="_4">功能说明</h2>
<h3 id="_5">新建拨测节点</h3>
<p>当没有现成可用的拨测节点时，需要先进行拨测节点的创建才可以添加拨测任务。</p>
<p><strong>功能位置</strong>：导航  →  服务拨测  →  节点  →  新建拨测节点</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15771084983223.jpg" /></p>
<ul>
<li>【1】管理员可以设置为公共的节点，其他业务都可以查看，默认是只有本业务可以使用。</li>
<li>【2】默认是自建节点，未来可支持云拨测节点。</li>
<li>【3】如果是自建节点，选择的 IP 信息会同步配置平台的地区和运营商。</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15771090963329.jpg" /></p>
<blockquote>
<p>注意：当然在配置平台没有配置也是可以自定义的，但建议这类信息可以在 CMDB 维护好有利于其他 SaaS 的使用。</p>
</blockquote>
<h3 id="_6">拨测任务查看模式</h3>
<p><strong>功能位置</strong>：导航  →  服务拨测  →  任务</p>
<ul>
<li>默认为卡片模式和分组的管理方式</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15754459509275.jpg" /></p>
<ul>
<li>切换成列表模式</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15771078754865.jpg" /></p>
<ul>
<li>批量导入</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15771532908360.jpg" /></p>
<h3 id="_7">新建拨测任务</h3>
<p><strong>功能位置</strong>：导航  →  服务拨测  →  任务 →  新建拨测任务</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/15754460310042.jpg" /></p>
<ul>
<li>TCP、UDP、ICMP 支持五种目标 IP 的填写方式：<ul>
<li>动态拓扑：从CMDB拓扑中自动获取IP，有新增IP会自动配置监控目标</li>
<li>静态拓扑：只有已选择的拓扑才会生效，如子节点新增，则不会自动覆盖监控目标</li>
<li>服务模板：按服务模板进行配置</li>
<li>集群模板：按集群模板进行配置</li>
<li>自定义输入：支持手动输入内网IP，外网IP，其中外网 IP 地址，只要符合 IP 格式就可以不会进行 CMDB 的检验</li>
</ul>
</li>
</ul>
<p><img alt="image-20210421150942585" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/image-20210421150942585.png" /></p>
<h3 id="_8">查看拨测详情</h3>
<ul>
<li>【1】关联编辑操作和关联策略配置</li>
<li>【2】可以在曲线和地图视图之间切换</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/scene/media/16044653735836.jpg" /></p><h1 id="_1">数据检索</h1>
<p>当前数据检索可以直接检索两类数据，指标和日志数据。数据检索的目的就是在分析定位的时候，可以快速的进行数据的查询。</p>
<h2 id="_2">与仪表盘和场景视图的区别</h2>
<p><strong>仪表盘</strong> 是以固化图表为主，而且仪表盘里面的一个查询只能是一张图。如果查询的数据超过 20 上限是无法绘制数据，当然也就没有办法看到真实的数据情况。</p>
<p><strong>场景视图</strong> 什么是场景视图? 比如： 主机的详情，采集里面的检查视图，相比仪表盘就是不需要用户去配置，简单暴力的呈现已知的数据。</p>
<p><strong>数据检索</strong> 可以一次查询出多种图，可以快速的进行不同视角的切换和数据下钻。 </p>
<p><img alt="数据检索" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2.gif" /></p>
<h2 id="_3">功能列表</h2>
<ol>
<li>指标检索，默认多张图，可合并成一张图</li>
<li>收藏到仪表盘</li>
<li>数据对比：时间对比，目标对比，指标对比</li>
<li>查询收藏</li>
<li>直接添加策略</li>
<li>大图功能，查看原始数据</li>
<li>视图设置：面积图，y 轴最小值为 0</li>
<li>视图显示：一行一个，一行两个，一行三个</li>
<li>数据下钻，查看关联策略和主机详情</li>
<li>指标检索与日志检索切换</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/16044647842285.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/16044650045876.jpg" /></p><h1 id="_1">事件中心</h1>
<p>事件中心记录的是所有的告警事件，及告警通知情况。可以在事件中心进行基本的问题定位和分析。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>工作原理</strong></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15794918343257.jpg" /></p>
<p><strong>了解概念</strong>：</p>
<ul>
<li><strong>异常点</strong>：时序数据通过算法检测判断有异常的点</li>
<li><strong>告警事件</strong>：多个异常点为同一类为事件，一般具有持续性</li>
<li><strong>告警通知</strong>：多个告警事件通过收敛规则，风暴抑制等手段汇总成告警通知</li>
</ul>
<blockquote>
<p>更多查看<a href="../../concepts/glossary.md">术语解释</a></p>
</blockquote>
<h2 id="_3">主功能一览</h2>
<ul>
<li>告警事件趋势</li>
<li>持续事件，事件状态，通知状态</li>
<li>事件详情及事件趋势图</li>
<li>告警确认</li>
<li>快捷屏蔽</li>
<li>处理建议</li>
<li>流转记录</li>
</ul>
<h2 id="_4">功能说明</h2>
<h3 id="_5">事件查看</h3>
<p>告警事件提供多种查询方法，帮助快速的定位到事件。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15754464198583.jpg" /></p>
<p><strong>通知状态</strong>：</p>
<ul>
<li>成功：全部成功</li>
<li>部分失败：通知有部分失败</li>
<li>失败：通知全部失败</li>
<li>通知人为空：配置了告警组但是通知人为空的情况</li>
</ul>
<p><strong>告警状态</strong>：</p>
<ul>
<li>未恢复：事件一直在持续未恢复，需要重点关注</li>
<li>未恢复(已确认)：事件一直在持续未恢复，有人已经进行了<strong>告警确认</strong></li>
<li>未恢复(已屏蔽)：事件一直在持续未恢复，有人已经进行了<strong>快捷屏蔽</strong></li>
<li>未恢复(已抑制)：是监控的内部逻辑</li>
<li>已恢复：事件不再持续，算是历史情况，可以不再重点关注</li>
<li>已关闭：当策略删除的情况下，事件直接接入到关闭状态</li>
</ul>
<h3 id="_6">事件详情</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15754466559162.jpg" /></p>
<ul>
<li>【1】查看关联的告警策略，查看的是快照，有可能当前的策略已经被修改或者被删除</li>
<li>【2】告警处理<ul>
<li><strong>快捷屏蔽</strong>：快捷的屏蔽该事件，后续再出现类似的事件在屏蔽时间内也不再进行通知</li>
<li><strong>告警确认</strong>：该告警事件快速确认，该事件恢复前不再进行通知。恢复后再出现相同的事件时还是会再进行通知</li>
</ul>
</li>
<li>【3】通知状态详情：可以查看到每次通知的情况</li>
<li>【4】视图信息：展示出现首次异常时间到结束时间点的数据状态。日志，事件类的展示方式不一样</li>
<li>【5】处理建议：简单的记录事件的处理解决方案，和指标进行关联</li>
<li>【6】流转记录：详细的事件流转过程，主要用于单一事件追踪定位</li>
</ul>
<h3 id="_7">问题定位</h3>
<p>当通知没有收到的情况可以查看“通知状态详情”。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15795904494681.jpg" /></p>
<p>告警通知被收敛了的细节可以查看流转记录。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15795911129315.jpg" /></p><h1 id="_1">插件制作</h1>
<p>所有的采集配置都需要先定义插件(除了内置插件，如日志)，插件包含内置插件和自定义插件， 业务私有插件和公共插件，插件的本地采集和远程采集模式，支持不同的操作系统。</p>
<h2 id="_2">前置步骤</h2>
<blockquote>
<p>注意：对于 Linux 和 Windows 都默认只支持 64 位的操作系统。如果需要支持 32 位的操作系统，需要进行订制。</p>
</blockquote>
<p>插件输出格式说明：详细查看 <a href="../../concepts/datamodule.md#Promtheus的数据结构">数据模型</a>之『监控平台支持 Promtheus 的数据结构』。</p>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15767474716683.jpg" /></p>
<p><strong>术语解释</strong>：</p>
<ul>
<li><strong>采集器</strong>： Monitor Collector 监控内置的采集器，像 basereport 采集操作系统的指标， bkmonitorbeat 管理采集插件。</li>
<li><strong>采集插件</strong>： 用户自定义的采集插件，可以基于标准要求进行无限扩展。</li>
</ul>
<blockquote>
<p>两者的区别，更多请查看<a href="../../concepts/glossary.md">术语解释</a></p>
</blockquote>
<h2 id="_3">主功能一览</h2>
<ul>
<li>支持的操作系统：Linux、Windows、AIX6、AIX7</li>
<li>支持的插件类型：Exporter、DataDog、Script(Linux：Shell、Python、Perl、自定义，Windows：PowerShell、VBS、Python、自定义)、BK-Pull、JMX</li>
<li>支持的运作方式：公共插件、远程插件、官方插件</li>
<li>参数定义：命令行参数、环境变量、位置参数</li>
<li>插件导入导出</li>
<li>插件调试</li>
<li>插件定义：LOGO，描述，指标维度单位等</li>
</ul>
<h2 id="_4">功能说明</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754467635624.jpg" /></p>
<p>插件的制作分为几种情况：</p>
<ol>
<li>在线定义，直接在 web 界面定义，比如：<a href="../../guide/import_exporter.md">如何使用开源的 Exporter</a></li>
<li>线下定义，线下将插件包制作好，直接导入，比如：<a href="../../guide/import_datadog_offline.md">如何线下定义 DataDog 插件</a></li>
<li>采集程序本身的开发，比如：<ul>
<li><a href="../../dev/plugin_exporter_dev.md">Exporter 插件开发</a></li>
<li><a href="../../dev/plugin_datadog_dev.md">DataDog 插件开发</a></li>
</ul>
</li>
</ol>
<h3 id="_5">插件导入和导出</h3>
<p>插件导入支持单个自定义插件的导入和导出</p>
<p>认证的插件可以批量导入</p>
<blockquote>
<p><strong>注意</strong>：
1) 官方插件因为默认是公共插件，只有管理员权限的才可以导入
2) 在菜单的配置导入导出也可以导出相关联的插件</p>
</blockquote>
<h3 id="_6">在线制作插件</h3>
<p><strong>插件定义基本流程</strong>：</p>
<ul>
<li><strong>第一步： 插件定义</strong><ul>
<li>插件的基本信息：ID，别名，分类，是否为公共插件，是否支持远程</li>
<li>插件主体内容：<ul>
<li>脚本/二进制程序/配置内容</li>
<li>参数定义</li>
</ul>
</li>
<li>插件的辅助信息：描述，LOGO</li>
</ul>
</li>
</ul>
<p><img alt="定义插件" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15833902302710.jpg" /></p>
<blockquote>
<p>注意：公共插件只有平台权限才可以进行设置。设置完就是全平台全业务可用。</p>
</blockquote>
<ul>
<li><strong>第二步： 插件调试</strong></li>
</ul>
<p>插件调试是为了确保插件的制作返回的数据是正常的。</p>
<ul>
<li>
<p>步骤：
        * 参数填写
        * 选择调试机器
        * 调试过程
        * 设置指标和维度
        * 保存</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15833949594912.jpg" /></p>
</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15833949793387.jpg" /></p>
<h4 id="_7">参数定义说明</h4>
<p>参数定义提供了三种方式：命令行参数、位置参数、环境变量。</p>
<h5 id="_8">命令行参数</h5>
<p>最常见的参数定义方式。</p>
<p>如 redis_exporter 的启动参数</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Environment Variable Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>redis.addr</td>
<td>REDIS_ADDR</td>
<td>Address of the Redis instance, defaults to <code>redis://localhost:6379</code>.</td>
</tr>
<tr>
<td>redis.password</td>
<td>REDIS_PASSWORD</td>
<td>Password of the Redis instance, defaults to <code>""</code> (no password).</td>
</tr>
</tbody>
</table>
<p>如定义 <code>--redis.addr  redis://localhost:6379</code></p>
<p>可以这样设置：选择命令行参数</p>
<ul>
<li>参数名称： <code>--redis.addr</code></li>
<li>默认值：文本  <code>redis://localhost:6379</code></li>
<li>参数说明：Address of the Redis instance, defaults to <code>redis://localhost:6379</code></li>
</ul>
<p>更多完整的 redis_exporter 的插件制作查看 <a href="../../guide/import_exporter.md">如何使用开源的 Exporter 在线制作插件</a></p>
<h5 id="_9">位置参数</h5>
<p>在 shell 脚本里面经常使用到，如<code>$1,$2</code>这类方式。</p>
<p>比如脚本执行 <code>./script1.sh  localhost 6379</code></p>
<p>那么在脚本里面肯定有接收的位置</p>
<pre class="codehilite"><code class="language-bash">#!/bin/bash
redis-cli -h $1 -p $2</code></pre>


<p>那么就可以这样设置(以$1 为例）：选择位置参数</p>
<ul>
<li>参数名称： <code>redis地址</code>      # 参数名称在位置参数里面就是一个显示名，在插件使用的时候参数填写部分会显示这个。</li>
<li>默认值：文本  <code>localhost</code>   # 可以设置默认值，也可以不设置</li>
<li>参数说明： <code>redis地址填写，默认为localhost</code></li>
</ul>
<blockquote>
<p>注意：<code>$1 $2</code>以设置的顺序来决定。</p>
</blockquote>
<h5 id="_10">环境变量</h5>
<p>在程序里面使用的是环境变量来获取的内容。就使用环境变量参数定义。</p>
<p>比如在程序中直接获取环境变量中的变量，想让这个变量可以由插件的使用者来设置 <code>os.getenv('PYTHONPATH')</code></p>
<p>那么可以这样设置：选择环境变量</p>
<ul>
<li>参数名称：<code>PYTHONPATH</code></li>
<li>默认值：文本 <code>/usr/bin/python</code></li>
<li>参数说明：<code>Python 的路径 默认为/usr/bin/python</code></li>
</ul>
<h4 id="script">Script 插件定义</h4>
<p>Script 就是由用户自定义脚本进行 Metrics 采集。只要符合监控的标准格式就可以把数据采集上来。 支持的脚本有：</p>
<ul>
<li>
<p>Linux：Shell，Python，自定义</p>
</li>
<li>
<p>Windows：Shell，Python，VBS，PowerShell，自定义</p>
</li>
</ul>
<blockquote>
<p>INFO：自定义是直接执行，不用解释器进行执行。 如 ./script</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794940408106.jpg" /></p>
<ul>
<li><a href="../../guide/script_collect.md">如何通过脚本进行监控</a></li>
</ul>
<h4 id="exporter">Exporter 插件定义</h4>
<p>Exporter 是用于暴露第三方服务的 metrics 给 Prometheus。是 Prometheus 中重要的一个组件。</p>
<p>按监控平台插件的规范就可以将开源的 Exporter 插件变成监控平台的采集能力。</p>
<p>运行的 Exporter 是 go 的二进制程序，需要定义启动进程和占用端口。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794940142991.jpg" /></p>
<ul>
<li><a href="../../guide/import_exporter.md">如何使用开源的 Exporter 采集能力</a></li>
</ul>
<h4 id="datadog">DataDog 插件定义</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794940751608.jpg" /></p>
<ul>
<li><a href="../../guide/import_datadog_online.md">如何使用开源的 DataDog 采集能力</a></li>
</ul>
<h4 id="jmx">JMX 插件定义</h4>
<p>JMX 可以采集任何开启了 JMX 服务端口的 java 进程的服务状态，通过 JMX 采集 java 进程的 jvm 信息，</p>
<p>包括 gc 耗时、gc 次数、gc 吞吐、老年代使用率、新生代晋升大小、活跃线程数等信息。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794940240535.jpg" /></p>
<ul>
<li><a href="../../guide/plugin_jmx.md">如何定义一个 JMX 的插件</a></li>
</ul>
<h4 id="bk-pull">BK-Pull 插件定义</h4>
<p>BK-Pull 主要是解决那些只暴露了端口服务的数据源。通过 pull 拉取目标的数据。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794940929248.jpg" /></p>
<ul>
<li><a href="../../guide/howto_bk-pull.md">如何直接获取 Prometheus 的数据</a></li>
</ul>
<h4 id="_11">远程插件定义</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15794941254275.jpg" /></p>
<ul>
<li><a href="../../guide/noagent_monitor.md">如何在不安装蓝鲸 Agent 情况下实现监控</a></li>
</ul>
<h4 id="_12">公共插件定义</h4>
<p>公共插件只有管理员可以设置，设置为公共插件之后监控平台的用户都可以使用该插件。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795316967969.jpg" /></p>
<blockquote>
<p>注意：一旦设为公共插件并且有采集配置之后就不能取消，除非没有一个采集依赖。</p>
</blockquote>
<h3 id="_13">线下制作插件</h3>
<p>插件完全也可以通过线下制作直接进入导入，线下插件制作主要清楚各种插件的配置内容及关系。</p>
<ul>
<li><a href="../../functions/addenda/plugins_explain.md">插件配置说明</a></li>
<li><a href="../../guide/import_datadog_offline.md">如何线下定义 DataDog 插件</a></li>
</ul>
<h3 id="_14">升级插件</h3>
<p>每次修改插件都会进行版本的记录，版本记录分为两类。如：x.y。升级插件的动作在编辑完插件完后在采集配置中会有相应的升级提醒。</p>
<blockquote>
<p>注意：x 和 y 都是各自变化，不受影响。</p>
</blockquote>
<p>大版本 x</p>
<ul>
<li>二进制/脚本修改</li>
<li>配置模板修改</li>
<li>参数修改</li>
<li>是否为远程采集</li>
</ul>
<p>小版本 y</p>
<ul>
<li>插件指标</li>
<li>插件描述</li>
<li>插件别名</li>
<li>LOGO</li>
</ul><h1 id="_1">采集配置</h1>
<p>采集配置及采集任务，是为了将数据从监控对象源头采集数据上来，采集使用的要么是内置的采集能力，要么是用户创建的插件。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795742954623.jpg" /></p>
<p><strong>导航路径</strong>： 导航 →  监控配置 →  采集 →  新建</p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>采集参数支持变量</li>
<li>基于业务拓扑动态采集</li>
<li>检查视图</li>
<li>插件升级</li>
<li>采集状态</li>
</ul>
<h2 id="_4">功能说明</h2>
<h3 id="_5">采集配置列表</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795749115730.jpg" /></p>
<p><strong>统计数据说明</strong>：</p>
<ol>
<li>已启用配置：显示的是还在生效的采集任务</li>
<li>已停用配置：采集配置可以停用，停用后的配置数</li>
<li>异常采集目标：采集异常是采集出现问题，在检查视图处会有异常提示，这里的目标数量是 IP/实例数量</li>
<li>待升级目标：插件进行了变更后，大版本的变化会提示需要进行升级，否则无法编辑等操作，这里的目标数据是 IP/实例数量</li>
</ol>
<blockquote>
<p>注意：
1. 统计数据可以点击进行过滤，再点击是取消过滤
2. 日志采集是使用的日志平台的能力，界面交互暂时不在“新建”中</p>
</blockquote>
<h3 id="_6">新建采集</h3>
<p><strong>第一步： 基本配置</strong></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754470245591.jpg" /></p>
<ul>
<li>采集周期：默认是 1 分钟，可以采集 2 分钟 5 分钟的数据，图表类会兼容采集周期显示。 注意的是策略设置的监控周期最好和采集周期一致</li>
<li>Exporter 的需要设置 Exporter 启动的端口</li>
<li>参数的填写可以使用 CMDB 的变量。适用的场景就是参数内容不一样处理逻辑有所区别的。如被监控的进程端口不一样，角色不一样(master slave)等。具体查看<a href="../../guide/multi_instance_monitor.md">如何实现多实例采集</a></li>
</ul>
<p><strong>第二步： 选择目标</strong></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795947218571.jpg" /></p>
<p>静态和动态的采集方式，建议使用动态采集可以基于 CMDB 拓扑进行动态的扩缩容。</p>
<blockquote>
<p>注意：主机对应最小粒度是 IP ，服务对应的最小粒度是服务实例 instance 。</p>
</blockquote>
<p><strong>第三步： 采集下发</strong></p>
<p>采集目标下发过程可视化是因为采集的目标环境有很多种不确定性因素影响采集的过程，过程可视化可以帮助相关人快速的定位问题。</p>
<p>失败可以查看具体的详情，还可以进行批量重试。在编辑的时候还可以进行快速的回滚。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795951541532.jpg" /></p>
<p><strong>第四步： 完成</strong></p>
<p>完成阶段可以快速指引到“检查视图”和“策略配置”。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795952646927.jpg" /></p>
<h3 id="_7">查看采集数据</h3>
<p>为了判断采集的任务是否成功采集到数据。有如下的方法：</p>
<ul>
<li>1) 检查视图</li>
<li>2) 运行状态查看</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795955094428.jpg" /></p>
<p><strong>1) 检查视图查看</strong></p>
<p>列表页上面有“检查视图”的操作可以直接看到该采集任务的指标数据内容。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/16044652669257.jpg" /></p>
<p><strong>2) 运行状态检查</strong></p>
<p>当已经遇到一些采集问题，或者列表页的统计数据已经有一些异常数据，需要关心并进行处理。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15795956263451.jpg" /></p>
<h2 id="_8">相关</h2>
<p><a href="../../guide/nodata_problem.md">如何进行无数据问题定位</a> 检查视图，采集状态，数据采样。</p><h1 id="_1">策略配置</h1>
<p>时序数据，事件数据，日志数据都是通过策略的配置规划产生告警事件，并触发告警通知等动作达到监控告警的目的。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  监控配置  →  策略  →  新建</p>
<p>策略配置的基本过程：</p>
<p><img alt="策略配置过程截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15834049492119.jpg" /></p>
<ul>
<li>第一步： <strong>填写基本信息</strong><ul>
<li>策略名称：会显示在告警通知里面</li>
<li>监控对象：是指标选择的一种分类条件，也是本条策略的分类</li>
</ul>
</li>
<li>第二步：<strong>监控项设置</strong> - 判断异常点<ul>
<li>选择一个监控项，时序-指标，事件-事件名称，日志关键字</li>
<li>计算公式：AVG MAX MIN SUM COUNT 实时</li>
<li>监控周期：默认是 1 分钟，建议大于等于采集的周期</li>
<li>监控维度：检测的粒度，是 IP/实例/某个数据维度</li>
<li>监控条件：指的是维度条件，如 挂载点=/</li>
<li>监控目标：对于监控采集的都可以快速的选择监控目录，还可以基于集群和模块进行维度进行告警
    &gt; <strong>监控目标范围选择</strong>
        基于 CMDB 采集的数据是必选，如采集配置中的任务，操作系统，进程，系统事件等
        基于自定义上报或者数据平台或者服务拨测的无此选择</li>
<li>检测算法和设置：如静态阈值</li>
</ul>
</li>
<li>第三步：<strong>高级设置</strong> - 非必需项<ul>
<li>触发条件：是防抖机制，5 个周期内满足 3 次监控项的算法才进行告警通知。</li>
<li>恢复条件：是连续的周期内不满足触发条件才代表恢复。</li>
<li>告警模版：自定义告警通知模版</li>
</ul>
</li>
<li>第四步：<strong>告警通知设置</strong><ul>
<li>恢复通知</li>
<li>通知时间段</li>
<li>通知方式：告警组，如果没有需要的告警组需要进行新建 <a href="./alarm-group.md">告警组说明</a></li>
</ul>
</li>
</ul>
<p><strong>工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/analyze/media/15794918343257.jpg" /></p>
<p><strong>了解概念</strong>：</p>
<ul>
<li><strong>异常点</strong>：时序数据通过算法检测判断有异常的点</li>
<li><strong>告警事件</strong>：多个异常点为同一类为事件，一般具有持续性</li>
<li><strong>告警通知</strong>：多个告警事件通过收敛规则，风暴抑制等手段汇总成告警通知</li>
</ul>
<blockquote>
<p>更多查看<a href="../../concepts/glossary.md">术语解释</a></p>
</blockquote>
<h2 id="_3">主功能一览</h2>
<ul>
<li>支持的数据类型策略：<ul>
<li>时序指标策略</li>
<li>系统事件策略</li>
<li>自定义事件策略</li>
<li>日志关键字策略</li>
<li>日志时序策略</li>
<li>数据平台来源指标策略</li>
</ul>
</li>
<li>策略方法<ul>
<li>计算公式：AVG MAX MIN SUM COUNT 实时</li>
<li>监控汇聚：监控维度 和 监控条件</li>
<li>集群监控：基于 CMDB 业务拓扑任意节点进行监控</li>
<li>检测算法：8 种算法</li>
</ul>
</li>
<li>防抖机制<ul>
<li>触发条件</li>
<li>恢复机制</li>
</ul>
</li>
<li>告警通知<ul>
<li>模版预览</li>
<li>变量列表</li>
<li>收敛方法</li>
</ul>
</li>
<li>通知控制<ul>
<li>通知间隔</li>
<li>生效时间</li>
<li>告警通知组</li>
<li>消息队列通知方式</li>
<li>告警恢复通知</li>
</ul>
</li>
</ul>
<h2 id="_4">功能介绍</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754471359709.jpg" /></p>
<ul>
<li>批量修改功能：可以批量的修改策略的一些项到期望的设置。 如：告警组，触发条件，恢复条件，通知间隔，恢复通知</li>
<li>增删目标：快速变更策略生效的范围</li>
<li>快捷屏蔽：快速屏蔽该策略产生的所有告警通知，影响通知的接收</li>
<li>启停策略：快速的启用和停用策略，影响事件的产生</li>
</ul>
<p><img alt="策略配置截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15834000575887.jpg" /></p>
<h3 id="_5">第一步：基本信息设置</h3>
<ul>
<li><strong>策略名称</strong>：用于形容告警策略的具体意义，便于在发出告警时，用户能从告警的标题快速的确认问题的来源。</li>
<li><strong>监控对象</strong>：具体分类及概念查看<a href="../../concepts/glossary.md">术语解释</a>。有两个作用：<ul>
<li>确定策略的分类属于哪一处。</li>
<li>帮助指标，事件和日志做一个分类的筛选</li>
</ul>
</li>
</ul>
<h3 id="_6">第二步： 监控项设置</h3>
<h4 id="_7">选项监控项</h4>
<p>监控项的选择是必需项，监控项的选择范围由“监控对象”决定。</p>
<p><img alt="指标选择器截图" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15797073734399.jpg" /></p>
<p><strong>时序数据</strong>：监控项为指标 Metric，监控指标的来源有，监控采集，数据平台，自定义上报，<a href="./custom-report.md">日志字段提取</a></p>
<p><strong>事件数据</strong>：监控项为事件名称 Event，事件名称的来源有，系统事件，自定义事件上报</p>
<p><strong>日志关键字</strong>：监控项为选择[索引集]的“检索语句”即关键字内容</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15797077471928.jpg" /></p>
<h4 id="_8">监控项汇聚计算</h4>
<ul>
<li><strong>计算公式</strong>：指的是在监控周期内数据的计算方式，如一个周期内出现了多个数据点，要如何取值的问题。如果一个周期内只有一个数据点，当然这些计算公式就都是一样的结果<ul>
<li>汇聚的运算方法：支持 SUM，AVG，MAX，MIN，COUNT</li>
<li>实时：指的是直接按数据点进行判断，所以实时也就没有办法基于维度聚合</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意： 有些监控项是没有所有可选的汇聚方法，如关键字和拨测的期望响应码就是 COUNT。</p>
</blockquote>
<ul>
<li><strong>监控维度</strong>：是汇聚的最小粒度，如维度是 IP，那么会以 IP 维度进行告警；如果是实例，那么会以实例维度进行告警；如果是某个数据维度如模块节点，那么就是以模块节点进行汇聚判断。更多使用方法查看场景案例<a href="../../guide/cluster_monitor.md">如何进行集群监控</a></li>
<li><strong>监控条件</strong>：指的是维度或者指标的条件，目的就是找到最准确的数据进行策略检测</li>
</ul>
<h4 id="_9">监控目标范围选择</h4>
<p>监控目标范围还是在选择数据的检查准确性范围。只有使用了 CMDB 方式采集数据才会有目标范围的选择，如监控采集配置的，操作系统默认采集的，进程采集，系统事件采集等。</p>
<p>同样分为静态和动态，建议使用动态这样可以自动随着 CMDB 的变化而变化，避免人工同步的过程。</p>
<p>另外如果想监控集群状况，可以结合监控维度来达到集群，模块的监控需求。</p>
<h4 id="_10">级别和检测算法</h4>
<ul>
<li><strong>告警级别</strong>：分为提醒、预警和致命三种级别，目的是为了让用户能够方便的根据告警数值的大小、抖动趋势的高低来指定不同的处理方式和通知对象。相应的告警组里面也会有相应的配置。通知出来的信息也会基于不同的级别样式会有所区别，还会影响收敛和汇总的策略</li>
<li><strong>检测算法</strong>：提供了 8 种检测算法，每种算法有适用的一个场景。具体算法的说明查看附录 <a href="../addenda/algorithms.md">算法说明</a></li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15797093343755.jpg" /></p>
<h3 id="_11">第三步： 高级设置</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15797092075306.jpg" /></p>
<ul>
<li><strong>触发条件</strong>：是一种防抖机制，控制数据的敏感度，当然越不敏感告警通知的及时性越差，越敏感告警通知越多</li>
<li><strong>恢复条件</strong>：是判断问题恢复的方法，也是决定了事件恢复的结束时间</li>
<li><strong>告警通知模版</strong>：影响告警通知查看的内容，因为不同的通知渠道都有字符的限制，所以默认的告警通知是做了自动转换和截段处理等。目的是在有限的字符限制内提供更有用的信息。通知的种类有：<ul>
<li>异常单条告警 按级别</li>
<li>同策略不同目标 按级别</li>
<li>异常跨策略汇总告警 按级别)</li>
<li>以上对应的恢复通知<blockquote>
<p>更多告警通知模版的配置请查看场景案例<a href="../../guide/notify_case.md">如何设置自己的通知模版</a></p>
</blockquote>
</li>
</ul>
</li>
<li><strong>告警风暴抑制</strong>：指的是当同一时刻达到了某个平台设置的最大上限将进行跨策略汇总告警通知<ul>
<li>配置方法：导航 →  系统管理 →  全局配置 →  告警通知汇总设置</li>
<li>更多告警汇聚和收敛说明请查看附录<a href="../addenda/coverge.md">通知收敛&amp;汇总机制说明</a></li>
</ul>
</li>
</ul>
<h4 id="_12">触发条件、恢复条件工作原理</h4>
<p>数据经过算法检测后，会得到一个个的异常点。如果每一个异常点，都发送通知的话，那么在数据抖动或持续异常的场景下，一段时间内会多次收到通知，造成告警风暴。为了防止因为数据抖动等场景导致的告警骚扰，可以通过设置触发条件、恢复条件，以及通知间隔这三种方式来进行告警抑制。</p>
<ul>
<li>页面设置</li>
</ul>
<p><img alt="触发条件和恢复条件" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15834001297160.jpg" /></p>
<ul>
<li>
<p>触发条件</p>
<p>只有在连续多个检测周期中满足多次检测算法，才触发告警通知。</p>
<p>如设置触发条件为 5 个周期满足 3 次检测算法。则表示在连续 5 次数据检测中，有 3 次或 3 次以上检测结果满足检测算法，那么则触发告警。</p>
</li>
</ul>
<p><img alt="15807882679366" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15807882679366.jpg" /></p>
<p>如上图，2、7、17、18、19、20、21...等这些点都满足检测算法，但是从检测窗口来看。</p>
<blockquote>
<p>注：检测窗口，当前点往前看 5 个周期，在这 5 个周期内看有多少个点满足条件。</p>
</blockquote>
<p>只有 19、20、21...等这些才满足触发条件(5 个周期满足 3 次)，满足条件的才触发告警通知。从而可以有效的避免因抖动而产生的多次告警。</p>
<ul>
<li>
<p>恢复条件</p>
<p>恢复条件，是在触发条件的基础上来判断，只有<strong>连续</strong>多次不满足触发条件则表示恢复。</p>
<p>如设置恢复条件为连续 5 个周期不满足触发条件，表示在连续 5 次触发条件检测中，没有一次满足触发条件，则告警恢复。</p>
</li>
</ul>
<p><img alt="15808060152493" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15808060152493.jpg" /></p>
<p>如上图，19、20、21、22、23、24、25、26 等这些点都是满足触发条件(5 个周期满足 3 次)，那么从 27 开始，27、28、29、30、31、32 这些点都是不满足触发条件的。那么告警会在 31 这个点恢复，因为这个点首次达到连续 5 次不满足触发条件。</p>
<blockquote>
<p>注意：
触发条件里的周期，分两种情况：
时序类：按用户配置的聚合周期来
事件类：事件只有异常的时候才有数据，没有周期的概念，所以这里的周期固定为 1 分钟，5 个周期，即 5 分钟</p>
</blockquote>
<h4 id="_13">无数据工作原理</h4>
<p>无数据检测是在策略配置中的附加功能，在高级选项下配置，当连续 n 个周期未拉取到数据后，则触发告警。</p>
<p>假如配置连续 5 个周期未上报数据，</p>
<p>如图：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15810565732567.jpg" /></p>
<table>
<thead>
<tr>
<th>时间</th>
<th>无数据检测(连续 5 个周期无数据)</th>
<th>是否告警</th>
</tr>
</thead>
<tbody>
<tr>
<td>第 1 分钟</td>
<td>有数据</td>
<td>无</td>
</tr>
<tr>
<td>... ...</td>
<td>有数据</td>
<td>无</td>
</tr>
<tr>
<td>第 6 分钟</td>
<td>1 个周期无数据，不满足条件</td>
<td>无</td>
</tr>
<tr>
<td>第 7 分钟</td>
<td>2 个周期无数据，不满足条件</td>
<td>无</td>
</tr>
<tr>
<td>第 8 分钟</td>
<td>3 个周期无数据，不满足条件</td>
<td>无</td>
</tr>
<tr>
<td>第 9 分钟</td>
<td>4 个周期无数据，不满足条件</td>
<td>无</td>
</tr>
<tr>
<td>第 10 分钟</td>
<td>5 个周期无数据，满足条件</td>
<td>产生告警</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注：无数据告警同样有触发条件、恢复条件、告警间隔等这些。会跟随策略的配置。</p>
</blockquote>
<h3 id="_14">第四步： 告警通知设置</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15797103061763.jpg" /></p>
<ul>
<li><strong>告警恢复通知</strong>：默认恢复是不进行通知的</li>
<li><strong>通知间隔</strong>：指的是未恢复或未确认前则每隔多久将再进行告警</li>
<li><strong>通知时间段</strong>：如果能确认每个时间段不需要接收通知也没有问题，那就设置吧。默认是整天</li>
<li><strong>通知方式</strong>：默认是告警组，一般情况下接收告警的人都是相对固定的。通过告警组的设置和变更将更加的方便，还可以支持多个告警组。告警组的使用方法详细查看<a href="./alarm-group.md">告警组说明</a><ul>
<li>除了告警组，将还会支持故障自愈，webhook，工单的对接方式</li>
</ul>
</li>
</ul>
<h4 id="_15">设置通知间隔工作原理</h4>
<ul>
<li>页面设置</li>
</ul>
<p><img alt="15807892716298" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15807892716298.jpg" /></p>
<ul>
<li>
<p>说明</p>
<p>在持续异常的情况下，前面的触发条件会一直满足，则会一直触发告警，称为[持续事件]，为了防止频繁的收到告警，可以设置两次通知之间的最小间隔。如上图，通知间隔设置 2 个小时，一直产生告警的话，只要是未恢复，那么会按 2 个小时的最小间隔来发送。</p>
</li>
</ul>
<p><img alt="15807882679366" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15807882679366.jpg" /></p>
<p>这里引用触发条件里的图片，19、20、21、22、23、24 等都是满足触发条件，则都会触发告警通知，如果设置了告警间隔 120 分钟，那么只有在 19 会发送一次通知，后面的都不会发送，如果一直持续满足触发条件的话，那么下一次就是 139 这个点之后再通知一次。</p>
<h4 id="_16">事件生成原理</h4>
<ul>
<li>
<p>如下图，磁盘使用率告警，配置如下</p>
<ul>
<li>检测算法：&gt;= 90</li>
<li>触发条件：5 个周期满足 1 次</li>
<li>恢复条件：连续 5 个周期不满足触发条件</li>
<li>通知间隔：120 分钟</li>
</ul>
</li>
<li>
<p>数据点</p>
</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15809634260615.jpg" /></p>
<ul>
<li>异常点</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15809656915728.jpg" /></p>
<ul>
<li>每个时间点判断结果</li>
</ul>
<table>
<thead>
<tr>
<th>时间</th>
<th>检测算法(&gt;= 90)</th>
<th>触发条件(5 个周期满足 1 次)</th>
<th>通知(间隔 120 分钟)</th>
<th>是否恢复</th>
</tr>
</thead>
<tbody>
<tr>
<td>第 1 分钟</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>第 2 分钟</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>第 3 分钟</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>第 4 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 1 次</td>
<td>产生新的事件，并通知。<br>下一次通知时间第 124 分钟</td>
<td>无</td>
</tr>
<tr>
<td>第 5 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 2 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
<tr>
<td>... ...</td>
<td>满足&gt;90</td>
<td>... ...</td>
<td>... ...</td>
<td>... ...</td>
</tr>
<tr>
<td>第 123 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 5 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
<tr>
<td>第 124 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 5 次</td>
<td>产生通知。<br>下一次通知时间第 244 分钟</td>
<td>无</td>
</tr>
<tr>
<td>第 125 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 5 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
<tr>
<td>... ...</td>
<td>满足&gt;90</td>
<td>... ...</td>
<td>... ...</td>
<td>... ...</td>
</tr>
<tr>
<td>第 130 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 5 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
<tr>
<td>第 131~134 分钟</td>
<td>无</td>
<td>5 个周期分别满足 4~1 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
<tr>
<td>第 135~138 分钟</td>
<td>无</td>
<td>无</td>
<td>被收敛，不通知</td>
<td>不满足触发条件 1~4 次</td>
</tr>
<tr>
<td>第 139 分钟</td>
<td>无</td>
<td>无</td>
<td>结束通知，重置下次告警时间</td>
<td>不满足触发条件 5 次，事件恢复</td>
</tr>
<tr>
<td>第 140 分钟</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>... ...</td>
<td>无</td>
<td>... ...</td>
<td>... ...</td>
<td>... ...</td>
</tr>
<tr>
<td>第 143 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 1 次</td>
<td>产生新的事件，并通知。<br>下一次通知时间第 263 分钟</td>
<td>无</td>
</tr>
<tr>
<td>第 144 分钟</td>
<td>满足&gt;90</td>
<td>5 个周期满足 2 次</td>
<td>被收敛，不通知</td>
<td>无</td>
</tr>
</tbody>
</table>
<p>该事件变化情况可以在事件详情的事件流水中查看。</p>
<h3 id="_17">主机运营字段</h3>
<p>在 CMDB 进行主机运营字段的设置，默认会与监控进行联动，不会进行告警通知。所以该字段可以与发布相关操作进行联动。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15837253097538.jpg" /></p>
<p>具体的区别：在监控的全局设置中可以设置更多的状态。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15837254390358.jpg" /></p>
<ul>
<li>主机不监控字段列表：该主机下的策略不会产生任何告警事件</li>
<li>主机不告警字段列表：该主机下的策略会产生告警事件，在事件中心中可以查看到，但不会有告警通知发送到人，是被屏蔽状态</li>
</ul>
<h3 id="_18">监控目标范围抑制</h3>
<p>对于监控采集的，基于 CMDB 采集的数据可以做到监控目标范围的抑制。举一个例子：</p>
<ul>
<li>环境：一个集群下面机器 90%都是 500G，但是某些机器或某个模块是 2T，那么统一设置磁盘空间的告警策略超过 80%时进行告警，这个对于 2T 的服务器就不太合理，因为按百分比剩余的空间太多</li>
<li>配置方法：<ul>
<li>先创建一个全局的 A 策略，监控目标为该集群，静态阈值超过 80%进行告警</li>
<li>再创建一个小范围的 B 策略，监控目标为那几个特殊的服务器或者那个模块，静态阈值就可以设置超过 90%才进行告警</li>
</ul>
</li>
<li>效果就是：<ul>
<li>A 策略和 B 策略配置的内容都一样，只是监控目标的范围区别，那么小范围中的服务器会优先大范围生效。达到告警抑制的效果</li>
</ul>
</li>
</ul>
<h3 id="_19">监控等级抑制</h3>
<p>监控默认有三个等级，从低到高依次是：提醒、预警、致命。</p>
<p>那么在策略判断的时候会先以高等级进行判断，一旦符合高等级的条件，就不再再检查低等级的。达到等级抑制效果而不会进行重复的告警。</p>
<h3 id="_20">更多相关的场景案例</h3>
<ul>
<li><a href="../../guide/process_monitor.md">如何对进程进行监控</a></li>
<li><a href="../../guide/log_monitor.md">如何监控日志平台的数据</a></li>
<li><a href="../../guide/bigdata_monitor.md">如何监控数据平台的数据</a></li>
</ul><h1 id="_1">告警组</h1>
<p>告警组和日常管理一样，会有一组人同时负责一块内容，一起接收告警并进行处理。那么这组人就是属于一个告警组。</p>
<p>职能上划分如运维，开发，产品，测试。但实际上运维还会 A 组运维，B 组运维，所以告警组的粒度由管理的粒度来控制。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  监控配置  →  告警组</p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>通知对象：支持 CMDB 中的组，权限中心的用户组，个人</li>
<li>通知方式：按告警级别进行配置。通知渠道由全局配置进行控制，通知渠道的增加查看 <a href="../../guide/notify_setting.md">如何对接新的通知渠道</a></li>
<li>回调地址：支持告警回调，具体使用方法查看 <a href="../../guide/http_callback.md">如何配置告警回调</a></li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15833981927965.jpg" /></p><h1 id="_1">告警屏蔽</h1>
<p>告警发生后的一种常见的处理动作，一个事故的产生可能要持续很长时间，对于一个已知的问题不停的通知显然会影响正常的工作，而且会湮没更多新的告警通知。</p>
<p>所以屏蔽是非常有效的减少干扰的手段，尤其是在明知要做一些操作会影响线上服务产生告警的时候。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  监控配置  →  屏蔽</p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>基于范围屏蔽： 按目标范围进行屏蔽不会包含相应的指标和维度<ul>
<li>实例</li>
<li>IP</li>
<li>节点</li>
<li>业务</li>
</ul>
</li>
<li>基于策略屏蔽：是按策略设置的条件和维度进行屏蔽</li>
<li>基于告警事件屏蔽：是按告警的事件内容条件，事件内容包括维度和相应的值进行屏蔽</li>
<li>单次屏蔽，周期性屏蔽(每天，每周，每月)</li>
<li>屏蔽通知：屏蔽前后进行通知</li>
</ul>
<h2 id="_4">功能说明</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754473248000.jpg" /></p>
<h3 id="_5">基于范围屏蔽设置</h3>
<p>基于范围屏蔽是只要是该范围内的监控都将不再进行告警通知，如屏蔽的是某个 IP，那么该 IP 的进程，OS，服务实例都不再进行告警。如屏蔽的是某个集群，那个集群下的所有的 IP，服务实例都将不再进行告警。</p>
<h3 id="_6">基于策略屏蔽设置</h3>
<p>之所以能进行告警正是因为进行了策略的配置，那么基于策略的配置也可以非常准确的定位告警的数据。</p>
<blockquote>
<p>注意：与策略停用的区别是，屏蔽只是屏蔽的通知，策略生效的情况下还是会进行事件的产生，而策略的停用是不再产生事件，自然也就没有告警的通知了。</p>
</blockquote>
<h3 id="_7">基于告警事件屏蔽设置</h3>
<p>告警事件是策略里面特定的一个维度条件，所以要想能够进行事件的屏蔽，可以直接在事件详情中操作。</p>
<h3 id="_8">屏蔽周期设置</h3>
<p>默认是常用的单次时间范围，但如果业务的特点是有周期性特点的，如每天的凌晨会进行离线的计算占用大量的资源不进行告警，或者每周一都有那么一次数据的统计，每个月都有一次对帐，导致的所监控的对象周期性产生告警，那么就可以使用每天，每周，每月这种周期性设置。</p>
<h3 id="_9">屏蔽通知设置</h3>
<p>屏蔽通知设置是起到一定的提示作用。</p>
<ul>
<li>通知对象：可以是角色可以是单个的人</li>
<li>通知方式：和告警组的通知方式一样</li>
<li>通知时间：在屏蔽告警前和屏蔽失效后进行通知。 周期性的是在每次周期通知前和后进行通知</li>
</ul>
<h2 id="_10">其他相关屏蔽</h2>
<ul>
<li><strong>告警确认</strong>： 基于当前事件屏蔽，是按当前告警的事件进行屏蔽，一旦该事件恢复就失效。具体查看事件中心-事件详情-告警确认</li>
<li><strong>快捷屏蔽</strong>：<ul>
<li>策略列表页-快捷屏蔽，快速基于策略进行屏蔽</li>
<li>事件详情-快捷屏蔽，快速基于事件的条件进行快速屏蔽</li>
</ul>
</li>
<li><strong>主机运营状态</strong>：<ul>
<li>CMDB 的主机运营状态字段，一旦启用了，那么会基于主机运营字段确定是否要进行屏蔽</li>
<li>主机运营状态开关：导航  →  系统管理  →  全局配置  →  主机运营状态开关</li>
</ul>
</li>
</ul><h1 id="_1">分类管理</h1>
<p>分类管理指提服务分类的管理，主要是基于服务分类的角度来管理配置，可以满足跨业务拓扑树枝的管理需求。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  监控配置  →  分类管理</p>
<p>服务分类说明具体查看 <a href="../../../../配置平台/产品白皮书/产品功能/ServiceType.md">CMDB 服务分类</a></p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>配置导出</li>
<li>指标和配置索引</li>
</ul>
<h2 id="_4">功能说明</h2>
<blockquote>
<p><strong>注意</strong>：服务分类是属于 CMDB 的设置，需要前往 CMDB 进行配置。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754473533988.jpg" /></p><h1 id="_1">导入导出</h1>
<p>导入导出指提批量的导入和导出功能，可以将采集配置(及关联的插件)，策略配置，视图配置一起导出也可以一起导入。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  监控配置  →  导入导出</p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>导出功能</li>
<li>导入</li>
<li>导入历史</li>
</ul>
<h2 id="_4">功能说明</h2>
<h3 id="_5">导出</h3>
<p>可以按搜索，CMDB 节点，服务分类，数据对象进行检索卖出。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15799556373058.jpg" /></p>
<p>可以将强关联的插件和配置进行一起导出。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15799559459301.jpg" /></p>
<h3 id="_6">导入</h3>
<p>将批量导出的内容可以直接导入到另外一个业务，或者另外一个监控平台上面。 结合模版功能就会方便的共享监控的配置内容。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754475058661.jpg" /></p>
<blockquote>
<p><strong>警告：</strong>导入后，如果是相同的监控目标，强烈建议这个时候设置统一的监控目标，当前不进行统一设置，导入后的配置需要逐一进行设置。而且建议导出的也是相同监控目标的这样好管理。</p>
</blockquote>
<p>如果导入的内容太多，可能会占用比较久的时候，如果中途离开没有完成，还可以查看导入历史。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15799568641367.jpg" /></p>
<blockquote>
<p><strong>注意</strong>：导入历史默认只会保留近 30 天的数据，30 天后将清理记录和导入的数据。</p>
</blockquote><h1 id="_1">自定义上报</h1>
<p>自定义上报是支持用户不安装 Agent 的情况下，直接通过 HTTP 上报的方式，常见的就是是在程序里面进行打点打报。</p>
<p>自定义上报主要是注册自定义上报，只有先注册了才可以进行打点上报，分为自定义事件和自定义指标数据。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>自定义指标数据上报工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15769097214595.jpg" /></p>
<p><strong>自定义事件数据上报工作原理</strong>：</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15887429342933.jpg" /></p>
<h2 id="_3">主功能一览</h2>
<ul>
<li>SDK</li>
<li>自定义事件 分类/分组</li>
<li>特性 ID</li>
<li>自定义命令行工具</li>
</ul>
<h2 id="_4">功能说明</h2>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15754476249189.png" /></p>
<h4 id="_5">自定义事件上报</h4>
<p>自定义事件利用 http 协议，通过 bkmonitorproxy 上报事件数据。</p>
<ol>
<li>上报 IP 及端口
     bkmointorproxy 服务端口为 10205。而为了让在不同云区域下的主机都可以正常上报数据，监控平台将 bkmonitorproxy 部署到各个云区域：<ul>
<li>直连区域
   bkmonitorproxy 将会由部署到指定的直连区域主机上，。</li>
<li>非直连区域
   bkmonitorproxy 将会部署到各个非直连区域的 GSE proxy 主机上。此时，需要参考页面上对应云区域的上报 IP。进一步，对于有条件搭建域名服务的环境，可以考虑在不同云区域下搭建独立的域名服务，为 GSE proxy 提供统一的域名，方便不同云区域的上报域名统一。
 如下图，页面查找上报 IP：
<img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/conf/media/15887429814674.png" /></li>
</ul>
</li>
</ol>
<h4 id="_6">上报格式说明</h4>
<ul>
<li>上报格式：json</li>
<li>参数说明：</li>
<li>data_id：数据管道 ID，一个事件组使用同一个数据管道 ID</li>
<li>access_token：数据通道标识验证码，防止数据误上报至其他管道</li>
<li>data：上报事件集合</li>
<li>event_name：事件标识名</li>
<li>target：事件产生来源，可以理解为监控目标</li>
<li>event：事件详细内容<ul>
<li>content：事件具体内容文字描述</li>
</ul>
</li>
<li>dimension：事件维度，具体字段及内容可自定义填写</li>
<li>timestamp：事件发生时间，单位 ms</li>
</ul>
<h4 id="-">使用样例-自定义事件上报</h4>
<p>自定义系统事件监控，需要检查上报系统登录异常事件，通过 curl 上报样例：</p>
<p><code>bash
   curl -X POST http://${PROXY_IP}:10205/v2/push/ -d '{
       "data_id": 1500006,
       "access_token": "2e5a9c5c05394df2a6d0c0347f1d7c77",
       "data": [{
           "event_name": "login_failed",
           "target": "0:192.168.0.1",
           "event": {
               "content": "user-&gt;[user00] login failed"
           },
           "dimension": {
               "module": "db",
               "set": "guangdong"
           },
           "timestamp": 1587218838000
       }]
   }'
   #其中timestamp必须为13位，可由 date +%s000 生成</code></p>
<p>使用 Python 语言 requests 库上报事件样例</p>
<pre class="codehilite"><code class="language-python"># -*- coding: utf-8 -*-
import datetime
import time
import requests
import json
import random

timestamp=int(time.time() * 1000)

#PROXY_IP
PROXY_IP='X.X.X.X'  #直连区域可填此IP
PROXY_URL='http://%s:10205/v2/push/'%(PROXY_IP)

#data_id
DATA_ID=00000000    #修改为自己的data_id
#access_token
ACCESS_TOKEN=&quot;XXXXX&quot; #修改为自己的access_token

result = requests.post(PROXY_URL, data=json.dumps({
    &quot;data_id&quot;: DATA_ID,
    &quot;access_token&quot;: ACCESS_TOKEN,
    &quot;data&quot;: [{
        &quot;event_name&quot;: str(random.random())+&quot; my event __name__&quot;,
             &quot;event&quot;: {
                  &quot;content&quot;: &quot;user-&gt;[root] login failedt&quot; #事件内容数据类型是字符串
         },

    &quot;target&quot;: &quot;0:192.168.0.1&quot;, #修改为自己的设备IP
    &quot;dimension&quot;: {
        &quot;module&quot;: &quot;db&quot;,         #维度必须为字符串
        &quot;location&quot;: &quot;guangdong&quot; #维度必须为字符串
    },
    &quot;timestamp&quot;: timestamp
    }]
}))
print(result.text)</code></pre>


<p>返回内容：</p>
<p><code>bash
{"code":"200","message":"success","request_id":"a75ad22e-3c4f-4481-9096-c4947bf47187","result":"true"}</code></p>
<p>表示上报成功。</p>
<h4 id="-_1">使用样例-自定义指标上报</h4>
<p>使用 Python 语言 requests 库上报指标样例</p>
<pre class="codehilite"><code class="language-python"># -*- coding: utf-8 -*-
import datetime
import time
import requests
import json
import random

timestamp=int(time.time() * 1000)

#PROXY_IP
PROXY_IP='x.x.x.x'  #直连区域可填此IP
PROXY_URL='http://%s:10205/v2/push/'%(PROXY_IP)

#data_id
DATA_ID=1500101  #修改为自己的data_id
#access_token
ACCESS_TOKEN=&quot;XXXX&quot; #修改为自己的access_token

result = requests.post(PROXY_URL, data=json.dumps({
    &quot;data_id&quot;: DATA_ID,
    &quot;access_token&quot;: ACCESS_TOKEN,
    &quot;data&quot;: [{
        &quot;metrics&quot;: {                      #指标数据类型
            &quot;cpu_load&quot;: random.random(),  #指标值必须为数值类型
            &quot;mem_usage&quot;:random.random()   #指标值必须为数值类型
        },
        &quot;target&quot;: &quot;0:192.168.0.1&quot;, #修改为自己的设备IP
        &quot;dimension&quot;: {
            &quot;module&quot;: &quot;db&quot;,          #维度必须为字符串
            &quot;location&quot;: &quot;guangdong&quot;  #维度必须为字符串
        },
        &quot;timestamp&quot;: timestamp
    }]
}))
print(result.text)</code></pre>


<p>返回内容:</p>
<pre class="codehilite"><code class="language-python">{&quot;code&quot;:&quot;200&quot;,&quot;message&quot;:&quot;success&quot;,&quot;request_id&quot;:&quot;a75ad22e-3c4f-4481-9096-c4947bf47187&quot;,&quot;result&quot;:&quot;true&quot;}</code></pre>


<h3 id="_7">自定义命令行工具</h3>
<p>具体查看<a href="../../guide/custom-report-tools.md">自定义命令行工具介绍</a></p>
<h3 id="_8">注意事项</h3>
<ul>
<li>API 频率限制 1000/min，单次上报 Body 最大为 500KB；如果有更大量级数据的上报需求，请考虑使用插件方式上报数据.</li>
<li>bkmonitorproxy 部署说明<ul>
<li>直连区域
      直连区域的部署依赖环境管理员通过监控后台提供的命令进行部署。需要注意，部署的直连区域机器 10205 端口应该保持可用，并确保直连区域机器到该机器间的网络可用。部署操作命令如下：</li>
</ul>
</li>
</ul>
<pre class="codehilite"><code class="language-bash"># 登录到中控机
source /data/install/utils.fc
ssh $BKMONITORV3_MONITOR_IP
workon bkmonitorv3-monitor
# 执行部署bkmonitorproxy
./bin/manage.sh deploy_official_plugin --plugin_name bkmonitorproxy --target_hosts ${target_ip},${target_ip}</code></pre>


<blockquote>
<p>其中填写的 target_ip 将会在页面上显示为云区域 0(直连区域)的上报 IP</p>
</blockquote>
<ul>
<li>非直连云区域</li>
<li>只要是创建了自定义上报，非直连的云区域会自动创建并下发配置。需要等待5分钟左右。默认是部署在和GSE Proxy相同的服务器上。 </li>
</ul><h1 id="_1">全局配置</h1>
<p>全局配置是影响整个监控系统行为的，不区分业务。</p>
<h2 id="_2">前置步骤</h2>
<p><strong>导航路径</strong>：导航  →  系统管理  →  全局配置</p>
<blockquote>
<p><strong>注意</strong>：只有管理员才有权限进行设置。</p>
</blockquote>
<h3 id="_3">全局配置页面</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/global/media/15772819609704.jpg" /></p>
<h4 id="_4">数据保存周期</h4>
<p>数据保存周期设置完成后，是每天的凌晨 4 天进行生效。保存的时间越长，对存储的资源要求越高。注意资源的使用。</p>
<h4 id="_5">图表水印</h4>
<p>默认是开启图表水印的，页面上的图标将带上当前用户名的水印，关闭后整站的水印都会关闭。</p>
<h4 id="_6">告警通知渠道</h4>
<p>通知渠道是来自 ESB 中的通知方式，<a href="../../guide/notify_setting.md">ESB 的通知方式添加</a></p>
<p>配置告警组页面上允许选择的通知方式，但不影响已配置的告警组。["__all__"] 代表全部，sms 短信，weixin 微信，voice 电话，mail 邮件。</p>
<h4 id="_7">全局磁盘类型屏蔽配置</h4>
<p>若配置了磁盘只读和磁盘写满的策略，可通过该配置项屏蔽指定类型的磁盘的告警。</p>
<p>配置方法 <code>["iso9660", "tmpfs", "udf"]</code></p>
<h4 id="-">额外通知方式-消息队列设置</h4>
<p>设置了消息队列后在策略配置的时候可以选择哪些策略触发的告警信息是否要进入消息队列，方便基于告警事件进行二次开发的需求。</p>
<p>配置方法： <code>"redis://:${password}@${host}:${port}/${db}"</code></p>
<p>如： <code>"redis://:ycm%2C2rRn4A@10.0.1.10:6379/15/bk_monitor_queue"</code></p>
<h3 id="admin">更多 admin 配置方法</h3>
<ol>
<li>访问  <code>${BK_PAAS_HOST}/o/bk_monitor/admin/bkmonitor/globalconfig/</code> ，进入 admin 页面
点击看原图</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/global/media/15746678905653.jpg" /></p>
<ol>
<li>
<p>点击需要修改的配置，进入配置页面</p>
</li>
<li>
<p>配置信息根据实际需要填写，填写的文本需要严格符合 JSON 格式，数据类型与填写的文本必须匹配
支持的数据类型：</p>
<ul>
<li>整数。例如：1234</li>
<li>字符串(必须带上双引号)。例如："xxxxx"</li>
<li>布尔值。例如：true</li>
<li>JSON。任何符合 JSON 格式的文本</li>
<li>列表。例如：["test", 321]</li>
<li>字典。例如：{"key": "value"}</li>
</ul>
</li>
<li>
<p>修改完配置之后，点击右下角保存。若返回校验失败的报错，则需要检查配置是否符合 JSON 格式。然后重新进入页面填写提交。不要直接在原页面修改保存</p>
</li>
</ol>
<blockquote>
<p><strong>警告</strong>：由于缓存机制，配置将在修改后的 5 分钟内生效。</p>
</blockquote><h1 id="_1">自监控</h1>
<p>自监控是监控监控平台本身，保证监控平台本身没问题。自监控分为两部分：</p>
<p>第一部分：监控链路展示，简单展示监控的模块运行存活状态。</p>
<p>第二部分：监控模块性能指标，通过性能指标的展示可以更好的定位问题。</p>
<h2 id="_2">监控链路展示</h2>
<p>简单来说：</p>
<ul>
<li>红色 异常</li>
<li>黄色 警告</li>
<li>绿色 正常</li>
</ul>
<blockquote>
<p><strong>注意</strong>：当红色异常的时候，鼠标停留在上面可以看到更多具体的信息。是问题快速定位有效的一种办法。</p>
</blockquote>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/global/media/15754477874581.jpg" /></p>
<h2 id="_3">模块性能指标</h2>
<p>部署了一套 Prometheus+Grafana 自监控系统，可通过该系统监控 influxdb_proxy 与 transfer 的行为。</p>
<h3 id="_4">基本使用说明</h3>
<p>入口： https://bkmonitor.grafana.{$PaaS_URL}.com/?orgId=1</p>
<p>默认用户名密码： admin</p>
<blockquote>
<p>注意：域名部署时决定的。</p>
</blockquote>
<h3 id="_5">指标说明</h3>
<ul>
<li>influxdb_proxy_go_info 与 transfer_go_info</li>
</ul>
<table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>go_threads</td>
<td>线程数</td>
</tr>
<tr>
<td>go_gc_duration_seconds</td>
<td>gc 花费时间</td>
</tr>
<tr>
<td>go_goroutines</td>
<td>gouroutines 数</td>
</tr>
</tbody>
</table>
<ul>
<li>influxdb_proxy_alert</li>
</ul>
<table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>influxdb_proxy_state_change</td>
<td>监控 proxy 的重启操作，重启发生时，该指标会&gt;0</td>
</tr>
<tr>
<td>influxdb_proxy_backend_offline</td>
<td>backend(influxdb 实例)的离线情况</td>
</tr>
<tr>
<td>influxdb_proxy_backend_offline</td>
<td>kafka 离线情况</td>
</tr>
<tr>
<td>influxdb_proxy_consul_offline</td>
<td>consul 离线情况</td>
</tr>
<tr>
<td>influxdb_proxy_http_success_with_wrong_code</td>
<td>监控由 influxdb 实例通过 proxy 透传到 client 的错误 code</td>
</tr>
<tr>
<td>influxdb_proxy_http_request_failed</td>
<td>监控失败的 http 请求数</td>
</tr>
<tr>
<td>influxdb_proxy_http_blocked_request</td>
<td>阻塞(未返回)的 http 请求</td>
</tr>
<tr>
<td>influxdb_proxy_http_to_cluster_blocked_request</td>
<td>阻塞的从 http 传输到 cluster 的请求数</td>
</tr>
<tr>
<td>influxdb_proxy_cluster_request_failed</td>
<td>失败的 cluster 请求数</td>
</tr>
<tr>
<td>influxdb_proxy_cluster_blocked_request</td>
<td>阻塞的 cluster 请求数</td>
</tr>
<tr>
<td>influxdb_proxy_cluster_to_backend_blocked_request</td>
<td>阻塞的从 cluster 传递到 backend 的请求数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_request_failed</td>
<td>失败的 backend 请求数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_blocked_request</td>
<td>阻塞的 backend 请求数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_backup_failed</td>
<td>backend 备份失败数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_recover_failed</td>
<td>backend 恢复失败数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_blocked_backup</td>
<td>阻塞的备份数</td>
</tr>
<tr>
<td>influxdb_proxy_backend_not_recovered_too_large_backup</td>
<td>数据量过大的未恢复备份数</td>
</tr>
</tbody>
</table>
<ul>
<li>influxdb_proxy_request_speed</li>
</ul>
<table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>influxdb_proxy_http_increase_speed</td>
<td>http 请求数增速</td>
</tr>
<tr>
<td>influxdb_proxy_cluster_increase_speed</td>
<td>cluster 请求数增速</td>
</tr>
<tr>
<td>influxdb_proxy_backend_increase_speed</td>
<td>backend 请求数增速</td>
</tr>
<tr>
<td>influxdb_proxy_backup_increase_speed</td>
<td>备份数增速</td>
</tr>
<tr>
<td>influxdb_proxy_recover_increase_speed</td>
<td>恢复数增速</td>
</tr>
<tr>
<td>influxdb_proxy_cluster_to_backend_send_speed</td>
<td>cluster 传输到 backend 的请求增速</td>
</tr>
</tbody>
</table>
<ul>
<li>transfer_basic</li>
</ul>
<table>
<thead>
<tr>
<th>名称</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>transfer_bulk_backend_buffer_usage</td>
<td>缓冲区利用率</td>
</tr>
<tr>
<td>transfer_esb_request_status</td>
<td>esb 请求的状态计数</td>
</tr>
<tr>
<td>transfer_scheduler_panic_pipeline</td>
<td>崩溃的流水线数量</td>
</tr>
<tr>
<td>transfer_pipeline_frontend_status</td>
<td>前端流水线状态</td>
</tr>
<tr>
<td>transfer_pipeline_processor_status</td>
<td>处理器流水线状态</td>
</tr>
<tr>
<td>transfer_pipeline_backend_status</td>
<td>后端流水线状态</td>
</tr>
<tr>
<td>transfer_scheduler_pipeline_status</td>
<td>流水线调度状态</td>
</tr>
<tr>
<td>transfer_consul_write_status</td>
<td>transfer 写 consul 的计数</td>
</tr>
<tr>
<td>transfer_kafka_frontend_rebalanced</td>
<td>kafka 再均衡次数</td>
</tr>
<tr>
<td>transfer_esb_request_handle_seconds</td>
<td>处理 esb 请求消耗的时间</td>
</tr>
</tbody>
</table><h1 id="_1">移动端</h1>
<p>当前移动端没有单独的 App 或者公众号，而是以 H5 的方式存在。主要解决是可以在移动端进行简单问题定位和告警事件的处理。</p>
<h2 id="_2">主功能一览</h2>
<ol>
<li>查看具体告警及事件和流水</li>
<li>查看视图和视图对比</li>
<li>查看未恢复的事件列表</li>
<li>告警确认和屏蔽</li>
</ol>
<h2 id="_3">功能说明</h2>
<h3 id="_4">通知渠道入口</h3>
<p>当前是支持不同渠道可以进行配置是否启用移动端 H5 的入口地址，接下来是以微信信息为入口。 </p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15910991585063.jpg" /></p>
<ul>
<li>红色框的位置就是移动端的链接，点击可以直接进入到该告警的页面。</li>
</ul>
<h3 id="_5">告警详情</h3>
<p>点击链接后，默认看到的是该告警相关的信息。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15910997500618.jpg" /></p>
<h3 id="_6">事件详情</h3>
<p>想看具体的事件内容时，点击事件的内容区域就可以进入事件详情查看更多信息。 </p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15910998130151.jpg" /></p>
<h3 id="_7">视图</h3>
<p>可以进行简单的数据对比操作，还可以横屏查看。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15910999479422.jpg" /></p>
<p>可以横屏查看大图</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15910999819870.jpg" /></p>
<h3 id="_8">屏蔽操作</h3>
<ul>
<li>事件屏蔽：屏蔽该事件</li>
<li>策略屏蔽：屏蔽事件对应的策略</li>
<li>IP/实例屏蔽：屏蔽该事件对应的 IP/服务实例</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911000547255.jpg" /></p>
<h3 id="_9">该业务事件中心</h3>
<p>未恢复事件：以策略进行汇总</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911001571382.jpg" /></p>
<p>异常目标：以 IP/服务实例汇总</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911002290309.jpg" /></p>
<p>已屏蔽事件：正在屏蔽中的事件</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911002702039.jpg" /></p><h1 id="_1">通知内容说明</h1>
<p>监控有四类消息通知渠道样式，每一种又有 3 种汇总的信息格式。 </p>
<h2 id="_2">功能一览</h2>
<ul>
<li>通知渠道：短信，电话，邮件，IM 文本(微信，企业微信)</li>
<li>消息格式：单事件告警，同策略多事件告警，不同策略多事件告警</li>
<li>通知类型：异常通知，恢复通知，无数据通知</li>
</ul>
<h2 id="_3">功能说明</h2>
<h3 id="_4">邮件&amp;同策略多事件告警</h3>
<ul>
<li>邮件信息最多，带对比图，带事件详情链接</li>
<li>同策略多事件：只有目标不一样，将在告警目标提供 IP/服务实例列表
<img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911009385709.jpg" /></li>
</ul>
<h3 id="_5">短信&amp;单事件告警</h3>
<p>短信最简洁，不带链接，不带图
<img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911011080145.jpg" /></p>
<h3 id="_6">微信/企业微信&amp;汇总告警</h3>
<p>当同一时间达到了汇总收敛的阈值会进行跨策略的告警合并，提示汇总条数，并给出一个代表信息。详情点击进入可以看到更具体的。邮件就会带有事件的列表。并且微信带有移动端 H5 的入口，具体查看<a href="h5_app.md">移动端</a></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911013706265.jpg" /></p>
<h3 id="_7">无数据告警</h3>
<p>无数据告警都是预警级别
<img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911562374591.jpg" /></p>
<h3 id="_8">已恢复通知</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/notify/media/15911563921839.jpg" /></p>
<h3 id="_9">电话</h3>
<p>因为电话本身就会有限流和收敛，所以电话起到的是提醒。</p>
<pre class="codehilite"><code class="language-bash">当前{{业务}} {{策略名}}发生{{等级}}告警</code></pre><h1 id="-">主机-操作系统指标</h1>
<p>内置的主机指标是通过 basereport 进行采集,不同的监控系统可能在计算方法上会有差异,了解计算方法能够好的理解采集上来的数据。</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>类型</th>
<th>单位</th>
<th>含义</th>
<th>采集方法(Linux)</th>
<th>采集方法(Windows)</th>
</tr>
</thead>
<tbody>
<tr>
<td>5 分钟平均负载</td>
<td>CPU</td>
<td>%</td>
<td>五分钟内同时处于就绪状态的平均进程数</td>
<td _2="$2" print="print">awk ‘</td>
<td>N/A</td>
</tr>
<tr>
<td>cpu 总使用率</td>
<td>CPU</td>
<td>%</td>
<td>当前消耗的总 CPU 百分比</td>
<td>delta(busy) / delta(total) * 100 busy = user + sys + nice + iowait + irq + softirq + steal + guest + guestnice + stolen total = busy + idle</td>
<td>for /f “tokens=1,2,* delims==” %i in (‘wmic path Win32_PerfFormattedData_Counters_ProcessorInformation where "Name=’_Total’" get PercentIdleTime/value &#124; findstr PercentIdleTime’) do (set /a 100-%j)</td>
</tr>
<tr>
<td>cpu 单核使用率</td>
<td>CPU</td>
<td>%</td>
<td>当前单个 CPU 消耗的百分比</td>
<td>delta(busy) / delta(total) * 100 busy = user + sys + nice + iowait + irq + softirq + steal + guest + guestnice + stolen total = busy + idle</td>
<td>for /f “tokens=1,2,* delims==” %i in (‘wmic path Win32_PerfFormattedData_Counters_ProcessorInformation where “not name like ‘%Total%’” get PercentIdleTime/value &#124; findstr PercentIdleTime’) do (set /a 100-%j)</td>
</tr>
<tr>
<td>接收字节流量</td>
<td>网络</td>
<td>KB/s</td>
<td>网卡每秒接收的比特数，即网卡的上行带宽</td>
<td>读取/proc/net/dev 文件 第 1 项 SpeedRecv = delta(new.BytesRecv, old.BytesRecv) / interval</td>
<td>wmic path Win32_PerfRawData_Tcpip_NetworkInterface get BytesReceivedPersec/value &#124; findstr BytesReceivedPersec</td>
</tr>
<tr>
<td>发送字节流量</td>
<td>网络</td>
<td>KB/s</td>
<td>网卡每秒发送的比特数，即网卡的下行带宽</td>
<td>读取/proc/net/dev 文件第 9 项 SpeedSent = delta(new.BytesSent, old.BytesSent) / interval</td>
<td>wmic path Win32_PerfRawData_Tcpip_NetworkInterface get BytesSentPersec/value &#124; findstr BytesSentPersec</td>
</tr>
<tr>
<td>发送包速率</td>
<td>网络</td>
<td>个/s</td>
<td>网卡每秒接收的数据包数</td>
<td>读取/proc/net/dev 文件 第 10 项 SpeedPacketsSent = (counterDiff(once.Stat[i].PacketsSent, val.PacketsSent, NetCoutnerMaxSize)) / interval</td>
<td>wmic path Win32_PerfRawData_Tcpip_NetworkInterface get PacketsSentPersec/value &#124; findstr PacketsSentPersec</td>
</tr>
<tr>
<td>接收包速率</td>
<td>网络</td>
<td>个/s</td>
<td>网卡每秒发送的数据包数</td>
<td>读取/proc/net/dev 文件 第 2 项 SpeedPacketsRecv = delta(new.PacketsRecv, old.PacketsRecv) / interval</td>
<td>wmic path Win32_PerfRawData_Tcpip_NetworkInterface get PacketsReceivedPersec/value &#124; findstr PacketsReceivedPersec</td>
</tr>
<tr>
<td>established 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 ESTABLISHED 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep ESTABLISHED</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " ESTABLISHED "</td>
</tr>
<tr>
<td>time_wait 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 TIME_WAIT 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep TIME_WAIT</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " TIME_WAIT "</td>
</tr>
<tr>
<td>listen 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 LISTEN 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep LISTEN</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " LISTENING "</td>
</tr>
<tr>
<td>last_ack 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 LAST_ACK 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep LAST_ACK</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " LAST_ACK "</td>
</tr>
<tr>
<td>syn_recv 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 SYN_RECV 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep SYNC_RECV</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " SYN_RECV "</td>
</tr>
<tr>
<td>syn_sent 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 SYN_SENT 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep SYNC_SENT</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " SYN_SENT "</td>
</tr>
<tr>
<td>fin_wait1 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 FIN_WAIT1 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep FIN_WAIT1</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " FIN_WAIT_1 "</td>
</tr>
<tr>
<td>fin_wait2 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 FIN_WAIT2 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep FIN_WAIT2</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " FIN_WAIT_2 "</td>
</tr>
<tr>
<td>closing 连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 CLOSING 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep CLOSING</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " CLOSING "</td>
</tr>
<tr>
<td>closed 状态连接数</td>
<td>网络</td>
<td>个</td>
<td>当前服务器下 TCP 链接处于 CLOSED 状态的连接数</td>
<td>系统 netlink 实现 验证方法 netstat -pant&#124;grep CLOSED</td>
<td>netstat -ano -p tcp &#124; more +4 &#124; find " CLOSE "</td>
</tr>
<tr>
<td>UDP 接收包量</td>
<td>网络</td>
<td>个</td>
<td>UDP 包接受数</td>
<td _2="$2" print="print">读取 /proc/net/snmp 文件 InDatagrams 项 cat /proc/net/snmp&#124;grep Udp:&#124;grep -v ‘InDatagrams’&#124;awk ‘</td>
<td>wmic path Win32_PerfFormattedData_Tcpip_UDPv4 get DatagramsReceivedPersec/value</td>
</tr>
<tr>
<td>UDP 发送包量</td>
<td>网络</td>
<td>个</td>
<td>UDP 包发送数</td>
<td _5="$5" print="print">读取 /proc/net/snmp 文件 OutDatagrams 项 cat /proc/net/snmp&#124;grep Udp:&#124;grep -v ‘InDatagrams’&#124;awk ‘</td>
<td>读取/proc/net/dev 文件 第 2 项 SpeedPacketsRecv = delta(new.PacketsRecv, old.PacketsRecv) / interval</td>
</tr>
<tr>
<td>可用物理内存</td>
<td>内存</td>
<td>MB</td>
<td>可用内存容量</td>
<td _2="$2" print="print">读取 /proc/meminfo 文件 MemTotal 字段*1024 cat /proc/meminfo &#124;grep ‘MemTotal’&#124;awk -F ‘:’ ‘</td>
<td>for /f “tokens=1,2,* delims==” %i in (‘wmic OS get FreePhysicalMemory/value&#124; findstr FreePhysicalMemory’) do (set /a %j/1024)</td>
</tr>
<tr>
<td>交换分区已用量</td>
<td>内存</td>
<td>MB</td>
<td>交换分区使用容量</td>
<td>读取 /proc/meminfo 文件 golang 系统调用 syscall.Sysinfo sysinfo.Totalswap - sysinfo.Freeswap 验证方法 free -m</td>
<td>wmic os get TotalSwapSpaceSize/value</td>
</tr>
<tr>
<td>物理内存使用率</td>
<td>内存</td>
<td>%</td>
<td>内存使用百分比</td>
<td>读取 /proc/meminfo 文件[MemTotal-MemFree]/MemTotal*100.0</td>
<td>wmic os get FreePhysicalMemory,TotalVisibleMemorySize/value</td>
</tr>
<tr>
<td>物理内存使用量</td>
<td>内存</td>
<td>MB</td>
<td>已经使用的内存容量</td>
<td>读取 /proc/meminfo 文件[MemTotal-MemFree]*1024</td>
<td>wmic os get FreePhysicalMemory,TotalVisibleMemorySize/value &#124; findstr “FreePhysicalMemory TotalVisibleMemorySize”</td>
</tr>
<tr>
<td>应用内存使用量</td>
<td>内存</td>
<td>MB</td>
<td>应用进程使用的内存量</td>
<td>读取 /proc/meminfo 文件 如果有 MemAvailable 字段(不同系统版本有差异)(MemTotal-MemAvailable)/1024,如果没有该字段，MemAvailable=MemFree+Buffers+Cached</td>
<td>N/A</td>
</tr>
<tr>
<td>应用内存使用率</td>
<td>内存</td>
<td>%</td>
<td>应用进程内存量占总内存的百分比</td>
<td>读取 /proc/meminfo 文件 (MemTotal-MemAvailable)/(MemTotal*100.0)，如果没有 MemAvailable 字段，则 MemAvailable=MemFree+Buffers+Cached</td>
<td>N/A</td>
</tr>
<tr>
<td>磁盘使用率</td>
<td>磁盘</td>
<td>%</td>
<td>磁盘已用空间的百分占比</td>
<td>golang 系统调用 syscall.Statfs 相当于 df</td>
<td>for /f “tokens=1,2,* delims==” %i in (‘wmic path Win32_PerfFormattedData_PerfDisk_LogicalDisk where “name like ‘%:%’” get PercentFreeSpace/value &#124; findstr PercentFreeSpace’) do (set /a 100-%j)</td>
</tr>
<tr>
<td>读速率</td>
<td>磁盘</td>
<td>次/s</td>
<td>磁盘每秒输出次数</td>
<td>读取 /proc/diskstats 每一行的第四项 float64((new_stat.ReadCount - stat.ReadCount)) / 60 只上报逻辑分区</td>
<td>wmic path Win32_PerfFormattedData_PerfDisk_LogicalDisk get DiskReadsPersec/value</td>
</tr>
<tr>
<td>写速率</td>
<td>磁盘</td>
<td>次/s</td>
<td>磁盘每秒写入次数</td>
<td>读取 /proc/diskstats 第 8 项 float64((new_stat.WriteCount - stat.WriteCount)) / 60 只上报逻辑分区</td>
<td>wmic path Win32_PerfFormattedData_PerfDisk_LogicalDisk get DiskWritesPersec/value</td>
</tr>
<tr>
<td>磁盘 IO 使用率</td>
<td>磁盘</td>
<td>%</td>
<td>磁盘处于活动时间的百分比</td>
<td>读取 /proc/diskstats 文件读取 /proc/diskstats 第 13 项 (new_stat.IoTime - stat.IoTime)/60.0 / 1000.0</td>
<td>for /f “tokens=1,2,* delims==” %i in (‘wmic path Win32_PerfFormattedData_PerfDisk_LogicalDisk where "Name=’_Total’" get PercentIdleTime/value &#124; findstr PercentIdleTime’) do (set /a 100-%j)</td>
</tr>
<tr>
<td>系统进程数</td>
<td>进程</td>
<td>个</td>
<td>系统已启动进程数量</td>
<td>抓取/proc 目录下所有子目录数量</td>
<td>wmic path win32_process get ProcessId/value</td>
</tr>
</tbody>
</table><h1 id="-">主机-操作系统-系统事件</h1>
<p>系统事件，是内置主机操作和进程类的事件判断</p>
<h3 id="agent">Agent心跳丢失</h3>
<ul>
<li>含义： 监测 GSE 的 Agent 是否正常</li>
<li>采集方法： <ul>
<li>gse每隔60秒检查一次agent心跳数据。gse从agent最后一次心跳数据更新开始，第5分钟、第10分钟、第12小时各触发一次告警事件。从第24小时起，如果心跳依然未更新则重复上述第5分钟、第10分钟、第12小时各触发一次告警事件的过程。</li>
</ul>
</li>
<li>依赖： GSE 的服务上报</li>
</ul>
<h3 id="_1">磁盘只读</h3>
<ul>
<li>含义： 监测磁盘的只读状态</li>
<li>采集方法：Linux<ol>
<li>依赖exceptionbeat采集器, 在节点管理安装 </li>
<li>通过对挂载磁盘的文件状态ro进行判断，类似Linux命令：<code>fgrep ' ro,' /proc/mounts</code></li>
</ol>
</li>
</ul>
<h3 id="_2">磁盘写满</h3>
<ul>
<li>含义： 监测磁盘的写满状态</li>
<li>采集方法：<ul>
<li>Linux: 依赖exceptionbeat采集器, 在节点管理安装</li>
</ul>
</li>
</ul>
<h3 id="corefile">Corefile产生</h3>
<ul>
<li>含义： 监测 /proc/sys/kernel/core_pattern 中目录内文件的变化</li>
<li>采集方法：Linux<ol>
<li>查看corefile生成路径：<code>cat /proc/sys/kernel/core_pattern</code>，确保在某一个目录下，例如 <code>/data/corefile/core_%e_%t</code></li>
<li>依赖exceptionbeat采集器, 在节点管理安装,会自动根据core_pattern监听文件目录</li>
</ol>
</li>
</ul>
<h3 id="ping">Ping不可达</h3>
<ul>
<li>含义： 监测管控的服务器ping的状况</li>
<li>采集方法：<ol>
<li>依赖bkmonitorproxy采集器的安装，直连区域请联系管理员进行安装，非直连区域自动安装</li>
<li>由监控后台bkmonitorproxy去探测目标IP是否存活</li>
</ol>
</li>
<li>支持： 所有被管控的服务器。</li>
</ul>
<h3 id="_3">进程端口</h3>
<ul>
<li>含义： 进程端口不通</li>
<li>采集方法：<ol>
<li>Linux ：  processbeat 上报数据匹配产生</li>
<li>Windows： <code>wmic path win32_process get */value</code> 和 <code>netstat -ano</code></li>
</ol>
</li>
</ul>
<h3 id="_4">主机重启</h3>
<ul>
<li>含义： 监测系统启动异常告警</li>
<li>采集方法：Linux<ol>
<li>依赖basereport采集器的安装 ，在节点管理进行安装</li>
<li>检测原理：通过最近2次的uptime数据对比，满足<code>cur_uptime &lt; pre_uptime</code>，则判断为重启</li>
</ol>
</li>
</ul>
<h3 id="oom">OOM告警采集原理说明</h3>
<ul>
<li>
<p>说明
    蓝鲸监控中的OOM告警信息是由exceptionbeat采集器负责采集。OOM告警信息采集会有两个来源：kernel log及/proc/vmstat中的oom_kill计数器。下面将会分别说明两个来源的采集匹配逻辑</p>
</li>
<li>
<p>采集器原理</p>
<ol>
<li>kernel log<ul>
<li>采集原理<br />
    exceptionbeat是通过Syscall调用，获取内核当前缓冲区中的日志信息，然后匹配关键字<code>ut of memory:</code>。如果有匹配结果，采集器则认为系统发生过OOM事件，会将OOM告警信息上报。
    &gt; 注意：由于内核日志缓冲区是会有清空的情况，因此dmesg任意时刻不一定会打印日志内容</li>
<li>
<p>等价脚本</p>
<p><code>bash
    dmesg | grep 'ut of memory:'</code>
    2. oom_kill计数器
        - 采集原理
在linux 4.13+内核版本中，增加了oom_kill计数器，该计数器记录了OOM Killer被激活的次数。如果发现本次采集oom_kill数量较上一周期有增加，则上报OOM告警</p>
<blockquote>
<p>注意：由于是从计数器中感知到OOM事件发生，所以产生的OOM事件并不能提供具体进程信息，统一会记录为System发生OOM
        - 等价脚本</p>
</blockquote>
<p><code>bash
    grep 'oom_kill' /proc/vmstat</code></p>
</li>
</ul>
</li>
</ol>
</li>
<li>
<p>常见问题</p>
<ol>
<li>
<p>/proc/vmstat中没有看到oom_kill关键字？
    如上所述，该关键字是在linux 4.13+中增加，请<code>uname -a</code>确认机器内核版本</p>
</li>
<li>
<p>两个采集手段的优先级？
    为了尽可能的采集OOM的进程信息，exceptionbeat采集器优先会匹配kernel log中的关键字。如果kernel log中无关键字命中，再检查/prom/vmstat中的oom_kill计数器是否有增加</p>
</li>
<li>
<p>采集器的采集周期是多久一次？
    由于内核日志的缓冲区是会存在清空的情况，所以exceptionbeat默认<code>每10秒</code>检查一次kernel log。如果需要调整该频率，可以通过修改exceptionbeat采集器配置：</p>
<p><code>yaml
exceptionbeat:
    check_oom_interval: 10  # 单位秒</code></p>
</li>
</ol>
</li>
</ul><h1 id="-">主机-进程-指标</h1>
<p>| 指标 | 单位  | 备注 | 采集方式(Linux) |
| --- | --- | --- | --- | --- |
| Process.CPU | % | 进程当前占用 CPU 的使用率 | 从/proc/{pid}/stat 中采集：获得采集间隔中，进程系统 CPU 总时间及用户 CPU 总时间，然后与上一次采集值对比的差值为当次进程 CPU 使用时间，使用率为当次 CPU 使用时间除以采集间隔(current_total_time - last_total_time) / (gap_time) |
| Process.Mem | % | 进程当前占用内存的使用率 | 从/proc/{pid}/statm 采集：使用当前进程的物理使用量除以机器整体物理内存量 |
| Process.FileDescriptor |  文件句柄数 | | lsof -p ${pid} 来获取单个进程占用的文件句柄数 |
| Process.RES | MB | 物理内存 | 任务已使用的物理内存大小 | 从/proc/{pid}/statm 采集 |
| Process.VIRT | MB | 虚拟内存 | 任务已使用的虚拟内存大小 | 从/proc/{pid}/statm 采集 |</p><h1 id="_1">内置官方插件</h1>
<p>内置官方插件是由蓝鲸官方维护的插件，主要是满足监控平台开箱即用的一个需求。虽然是内置的官方插件，也会有一定的依赖和功能局限性。</p>
<p>如果使用描述不清或者错误，或者有需求可以反馈给官方。</p>
<blockquote>
<p><strong>注意</strong>：其实基于监控平台的插件定义可以非常方便的扩展监控能力，可以不用完全依赖官方的插件。具体查看
* <a href="../../guide/import_exporter.md">如何使用开源的 Exporter</a>
* <a href="../../guide/import_datadog.md">如何使用开源的 DataDog</a></p>
</blockquote>
<h2 id="exporter">Exporter 插件</h2>
<h3 id="apache">Apache 插件</h3>
<h4 id="_2">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>apache.net.bytes</td>
<td>bytes</td>
<td>总计传输的字节数</td>
</tr>
<tr>
<td>apache.net.bytes_per_s</td>
<td>bytes/second</td>
<td>每秒传输字节数</td>
</tr>
<tr>
<td>apache.net.hits</td>
<td>requests</td>
<td>总的请求数</td>
</tr>
<tr>
<td>apache.net.request_per_s</td>
<td>requests/second</td>
<td>每秒请求数</td>
</tr>
<tr>
<td>apache.performance.busy_workers</td>
<td>threads</td>
<td>活动线程数</td>
</tr>
<tr>
<td>apache.performance.cpu_load</td>
<td>percent</td>
<td>CPU 负载</td>
</tr>
<tr>
<td>apache.performance.idle_workers</td>
<td>threads</td>
<td>空闲线程数</td>
</tr>
<tr>
<td>apache.performance.uptime</td>
<td>seconds</td>
<td>Apache 运行时间</td>
</tr>
</tbody>
</table>
<h3 id="nginx">Nginx 插件</h3>
<h4 id="_3">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>nginx.connections.accepted</td>
<td>connections</td>
<td>接受的客户端连接的总数</td>
</tr>
<tr>
<td>nginx.connections.active</td>
<td>connections</td>
<td>当前客户端连接数</td>
</tr>
<tr>
<td>nginx.connections.dropped</td>
<td>connections</td>
<td>删除的客户端连接的总数</td>
</tr>
<tr>
<td>nginx.connections.idle</td>
<td>connections</td>
<td>当前空闲客户端连接数</td>
</tr>
<tr>
<td>nginx.generation</td>
<td></td>
<td>配置(configuration)重新加载的总数</td>
</tr>
<tr>
<td>nginx.load_timestamp</td>
<td>milliseconds</td>
<td>上次重新加载配置(configuration)的时间(自 Epoch 以来的时间)</td>
</tr>
<tr>
<td>nginx.net.conn_dropped_per_s</td>
<td>connections/second</td>
<td>连接丢失率</td>
</tr>
<tr>
<td>nginx.net.conn_opened_per_s</td>
<td>connections/second</td>
<td>打开连接的速率</td>
</tr>
<tr>
<td>nginx.net.connections</td>
<td>connections</td>
<td>活动连接的总数</td>
</tr>
<tr>
<td>nginx.net.reading</td>
<td>connections</td>
<td>读取客户端请求的连接数</td>
</tr>
<tr>
<td>nginx.net.request_per_s</td>
<td>requests/second</td>
<td>请求的处理速率</td>
</tr>
<tr>
<td>nginx.net.waiting</td>
<td>connections</td>
<td>等待工作的 keep-alive 连接的数量</td>
</tr>
<tr>
<td>nginx.net.writing</td>
<td>connections</td>
<td>等待上行(upstream)响应 和/或 将响应写回客户端的连接数</td>
</tr>
<tr>
<td>nginx.pid</td>
<td></td>
<td>处理状态请求的工作进程的 ID</td>
</tr>
<tr>
<td>nginx.processes.respawned</td>
<td>processes</td>
<td>异常终止并重新生成的子进程的总数</td>
</tr>
<tr>
<td>nginx.requests.current</td>
<td>requests</td>
<td>当前客户端请求数</td>
</tr>
<tr>
<td>nginx.requests.total</td>
<td>requests</td>
<td>客户端请求的总数</td>
</tr>
<tr>
<td>nginx.server_zone.discarded</td>
<td>requests</td>
<td>未发送响应而完成的请求总数</td>
</tr>
<tr>
<td>nginx.server_zone.processing</td>
<td>requests</td>
<td>当前正在处理的客户端请求数</td>
</tr>
<tr>
<td>nginx.server_zone.received</td>
<td>bytes</td>
<td>从客户端接收的数据总量</td>
</tr>
<tr>
<td>nginx.server_zone.requests</td>
<td>requests</td>
<td>从客户端接收的客户端请求的总数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.1xx</td>
<td>responses</td>
<td>具有 1xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.2xx</td>
<td>responses</td>
<td>具有 2xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.3xx</td>
<td>responses</td>
<td>具有 3xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.4xx</td>
<td>responses</td>
<td>具有 4xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.5xx</td>
<td>responses</td>
<td>具有 5xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.server_zone.responses.total</td>
<td>responses</td>
<td>发送到客户端的响应总数</td>
</tr>
<tr>
<td>nginx.server_zone.sent</td>
<td>bytes</td>
<td>发送到客户端的数据总量</td>
</tr>
<tr>
<td>nginx.ssl.handshakes</td>
<td></td>
<td>成功的 SSL 握手总数</td>
</tr>
<tr>
<td>nginx.ssl.handshakes_failed</td>
<td></td>
<td>失败的 SSL 握手总数</td>
</tr>
<tr>
<td>nginx.ssl.session_reuses</td>
<td></td>
<td>SSL 握手期间的会话重用总数</td>
</tr>
<tr>
<td>nginx.timestamp</td>
<td>milliseconds</td>
<td>自 Epoch 以来的时间</td>
</tr>
<tr>
<td>nginx.upstream.keepalive</td>
<td>connections</td>
<td>当前空闲的 keepalive 连接数</td>
</tr>
<tr>
<td>nginx.upstream.peers.active</td>
<td>connections</td>
<td>当前活动连接数</td>
</tr>
<tr>
<td>nginx.upstream.peers.backup</td>
<td></td>
<td>指示服务器是否为备份服务器的布尔值</td>
</tr>
<tr>
<td>nginx.upstream.peers.downstart</td>
<td>milliseconds</td>
<td>服务器变成 “unavail” 或 “unhealthy” 的时间(自 Epoch 开始)</td>
</tr>
<tr>
<td>nginx.upstream.peers.downtime</td>
<td>milliseconds</td>
<td>服务器处于 “unavail” 或 “unhealthy” 状态的总时间</td>
</tr>
<tr>
<td>nginx.upstream.peers.fails</td>
<td></td>
<td>与服务器通信失败的总次数</td>
</tr>
<tr>
<td>nginx.upstream.peers.health_checks.checks</td>
<td></td>
<td>health check 请求总数</td>
</tr>
<tr>
<td>nginx.upstream.peers.health_checks.fails</td>
<td></td>
<td>health check 的失败数</td>
</tr>
<tr>
<td>nginx.upstream.peers.health_checks.last_passed</td>
<td></td>
<td>布尔值，指示上次运行状况检查请求是否成功并通过了测试</td>
</tr>
<tr>
<td>nginx.upstream.peers.health_checks.unhealthy</td>
<td></td>
<td>服务器变得不健康 (state “unhealthy”) 的次数</td>
</tr>
<tr>
<td>nginx.upstream.peers.id</td>
<td></td>
<td>服务器的 ID</td>
</tr>
<tr>
<td>nginx.upstream.peers.received</td>
<td>bytes</td>
<td>从此服务器接收的总数据量</td>
</tr>
<tr>
<td>nginx.upstream.peers.requests</td>
<td>requests</td>
<td>转发到此服务器的客户端请求总数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.1xx</td>
<td>responses</td>
<td>具有 1xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.2xx</td>
<td>responses</td>
<td>具有 2xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.3xx</td>
<td>responses</td>
<td>具有 3xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.4xx</td>
<td>responses</td>
<td>具有 4xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.5xx</td>
<td>responses</td>
<td>具有 5xx 状态码的响应数</td>
</tr>
<tr>
<td>nginx.upstream.peers.responses.total</td>
<td>responses</td>
<td>从此服务器获取的响应总数</td>
</tr>
<tr>
<td>nginx.upstream.peers.selected</td>
<td>milliseconds</td>
<td>上次选择服务器以处理请求(1.7.5)的时间(自 Epoch 开始)</td>
</tr>
<tr>
<td>nginx.upstream.peers.sent</td>
<td>bytes</td>
<td>发送到此服务器的数据总量</td>
</tr>
<tr>
<td>nginx.upstream.peers.unavail</td>
<td></td>
<td>由于失败尝试次数达到 max_fails 阈值，服务器对客户端请求不可用 (state “unavail”) 的次数</td>
</tr>
<tr>
<td>nginx.upstream.peers.weight</td>
<td></td>
<td>Weight of the server</td>
</tr>
<tr>
<td>nginx.version</td>
<td></td>
<td>nginx 的版本</td>
</tr>
</tbody>
</table>
<h3 id="mysql">MySQL 插件</h3>
<h4 id="_4">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>mysql.galera.wsrep_cluster_size</td>
<td>nodes</td>
<td>在 Galera 集群中的节点数.</td>
</tr>
<tr>
<td>mysql.innodb.buffer_pool_free</td>
<td>pages</td>
<td>InnoDB 缓冲池空闲页面数</td>
</tr>
<tr>
<td>mysql.innodb.buffer_pool_total</td>
<td>pages</td>
<td>InnoDB 缓冲池的总页数</td>
</tr>
<tr>
<td>mysql.innodb.buffer_pool_used</td>
<td>pages</td>
<td>InnoDB 缓冲池中已使用的页数</td>
</tr>
<tr>
<td>mysql.innodb.buffer_pool_utilization</td>
<td>fractions</td>
<td>InnoDB 的缓冲池的利用率</td>
</tr>
<tr>
<td>mysql.innodb.current_row_locks</td>
<td>locks</td>
<td>The number of current row locks.</td>
</tr>
<tr>
<td>mysql.innodb.data_reads</td>
<td>reads/second</td>
<td>数据的读取速率 (读的次数/s)</td>
</tr>
<tr>
<td>mysql.innodb.data_writes</td>
<td>writes/second</td>
<td>数据的写速率 (写的次数/s)</td>
</tr>
<tr>
<td>mysql.innodb.mutex_os_waits</td>
<td>events/second</td>
<td>The rate of mutex OS waits.</td>
</tr>
<tr>
<td>mysql.innodb.mutex_spin_rounds</td>
<td>events/second</td>
<td>The rate of mutex spin rounds.</td>
</tr>
<tr>
<td>mysql.innodb.mutex_spin_waits</td>
<td>events/second</td>
<td>The rate of mutex spin waits.</td>
</tr>
<tr>
<td>mysql.innodb.os_log_fsyncs</td>
<td>writes/second</td>
<td>fsync 写入日志文件的速率(写的次数/s)</td>
</tr>
<tr>
<td>mysql.innodb.row_lock_time</td>
<td>fractions</td>
<td>花费在 acquring 行锁上的时间(millisecond/s)</td>
</tr>
<tr>
<td>mysql.innodb.row_lock_waits</td>
<td>events/second</td>
<td>行锁每秒要等待的次数(event/s)</td>
</tr>
<tr>
<td>mysql.net.connections</td>
<td>connections/second</td>
<td>连接到服务器的速率(连接数量/s)</td>
</tr>
<tr>
<td>mysql.net.max_connections</td>
<td>connections</td>
<td>服务器启动同时使用的最大数目连接数</td>
</tr>
<tr>
<td>mysql.performance.com_delete</td>
<td>queries/second</td>
<td>删除语句的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_delete_multi</td>
<td>queries/second</td>
<td>删除多语句的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_insert</td>
<td>queries/second</td>
<td>插入语句的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_insert_select</td>
<td>queries/second</td>
<td>插入 SELECT 语句的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_replace_select</td>
<td>queries/second</td>
<td>代替 SELECT 语句的速度(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_select</td>
<td>queries/second</td>
<td>SELECT 语句的速度(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_update</td>
<td>queries/second</td>
<td>更新语句的速度(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.com_update_multi</td>
<td>queries/second</td>
<td>更新多语句的速度(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.created_tmp_disk_tables</td>
<td>tables/second</td>
<td>执行语句时每秒创建的服务器内部磁盘上的临时表的数量 (表数量/s)</td>
</tr>
<tr>
<td>mysql.performance.created_tmp_files</td>
<td>files/second</td>
<td>每秒创建临时文件的数量 (文件数/s)</td>
</tr>
<tr>
<td>mysql.performance.created_tmp_tables</td>
<td>tables/second</td>
<td>每秒执行语句时创建的服务器内部临时表的数量(表数量/s)</td>
</tr>
<tr>
<td>mysql.performance.kernel_time</td>
<td>percent</td>
<td>MySQL 在内核空间中花费的 CPU 时间占比</td>
</tr>
<tr>
<td>mysql.performance.key_cache_utilization</td>
<td>fractions</td>
<td>键缓存利用率 (百分比)</td>
</tr>
<tr>
<td>mysql.performance.open_files</td>
<td>files</td>
<td>打开的文件数</td>
</tr>
<tr>
<td>mysql.performance.open_tables</td>
<td>tables</td>
<td>打开的表数量</td>
</tr>
<tr>
<td>mysql.performance.qcache_hits</td>
<td>hits/second</td>
<td>查询缓存命中率</td>
</tr>
<tr>
<td>mysql.performance.queries</td>
<td>queries/second</td>
<td>查询的速率 (次数/s)</td>
</tr>
<tr>
<td>mysql.performance.questions</td>
<td>queries/second</td>
<td>服务器执行的语句的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.slow_queries</td>
<td>queries/second</td>
<td>慢查询的速率(次数/s)</td>
</tr>
<tr>
<td>mysql.performance.table_locks_waited</td>
<td></td>
<td>由于表锁定请求无法处理需要等待的总次数</td>
</tr>
<tr>
<td>mysql.performance.threads_connected</td>
<td>connections</td>
<td>当前打开的连接的数量</td>
</tr>
<tr>
<td>mysql.performance.threads_running</td>
<td>threads</td>
<td>正在运行的线程数</td>
</tr>
<tr>
<td>mysql.performance.user_time</td>
<td>percent</td>
<td>MySQL 在用户空间中花费的 CPU 时间占比</td>
</tr>
<tr>
<td>mysql.replication.seconds_behind_master</td>
<td>seconds</td>
<td>主服务器(master)和从服务器(slave)之间的滞后时间</td>
</tr>
<tr>
<td>mysql.replication.slave_running</td>
<td></td>
<td>一个布尔值，判断该服务器是否为连接到主服务器(master)的从服务器(slave)</td>
</tr>
</tbody>
</table>
<h3 id="redis">Redis 插件</h3>
<h4 id="_5">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>redis.aof.buffer_length</td>
<td>bytes</td>
<td>AOF 缓冲区大小</td>
</tr>
<tr>
<td>redis.aof.last_rewrite_time</td>
<td>seconds</td>
<td>上次 AOF 重写(rewrite)的持续时间</td>
</tr>
<tr>
<td>redis.aof.rewrite</td>
<td></td>
<td>AOF 重写(rewrite)的次数</td>
</tr>
<tr>
<td>redis.aof.size</td>
<td>bytes</td>
<td>AOF 当前文件大小(aof_current_size)</td>
</tr>
<tr>
<td>redis.clients.biggest_input_buf</td>
<td></td>
<td>当前客户端连接的最大输入缓存</td>
</tr>
<tr>
<td>redis.clients.blocked</td>
<td>connections</td>
<td>等待阻塞调用的连接数</td>
</tr>
<tr>
<td>redis.clients.longest_output_list</td>
<td></td>
<td>当前客户端连接的最长输出列表</td>
</tr>
<tr>
<td>redis.cpu.sys</td>
<td>seconds</td>
<td>Redis 服务器消耗的系统 CPU</td>
</tr>
<tr>
<td>redis.cpu.sys_children</td>
<td>seconds</td>
<td>后台进程消耗的系统 CPU</td>
</tr>
<tr>
<td>redis.cpu.user</td>
<td>seconds</td>
<td>Redis 服务器消耗的用户 CPU</td>
</tr>
<tr>
<td>redis.cpu.user_children</td>
<td>seconds</td>
<td>后台进程消耗的用户 CPU</td>
</tr>
<tr>
<td>redis.expires</td>
<td>keys</td>
<td>已过期的 key 数量</td>
</tr>
<tr>
<td>redis.expires.percent</td>
<td>percent</td>
<td>已过期的 key 百分比</td>
</tr>
<tr>
<td>redis.info.latency_ms</td>
<td>milliseconds</td>
<td>Redis info 命令的延迟</td>
</tr>
<tr>
<td>redis.key.length</td>
<td></td>
<td>给定 key 中元素的数量</td>
</tr>
<tr>
<td>redis.keys</td>
<td>keys</td>
<td>Key 的总数量</td>
</tr>
<tr>
<td>redis.keys.evicted</td>
<td>keys</td>
<td>由于最大内存限制被驱逐(evict)的 key 的总数量</td>
</tr>
<tr>
<td>redis.keys.expired</td>
<td>keys</td>
<td>数据库中过期的 key 的总数量</td>
</tr>
<tr>
<td>redis.mem.fragmentation_ratio</td>
<td>fractions</td>
<td>used_memory_rss 和 used_memory 的比率</td>
</tr>
<tr>
<td>redis.mem.lua</td>
<td>bytes</td>
<td>Lua 引擎使用的内存量</td>
</tr>
<tr>
<td>redis.mem.peak</td>
<td>bytes</td>
<td>Redis 使用的内存的峰值</td>
</tr>
<tr>
<td>redis.mem.rss</td>
<td>bytes</td>
<td>系统给 Redis 分配的内存</td>
</tr>
<tr>
<td>redis.mem.used</td>
<td>bytes</td>
<td>已经被 Redis 分配的内存量</td>
</tr>
<tr>
<td>redis.net.clients</td>
<td>connections</td>
<td>连接的客户端数 (不包括 slaves)</td>
</tr>
<tr>
<td>redis.net.commands</td>
<td>commands</td>
<td>服务器运行的命令数</td>
</tr>
<tr>
<td>redis.net.rejected</td>
<td>connections</td>
<td>被拒绝的连接数</td>
</tr>
<tr>
<td>redis.net.slaves</td>
<td>connections</td>
<td>连接的 slave 数</td>
</tr>
<tr>
<td>redis.perf.latest_fork_usec</td>
<td>microseconds</td>
<td>最新 fork 的持续时间</td>
</tr>
<tr>
<td>redis.persist</td>
<td>keys</td>
<td>持久化的 key 数(redis.keys - redis.expires)</td>
</tr>
<tr>
<td>redis.persist.percent</td>
<td>percent</td>
<td>持久化的 key 的百分比</td>
</tr>
<tr>
<td>redis.pubsub.channels</td>
<td></td>
<td>活跃的发布/订阅的频道数量</td>
</tr>
<tr>
<td>redis.pubsub.patterns</td>
<td></td>
<td>活跃的发布/订阅的模式数量</td>
</tr>
<tr>
<td>redis.rdb.bgsave</td>
<td></td>
<td>一个标志值，记录了服务器是否正在创建 RDB 文件，正在进行中是 1，否则是 0</td>
</tr>
<tr>
<td>redis.rdb.changes_since_last</td>
<td></td>
<td>上次后台保存后，RDB 的改动</td>
</tr>
<tr>
<td>redis.rdb.last_bgsave_time</td>
<td>seconds</td>
<td>最近一次 bg_save 操作的持续时间</td>
</tr>
<tr>
<td>redis.replication.backlog_histlen</td>
<td>bytes</td>
<td>积压在同步缓冲区的数据量</td>
</tr>
<tr>
<td>redis.replication.delay</td>
<td>offsets</td>
<td>复制延迟的偏移</td>
</tr>
<tr>
<td>redis.replication.last_io_seconds_ago</td>
<td>seconds</td>
<td>距离最近一次与主服务器行通信已经过去了多少秒钟</td>
</tr>
<tr>
<td>redis.replication.master_link_down_since_seconds</td>
<td>seconds</td>
<td>主从服务器连接断开了多少秒</td>
</tr>
<tr>
<td>redis.replication.master_repl_offset</td>
<td>offsets</td>
<td>从 master 报告的复制偏移量</td>
</tr>
<tr>
<td>redis.replication.slave_repl_offset</td>
<td>offsets</td>
<td>从 slave 报告的复制偏移量</td>
</tr>
<tr>
<td>redis.replication.sync</td>
<td></td>
<td>一个标志值，如果同步正在进行，则为 1，否则为 0</td>
</tr>
<tr>
<td>redis.replication.sync_left_bytes</td>
<td>bytes</td>
<td>距离同步完成还剩多少数据量</td>
</tr>
<tr>
<td>redis.slowlog.micros.95percentile</td>
<td>microseconds</td>
<td>在慢日志中，查询报告的持续时间的第 95 百分位值</td>
</tr>
<tr>
<td>redis.slowlog.micros.avg</td>
<td>microseconds</td>
<td>在慢日志中，查询报告的持续时间平均值</td>
</tr>
<tr>
<td>redis.slowlog.micros.count</td>
<td>queries/second</td>
<td>在慢日志中，报告的查询速率</td>
</tr>
<tr>
<td>redis.slowlog.micros.max</td>
<td>microseconds</td>
<td>在慢日志中，查询报告的持续时间最大值</td>
</tr>
<tr>
<td>redis.slowlog.micros.median</td>
<td>microseconds</td>
<td>在慢日志中，查询报告的持续时间中位值</td>
</tr>
<tr>
<td>redis.stats.keyspace_hits</td>
<td>keys</td>
<td>在数据库中查找 key 成功的次数</td>
</tr>
<tr>
<td>redis.stats.keyspace_misses</td>
<td>keys</td>
<td>在数据库中查找 key 失败的次数</td>
</tr>
</tbody>
</table>
<h3 id="oracle">Oracle 插件</h3>
<h4 id="_6">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>oracle.RWParse.oracledb_Executions</td>
<td></td>
<td>SQL 执行速率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_HardParse</td>
<td></td>
<td>SQL 硬解析率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_LogicalReads</td>
<td></td>
<td>逻辑块读速率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_PhysicalReads</td>
<td></td>
<td>物理块读速率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_PhysicalWrites</td>
<td></td>
<td>物理块写速率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_TotalParse</td>
<td></td>
<td>SQL 解析速率</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_Transaction</td>
<td></td>
<td>每秒事务数</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_insstatus</td>
<td></td>
<td>实例状态(1 代表 ONLINE，0 代表 OFFLINE)</td>
</tr>
<tr>
<td>oracle.RWParse.oracledb_runhealthtime</td>
<td>s</td>
<td>数据库健康运行时长</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_PGAFreeSize</td>
<td>MB</td>
<td>PGA 空闲大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_PGATotalSize</td>
<td>MB</td>
<td>PGA 分配大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_PGAUsedRate</td>
<td>%</td>
<td>PGA 使用率</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_PGAlUsedSize</td>
<td>MB</td>
<td>PGA 使用大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SGAFreeSize</td>
<td>MB</td>
<td>SGA 空闲大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SGATotalSize</td>
<td>MB</td>
<td>SGA 分配大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SGAUsedRate</td>
<td>%</td>
<td>SGA 使用率</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SGAUsedSize</td>
<td>MB</td>
<td>SGA 使用大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SharePoolFreeSize</td>
<td>MB</td>
<td>SharePool 空闲大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SharePoolTotalSize</td>
<td>MB</td>
<td>SharePool 分配大小</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SharePoolUsedRate</td>
<td>%</td>
<td>SharePool 使用率</td>
</tr>
<tr>
<td>oracle.MemoryInfo.oracledb_SharePoolUsedSize</td>
<td>MB</td>
<td>SharePool 使用大小</td>
</tr>
<tr>
<td>oracle.Table_space.oracledb_TablespaceFree</td>
<td>MB</td>
<td>表空间空闲大小</td>
</tr>
<tr>
<td>oracle.Table_space.oracledb_TablespaceRate</td>
<td>%</td>
<td>表空间使用率</td>
</tr>
<tr>
<td>oracle.Table_space.oracledb_TablespaceStatus</td>
<td></td>
<td>表空间状态(1 代表 ONLINE，0 代表 OFFLINE)</td>
</tr>
<tr>
<td>oracle.Table_space.oracledb_TablespaceTotal</td>
<td>MB</td>
<td>表空间分配大小</td>
</tr>
<tr>
<td>oracle.Table_space.oracledb_TablespaceUsed</td>
<td>MB</td>
<td>表空间使用大小</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_ActiveSession</td>
<td></td>
<td>活跃用户会话数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_InactiveSession</td>
<td></td>
<td>非活跃用户会话数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_SessionMax</td>
<td></td>
<td>会话分配数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_SessionTotal</td>
<td></td>
<td>用户会话数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_BlockNum</td>
<td></td>
<td>当前阻塞数量</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_BufferCacheHit</td>
<td>%</td>
<td>缓冲区命中率</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_BufferCacheSize</td>
<td>MB</td>
<td>缓冲区大小</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_DeadLockNum</td>
<td></td>
<td>死锁数量</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_ProcessMax</td>
<td></td>
<td>进程分配数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_ProcessTotal</td>
<td></td>
<td>进程总数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_RedoNum</td>
<td></td>
<td>Redo 日志文件组数</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_RedoSize</td>
<td>MB</td>
<td>Redo 日志文件总大小</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_SortMemory</td>
<td>%</td>
<td>内存排序率</td>
</tr>
<tr>
<td>oracle.sys_param.oracledb_sharepoolhit</td>
<td>%</td>
<td>共享池命中率</td>
</tr>
<tr>
<td>oracle.ASMInfo.oracledb_ASMDisk_total</td>
<td>MB</td>
<td>ASM 总磁盘大小</td>
</tr>
<tr>
<td>oracle.ASMInfo.oracledb_ASMDisk_free</td>
<td>MB</td>
<td>ASM 空闲磁盘大小</td>
</tr>
<tr>
<td>oracle.ASMInfo.oracledb_ASMDisk_state</td>
<td></td>
<td>ASM 磁盘状态(1 代表 MOUNT，0 代表其他非正常状态)</td>
</tr>
<tr>
<td>oracle.scanIpInfo.oracledb_ScanIPStatus</td>
<td></td>
<td>scanIP 监听状态(1 代表端口连通，0 代表端口不通)</td>
</tr>
<tr>
<td>oracle.InsIpInfo.oracledb_InsIpStatus</td>
<td></td>
<td>实例 IP 监听状态(1 代表端口连通，0 代表端口不通)</td>
</tr>
<tr>
<td>oracle.VIPInfo.oracledb_VIPStatus</td>
<td></td>
<td>VIP 监听状态(1 代表端口连通，0 代表端口不通)</td>
</tr>
</tbody>
</table>
<h3 id="sql-server">SQL Server 插件</h3>
<h4 id="_7">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>mssql.instance_Lock.mssqldb_LockWaits_sec</td>
<td></td>
<td>每秒锁等待次数</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_database_status</td>
<td></td>
<td>数据库状态 0 代表 offline 1 代表 online</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_used_data_size</td>
<td>MB</td>
<td>数据库数据大小</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_max_data_size</td>
<td>MB</td>
<td>数据库数据最大值</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_log_size</td>
<td>MB</td>
<td>日志大小</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_LogGrowths</td>
<td>MB</td>
<td>日志增长量</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_io_stall_total_ms</td>
<td>s</td>
<td>用户等待 IO 总时间</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_io_stall_read_ms</td>
<td>s</td>
<td>用户等待读取总时间</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_io_stall_write_ms</td>
<td>s</td>
<td>用户等待写入总时间</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_connections</td>
<td></td>
<td>数据库连接数</td>
</tr>
<tr>
<td>mssql.db_status.mssqldb_log_space_used</td>
<td>%</td>
<td>日志空间使用率</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_up</td>
<td></td>
<td>实例状态 0 代表 offline 1 代表 online</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_PageSplits_sec</td>
<td></td>
<td>每秒产生的页拆分数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_ProcessesBlocked</td>
<td></td>
<td>当前堵塞进程数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_SqlCompilations_sec</td>
<td></td>
<td>SQL 每秒编译次数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_SqlReCompilations_sec</td>
<td></td>
<td>SQL 每秒重编译次数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_UserConnections</td>
<td></td>
<td>用户连接数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_deadlocks_sec</td>
<td></td>
<td>导致死锁的每秒锁定请求数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_kill_conn_errors_sec</td>
<td></td>
<td>连接错误数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_local_time</td>
<td>s</td>
<td>实例运行时间</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_memory_utilization_percentage</td>
<td>%</td>
<td>内存使用率</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_batch_requests_sec</td>
<td></td>
<td>每秒查询数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_page_life_expectancy</td>
<td>s</td>
<td>数据页在内存中的驻留时间</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_page_fault_count</td>
<td></td>
<td>数据页错误数量/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_total_page_file_kb</td>
<td>MB</td>
<td>总页面文件</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_available_page_file_kb</td>
<td>MB</td>
<td>可用页面文件</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_total_physical_memory_kb</td>
<td>MB</td>
<td>总物理内存</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_available_physical_memory_kb</td>
<td>MB</td>
<td>可用物理内存</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_hit_radio</td>
<td>%</td>
<td>实例缓冲区命中率</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_total_pages</td>
<td></td>
<td>实例缓冲区总页数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_used_rate</td>
<td>%</td>
<td>实例缓冲区使用率</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_used_pages</td>
<td></td>
<td>实例缓冲区使用页数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_free_pages</td>
<td></td>
<td>实例缓冲区空闲页数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_tps</td>
<td></td>
<td>每秒事务数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_full_scan</td>
<td></td>
<td>每秒全表扫描数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_sessions</td>
<td></td>
<td>用户会话数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_active_sessions</td>
<td></td>
<td>活跃用户会话数</td>
</tr>
<tr>
<td>mssql.db_perform.mssqldb_inactive_sessions</td>
<td></td>
<td>非活跃用户会话数</td>
</tr>
<tr>
<td>mssql.cip.mssqldb_ha_ip_status</td>
<td></td>
<td>ip 监听状态 0 代表监听端口不通 1 代表监听端口通畅</td>
</tr>
</tbody>
</table>
<h3 id="haproxy">HAProxy 插件</h3>
<h4 id="_8">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>haproxy_backend_bytes_in_total</td>
<td>B</td>
<td>后端主机传入字节速率/分</td>
</tr>
<tr>
<td>haproxy_backend_bytes_out_total</td>
<td>B</td>
<td>后端主机发送字节速率/分</td>
</tr>
<tr>
<td>haproxy_backend_connection_errors_total</td>
<td></td>
<td>连接错误数/分</td>
</tr>
<tr>
<td>haproxy_backend_current_queue</td>
<td></td>
<td>未分配的后端请求数</td>
</tr>
<tr>
<td>haproxy_backend_current_server</td>
<td></td>
<td>后端服务数</td>
</tr>
<tr>
<td>haproxy_backend_current_sessions</td>
<td></td>
<td>活跃后端会话数</td>
</tr>
<tr>
<td>haproxy_backend_up</td>
<td></td>
<td>后端服务状态</td>
</tr>
<tr>
<td>haproxy_backend_http_responses_total</td>
<td></td>
<td>后端 HTTP 响应码</td>
</tr>
<tr>
<td>haproxy_frontend_bytes_in_total</td>
<td></td>
<td>前端主机传入字节速率/分</td>
</tr>
<tr>
<td>haproxy_frontend_bytes_out_total</td>
<td></td>
<td>前端主机发送字节速率/分</td>
</tr>
<tr>
<td>haproxy_frontend_current_session</td>
<td></td>
<td>前端会话数</td>
</tr>
<tr>
<td>haproxy_frontend_http_requests_total</td>
<td></td>
<td>前端 HTTP 请求码</td>
</tr>
<tr>
<td>haproxy_frontend_http_responses_total</td>
<td></td>
<td>前端 HTTP 响应码</td>
</tr>
</tbody>
</table>
<h3 id="zookeeper">Zookeeper 插件</h3>
<h4 id="_9">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>zk_packets_received</td>
<td></td>
<td>接收的数据包数量</td>
</tr>
<tr>
<td>zk_packets_sent</td>
<td></td>
<td>发送的数据包数量</td>
</tr>
<tr>
<td>zk_avg_latency</td>
<td></td>
<td>响应客户端请求的平均时间</td>
</tr>
<tr>
<td>zk_max_latency</td>
<td></td>
<td>响应客户端请求的最大时间</td>
</tr>
<tr>
<td>zk_min_latency</td>
<td></td>
<td>响应客户端请求的最小时间</td>
</tr>
<tr>
<td>zk_outstanding_requests</td>
<td></td>
<td>排队请求数</td>
</tr>
<tr>
<td>zk_pending_syncs</td>
<td></td>
<td>等待同步的 follower 数</td>
</tr>
<tr>
<td>zk_synced_followers</td>
<td></td>
<td>同步的 follower 数</td>
</tr>
<tr>
<td>zk_num_alive_connections</td>
<td></td>
<td>客户端连接总数</td>
</tr>
<tr>
<td>zk_approximate_data_size</td>
<td></td>
<td>数据集近似值</td>
</tr>
<tr>
<td>zk_ephemerals_count</td>
<td></td>
<td>短暂节点数</td>
</tr>
<tr>
<td>zk_followers</td>
<td></td>
<td>followers 数</td>
</tr>
<tr>
<td>zk_max_file_descriptor_count</td>
<td></td>
<td>文件句柄上限</td>
</tr>
<tr>
<td>zk_open_file_descriptor_count</td>
<td></td>
<td>文件句柄数</td>
</tr>
<tr>
<td>zk_watch_count</td>
<td></td>
<td>watches 数</td>
</tr>
<tr>
<td>zk_znode_count</td>
<td></td>
<td>节点数</td>
</tr>
<tr>
<td>zk_up</td>
<td></td>
<td>ZooKeeper 存活状态</td>
</tr>
<tr>
<td>zk_server_state</td>
<td></td>
<td>服务身份</td>
</tr>
</tbody>
</table>
<h3 id="rabbitmq">RabbitMQ 插件</h3>
<h4 id="_10">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>rabbitmq_channelsTotal</td>
<td></td>
<td>channels 开启总数</td>
</tr>
<tr>
<td>rabbitmq_connectionsTotal</td>
<td></td>
<td>连接开启总数</td>
</tr>
<tr>
<td>rabbitmq_consumersTotal</td>
<td></td>
<td>消费者数量</td>
</tr>
<tr>
<td>rabbitmq_exchangesTotal</td>
<td></td>
<td>使用中的 exchanges 总数</td>
</tr>
<tr>
<td>rabbitmq_queue_messages_ready_total</td>
<td></td>
<td>准备发送给客户端的消息数量</td>
</tr>
<tr>
<td>rabbitmq_queue_messages_total</td>
<td></td>
<td>集群中的消息总数</td>
</tr>
<tr>
<td>rabbitmq_queue_messages_unacknowledged_total</td>
<td></td>
<td>发送后未被确认的消息数</td>
</tr>
<tr>
<td>rabbitmq_queuesTotal</td>
<td></td>
<td>使用中的队列数</td>
</tr>
<tr>
<td>rabbitmq_up</td>
<td></td>
<td>存活状态</td>
</tr>
<tr>
<td>rabbitmq_fd_total</td>
<td></td>
<td>文件句柄数上限</td>
</tr>
<tr>
<td>rabbitmq_fd_used</td>
<td></td>
<td>已用文件句柄数</td>
</tr>
<tr>
<td>rabbitmq_node_mem_used</td>
<td>MB</td>
<td>内存使用量</td>
</tr>
<tr>
<td>rabbitmq_partitions</td>
<td></td>
<td>此节点可见的网络分区数量</td>
</tr>
<tr>
<td>rabbitmq_running</td>
<td></td>
<td>运行 nodes 数</td>
</tr>
</tbody>
</table>
<h3 id="memcached">Memcached 插件</h3>
<h4 id="_11">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>memcached_commands_total</td>
<td></td>
<td>请求状态/分</td>
</tr>
<tr>
<td>memcached_connections_total</td>
<td></td>
<td>连接速率/分</td>
</tr>
<tr>
<td>memcached_current_bytes</td>
<td>MB</td>
<td>当前存储 item 的大小</td>
</tr>
<tr>
<td>memcached_current_connections</td>
<td></td>
<td>当前服务器打开的连接数</td>
</tr>
<tr>
<td>memcached_current_items</td>
<td></td>
<td>实例当前 item 数</td>
</tr>
<tr>
<td>memcached_items_evicted_total</td>
<td></td>
<td>从缓存中给新 item 的速率/分</td>
</tr>
<tr>
<td>memcached_items_total</td>
<td></td>
<td>服务启动后存储 item 总数</td>
</tr>
<tr>
<td>memcached_limit_bytes</td>
<td>MB</td>
<td>内存使用上限</td>
</tr>
<tr>
<td>memcached_malloced_bytes</td>
<td>MB</td>
<td>分配 slab page 内存量</td>
</tr>
<tr>
<td>memcached_max_connections</td>
<td></td>
<td>连接数上限</td>
</tr>
<tr>
<td>memcached_read_bytes_total</td>
<td>bytes</td>
<td>服务器从网络读取字节的速率/分</td>
</tr>
<tr>
<td>memcached_written_bytes_total</td>
<td>bytes</td>
<td>服务器向网络发送字节的速率/分</td>
</tr>
<tr>
<td>memcached_uptime_seconds</td>
<td>s</td>
<td>服务运行时长</td>
</tr>
<tr>
<td>memcached_up</td>
<td></td>
<td>存活状态</td>
</tr>
</tbody>
</table>
<h3 id="elasticsearch">ElasticSearch 插件</h3>
<h4 id="_12">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>elasticsearch_docs_deleted</td>
<td></td>
<td>集群中所有分片的删除的文档</td>
</tr>
<tr>
<td>elasticsearch_indexing_delete_total</td>
<td></td>
<td>从 index 中删除的文档数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_generic_queue</td>
<td></td>
<td>generic 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_management_active</td>
<td></td>
<td>mgt 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_refresh_active</td>
<td></td>
<td>refresh 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_indexing_index_current</td>
<td></td>
<td>index 中被索引的文档数量</td>
</tr>
<tr>
<td>elasticsearch_indexing_delete_time</td>
<td>s</td>
<td>从 index 中删除文档花费时间</td>
</tr>
<tr>
<td>elasticsearch_indexing_index_time</td>
<td>s</td>
<td>从 index 索引文档花费时间</td>
</tr>
<tr>
<td>elasticsearch_process_open_fd</td>
<td></td>
<td>打开和当前进程相关的文件数据</td>
</tr>
<tr>
<td>elasticsearch_indexing_delete_current</td>
<td></td>
<td>从 index 中删除的文档数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_flush_queue</td>
<td></td>
<td>bulk 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_force_merge_queue</td>
<td></td>
<td>merge 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_get_total</td>
<td></td>
<td>文档存在时 get 请求次数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_refresh_queue</td>
<td></td>
<td>refresh 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_index_queue</td>
<td></td>
<td>index 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_search_threads</td>
<td></td>
<td>search 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_transport_tx_size</td>
<td>MB</td>
<td>集群通信中发送的数据大小</td>
</tr>
<tr>
<td>elasticsearch_indexing_index_total</td>
<td></td>
<td>index 中被索引的文档数量</td>
</tr>
<tr>
<td>elasticsearch_search_fetch_open_contexts</td>
<td></td>
<td>活跃查询次数</td>
</tr>
<tr>
<td>elasticsearch_docs_count</td>
<td></td>
<td>集群中所有分片的文档</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_management_queue</td>
<td></td>
<td>mgt 线程池排队的线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_bulk_active</td>
<td></td>
<td>bulk 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_search_queue</td>
<td></td>
<td>search 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_get_time</td>
<td>s</td>
<td>get 请求上的总时间</td>
</tr>
<tr>
<td>elasticsearch_merges_current</td>
<td></td>
<td>当前的活跃段合并数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_flush_threads</td>
<td></td>
<td>bulk 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_merges_current_size</td>
<td>MB</td>
<td>当前被合并的段的大小</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_snapshot_active</td>
<td></td>
<td>snap 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_search_fetch_current</td>
<td></td>
<td>当前运行的查询取回操作的数量</td>
</tr>
<tr>
<td>elasticsearch_flush_total</td>
<td></td>
<td>index 刷新到磁盘次数</td>
</tr>
<tr>
<td>elasticsearch_flush_total_time</td>
<td>s</td>
<td>index 刷新到磁盘花费时间</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_generic_threads</td>
<td></td>
<td>generic 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_store_size</td>
<td>MB</td>
<td>总的存储大小</td>
</tr>
<tr>
<td>elasticsearch_transport_tx_count</td>
<td></td>
<td>在集群通信中发送的包的总数量</td>
</tr>
<tr>
<td>elasticsearch_merges_total</td>
<td></td>
<td>所有段的合并数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_snapshot_queue</td>
<td></td>
<td>snap 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_search_fetch_time</td>
<td>s</td>
<td>查询取回操作的总时间</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_search_active</td>
<td></td>
<td>search 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_get_queue</td>
<td></td>
<td>get 线程池排队线程数</td>
</tr>
<tr>
<td>elasticsearch_fielddata_evictions</td>
<td></td>
<td>field 缓存被驱逐的数据量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_index_threads</td>
<td></td>
<td>index 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_flush_active</td>
<td></td>
<td>flush 队列中活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_search_query_time</td>
<td>s</td>
<td>查询操作的总时间</td>
</tr>
<tr>
<td>elasticsearch_get_exists_time</td>
<td>s</td>
<td>文档存在时 get 请求时间</td>
</tr>
<tr>
<td>elasticsearch_get_missing_total</td>
<td></td>
<td>文档丢失时 get 请求次数</td>
</tr>
<tr>
<td>elasticsearch_transport_rx_count</td>
<td></td>
<td>集群通信接受包的总数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_bulk_threads</td>
<td></td>
<td>bulk 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_transport_rx_size</td>
<td>MB</td>
<td>集群通信接受的数据大小</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_force_merge_threads</td>
<td></td>
<td>merge 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_refresh_total</td>
<td></td>
<td>总的 index 刷新次数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_snapshot_threads</td>
<td></td>
<td>snap 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_fielddata_size</td>
<td>MB</td>
<td>field 缓存区大小</td>
</tr>
<tr>
<td>elasticsearch_transport_server_open</td>
<td></td>
<td>为集群通信打开的连接数</td>
</tr>
<tr>
<td>elasticsearch_search_query_total</td>
<td></td>
<td>查询操作的数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_bulk_queue</td>
<td></td>
<td>bulk 线程池排队的线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_get_threads</td>
<td></td>
<td>get 线程池的线程总数</td>
</tr>
<tr>
<td>elasticsearch_get_current</td>
<td></td>
<td>正在运行的 get 请求数</td>
</tr>
<tr>
<td>elasticsearch_http_current_open</td>
<td></td>
<td>当前打开的 http 连接数</td>
</tr>
<tr>
<td>elasticsearch_get_missing_time</td>
<td>s</td>
<td>文档丢失花费 get 请求时间</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_index_active</td>
<td></td>
<td>index 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_refresh_total_time</td>
<td>s</td>
<td>index 刷新花费总时间</td>
</tr>
<tr>
<td>elasticsearch_http_total_opened</td>
<td></td>
<td>打开 http 的总连接数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_generic_active</td>
<td></td>
<td>generic 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_force_merge_active</td>
<td></td>
<td>merge 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_refresh_threads</td>
<td></td>
<td>refresh 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_search_fetch_total</td>
<td></td>
<td>查询取回操作的数量</td>
</tr>
<tr>
<td>elasticsearch_get_exists_total</td>
<td></td>
<td>文档存在时 get 请求数</td>
</tr>
<tr>
<td>elasticsearch_merges_total_size</td>
<td>MB</td>
<td>所有合并段的大小</td>
</tr>
<tr>
<td>elasticsearch_merges_current_docs</td>
<td></td>
<td>当前跨段合并的文档数量</td>
</tr>
<tr>
<td>elasticsearch_merges_total_docs</td>
<td></td>
<td>跨所有合并段的文档数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_get_active</td>
<td></td>
<td>get 线程池活跃线程数</td>
</tr>
<tr>
<td>elasticsearch_search_query_current</td>
<td></td>
<td>当前运行查询操作的数量</td>
</tr>
<tr>
<td>elasticsearch_thread_pool_management_threads</td>
<td></td>
<td>mgt 线程池线程总数</td>
</tr>
<tr>
<td>elasticsearch_merges_total_time</td>
<td>s</td>
<td>花在合并段上的时间</td>
</tr>
<tr>
<td>elasticsearch_active_primary_shards</td>
<td></td>
<td>集群中活跃的主分片数量</td>
</tr>
<tr>
<td>elasticsearch_pending_tasks_total</td>
<td></td>
<td>总的未完成的 task 数量</td>
</tr>
<tr>
<td>elasticsearch_unassigned_shards</td>
<td></td>
<td>未分配节点的分片数量</td>
</tr>
<tr>
<td>elasticsearch_pending_tasks_priority_urgent</td>
<td></td>
<td>紧急优先未完成的 task 数量</td>
</tr>
<tr>
<td>elasticsearch_pending_tasks_priority_high</td>
<td></td>
<td>高优先级的未完成的 task 数量</td>
</tr>
<tr>
<td>elasticsearch_cluster_status</td>
<td></td>
<td>集群健康数字红=0 黄=1 绿=2</td>
</tr>
<tr>
<td>elasticsearch_relocating_shards</td>
<td></td>
<td>节点搬到另一个节点的分片数量</td>
</tr>
<tr>
<td>elasticsearch_number_of_data_nodes</td>
<td></td>
<td>集群中 node 数据总数</td>
</tr>
<tr>
<td>elasticsearch_number_of_nodes</td>
<td></td>
<td>集群中 node 总数</td>
</tr>
<tr>
<td>elasticsearch_active_shards</td>
<td></td>
<td>集群中活跃分片数量</td>
</tr>
<tr>
<td>elasticsearch_initializing_shards</td>
<td></td>
<td>当前初始化碎片数量</td>
</tr>
</tbody>
</table>
<h3 id="kafka">Kafka 插件</h3>
<h4 id="_13">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>kafka_replication_leader_elections_rate</td>
<td></td>
<td>leader 选举频率</td>
</tr>
<tr>
<td>kafka_replication_isr_shrinks_rate</td>
<td>nodes/s</td>
<td>副本离开 ISR 池的速率</td>
</tr>
<tr>
<td>kafka_request_handler_avg_idle_pct_rate</td>
<td></td>
<td>处理请求线程时间百分比</td>
</tr>
<tr>
<td>kafka_net_bytes_out_rate</td>
<td>bytes/s</td>
<td>传出字节速率</td>
</tr>
<tr>
<td>kafka_net_bytes_rejected_rate</td>
<td>bytes/s</td>
<td>被拒绝的字节速率</td>
</tr>
<tr>
<td>kafka_messages_in_rate</td>
<td></td>
<td>传入消息速率</td>
</tr>
<tr>
<td>kafka_net_bytes_in_rate</td>
<td>bytes/s</td>
<td>传入字节速率</td>
</tr>
<tr>
<td>kafka_request_fetch_failed_rate</td>
<td></td>
<td>客户端请求失败次数</td>
</tr>
<tr>
<td>kafka_replication_unclean_leader_elections_rate</td>
<td></td>
<td>unleader 选举频率</td>
</tr>
<tr>
<td>kafka_replication_isr_expands_rate</td>
<td>nodes/s</td>
<td>副本加入 ISR 池的速率</td>
</tr>
<tr>
<td>kafka_request_produce_failed_rate</td>
<td></td>
<td>失败的 produce 请求数</td>
</tr>
<tr>
<td>kafka_request_produce_time_99percentile</td>
<td>ms</td>
<td>99%produce 请求时间</td>
</tr>
<tr>
<td>kafka_request_metadata_time_99percentile</td>
<td>ms</td>
<td>99%元数据请求时间</td>
</tr>
<tr>
<td>kafka_request_update_metadata_time_99percentile</td>
<td>ms</td>
<td>更新 99%元数据请求的时间</td>
</tr>
<tr>
<td>kafka_request_produce_time_avg</td>
<td>ms</td>
<td>produce 请求数的时间</td>
</tr>
<tr>
<td>kafka_request_update_metadata_time_avg</td>
<td>ms</td>
<td>更新元数据请求的时间</td>
</tr>
<tr>
<td>kafka_request_produce_rate</td>
<td></td>
<td>produce 请求数</td>
</tr>
<tr>
<td>kafka_request_metadata_time_avg</td>
<td>ms</td>
<td>元数据平均请求时间</td>
</tr>
</tbody>
</table>
<h3 id="mongodb">Mongodb 插件</h3>
<h4 id="_14">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>mongodb_replset_health</td>
<td></td>
<td>副本集状态</td>
</tr>
<tr>
<td>mongodb_metrics_repl_network_readerscreated</td>
<td></td>
<td>oplog 查询进程创建的个数</td>
</tr>
<tr>
<td>mongodb_opcounters_insert</td>
<td></td>
<td>插入操作的次数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_network_getmores_totalmillis</td>
<td>ms/s</td>
<td>getmore 操作收集数据时间</td>
</tr>
<tr>
<td>mongodb_metrics_repl_buffer_count</td>
<td></td>
<td>oplog 缓存中的操作数</td>
</tr>
<tr>
<td>mongodb_metrics_getlasterror_wtime_totalmillis</td>
<td>ms/s</td>
<td>执行获取最后错误操作的时间</td>
</tr>
<tr>
<td>mongodb_metrics_repl_network_getmores_num</td>
<td></td>
<td>getmore 操作的个数</td>
</tr>
<tr>
<td>mongodb_connections_available</td>
<td></td>
<td>未使用的可用连接数</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_delete</td>
<td></td>
<td>副本集删除操作的次数</td>
</tr>
<tr>
<td>mongodb_asserts_regular</td>
<td></td>
<td>常规断言数</td>
</tr>
<tr>
<td>mongodb_metrics_queryexecutor_scanned</td>
<td></td>
<td>被扫描的索引个数</td>
</tr>
<tr>
<td>mongodb_asserts_msg</td>
<td></td>
<td>消息断言数</td>
</tr>
<tr>
<td>mongodb_mem_mapped</td>
<td>MB</td>
<td>数据库映射的内存总数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_network_bytes</td>
<td>MB</td>
<td>从服务器同步源读取的数据总量</td>
</tr>
<tr>
<td>mongodb_metrics_record_moves</td>
<td></td>
<td>文档在磁盘上移动的次数</td>
</tr>
<tr>
<td>mongodb_opcounters_query</td>
<td></td>
<td>查询操作的次数</td>
</tr>
<tr>
<td>mongodb_uptime</td>
<td>s</td>
<td>mongo 进程启动时长</td>
</tr>
<tr>
<td>mongodb_opcounters_delete</td>
<td></td>
<td>删除操作的次数</td>
</tr>
<tr>
<td>mongodb_metrics_getlasterror_wtime_num</td>
<td></td>
<td>写操作获取最后错误操作的次数</td>
</tr>
<tr>
<td>mongodb_metrics_operation_fastmod</td>
<td></td>
<td>不导致更新操作的次数</td>
</tr>
<tr>
<td>mongodb_metrics_document_updated</td>
<td></td>
<td>文档更新数</td>
</tr>
<tr>
<td>mongodb_mem_resident</td>
<td>MB</td>
<td>数据库进程在使用的内存总数</td>
</tr>
<tr>
<td>mongodb_mem_virtual</td>
<td>MB</td>
<td>数据库进程使用的虚拟内存总数</td>
</tr>
<tr>
<td>mongodb_asserts_user</td>
<td></td>
<td>用户断言数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_apply_batches_totalmillis</td>
<td>ms/s</td>
<td>执行来自 oplog 的操作的时间</td>
</tr>
<tr>
<td>mongodb_metrics_document_inserted</td>
<td></td>
<td>文档增加数</td>
</tr>
<tr>
<td>mongodb_globallock_currentqueue_writers</td>
<td></td>
<td>当前在队列中等待写锁的操作数</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_query</td>
<td></td>
<td>副本集查询操作的次数</td>
</tr>
<tr>
<td>mongodb_metrics_operation_scanandorder</td>
<td></td>
<td>返回不能索引排序数字请求次数</td>
</tr>
<tr>
<td>mongodb_connections_totalcreated</td>
<td></td>
<td>所有连接数</td>
</tr>
<tr>
<td>mongodb_metrics_operation_idhack</td>
<td></td>
<td>包含_id 字段的请求次数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_buffer_sizebytes</td>
<td>MB</td>
<td>oplog 缓存的大小</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_command</td>
<td></td>
<td>命令的总数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_buffer_maxsizebytes</td>
<td>MB</td>
<td>缓存的最大值</td>
</tr>
<tr>
<td>mongodb_metrics_document_returned</td>
<td></td>
<td>文档被请求返回数</td>
</tr>
<tr>
<td>mongodb_metrics_ttl_deleteddocuments</td>
<td></td>
<td>有 ttl 索引删除的文档数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_network_ops</td>
<td></td>
<td>读取操作的个数</td>
</tr>
<tr>
<td>mongodb_metrics_document_deleted</td>
<td></td>
<td>文档删除数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_apply_batches_num</td>
<td></td>
<td>批处理的个数</td>
</tr>
<tr>
<td>mongodb_asserts_rollovers</td>
<td></td>
<td>计数器 rollover 次数</td>
</tr>
<tr>
<td>mongodb_opcounters_command</td>
<td></td>
<td>传给数据库的命令的总数</td>
</tr>
<tr>
<td>mongodb_globallock_totaltime</td>
<td>μs</td>
<td>全局锁启动时长</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_insert</td>
<td></td>
<td>副本集插入操作的次数</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_getmore</td>
<td></td>
<td>副本集 getmore 操作的次数</td>
</tr>
<tr>
<td>mongodb_opcountersrepl_update</td>
<td></td>
<td>副本集更新操作的次数</td>
</tr>
<tr>
<td>mongodb_opcounters_update</td>
<td></td>
<td>更新操作的次数</td>
</tr>
<tr>
<td>mongodb_asserts_warning</td>
<td></td>
<td>警告断言数</td>
</tr>
<tr>
<td>mongodb_opcounters_getmore</td>
<td></td>
<td>getmore 操作的次数</td>
</tr>
<tr>
<td>mongodb_globallock_currentqueue_total</td>
<td></td>
<td>当前在队列中等待锁的操作数</td>
</tr>
<tr>
<td>mongodb_metrics_repl_apply_ops</td>
<td></td>
<td>执行的 oplog 操作的个数</td>
</tr>
<tr>
<td>mongodb_metrics_ttl_passes</td>
<td></td>
<td>删除文档次数</td>
</tr>
<tr>
<td>mongodb_connections_current</td>
<td></td>
<td>从客户端到数据库服务端的连接数</td>
</tr>
<tr>
<td>mongodb_metrics_getlasterror_wtimeouts</td>
<td></td>
<td>超时导致操作数</td>
</tr>
<tr>
<td>mongodb_globallock_currentqueue_readers</td>
<td></td>
<td>当前在队列中等待读锁的操作数</td>
</tr>
<tr>
<td>mongodb_stats_indexsize</td>
<td></td>
<td>库中所有创建的索引总数</td>
</tr>
<tr>
<td>mongodb_stats_objects</td>
<td></td>
<td>库中所有的文档数</td>
</tr>
<tr>
<td>mongodb_stats_indexes</td>
<td></td>
<td>库中总索引数</td>
</tr>
<tr>
<td>mongodb_stats_storagesize</td>
<td>MB</td>
<td>collections 存储空间</td>
</tr>
<tr>
<td>mongodb_stats_datasize</td>
<td>MB</td>
<td>库中的数据量</td>
</tr>
</tbody>
</table>
<h3 id="ceph">Ceph 插件</h3>
<h4 id="_15">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>ceph_num_in_osds</td>
<td></td>
<td>参与存储守护进程的数量</td>
</tr>
<tr>
<td>ceph_aggregate_pct_used</td>
<td>%</td>
<td>总体容量使用量</td>
</tr>
<tr>
<td>ceph_num_up_osds</td>
<td></td>
<td>在线存储守护进程的数量</td>
</tr>
<tr>
<td>ceph_num_mons</td>
<td></td>
<td>监视器守护进程的数量</td>
</tr>
<tr>
<td>ceph_num_pools</td>
<td></td>
<td>存储池的数量</td>
</tr>
<tr>
<td>ceph_pgstate_active_clean</td>
<td></td>
<td>活动归置组数量</td>
</tr>
<tr>
<td>ceph_num_pgs</td>
<td></td>
<td>可用归置组的数量</td>
</tr>
<tr>
<td>ceph_num_near_full_osds</td>
<td></td>
<td>几乎完整的 osd 数量</td>
</tr>
<tr>
<td>ceph_num_full_osds</td>
<td></td>
<td>完整 osd 数量</td>
</tr>
<tr>
<td>ceph_total_objects</td>
<td></td>
<td>对象总数</td>
</tr>
<tr>
<td>ceph_num_osds</td>
<td></td>
<td>已知存储守护进程的数量</td>
</tr>
<tr>
<td>ceph_read_op_per_sec</td>
<td>MB/s</td>
<td>存储池每秒读字节数</td>
</tr>
<tr>
<td>ceph_num_objects</td>
<td></td>
<td>对象个数</td>
</tr>
<tr>
<td>ceph_write_op_per_sec</td>
<td>MB/s</td>
<td>存储池每秒写字节数</td>
</tr>
<tr>
<td>ceph_write_bytes_sec</td>
<td>MB/s</td>
<td>ceph 每秒写字节数</td>
</tr>
<tr>
<td>ceph_read_bytes_sec</td>
<td>MB/s</td>
<td>ceph 每秒读字节数</td>
</tr>
<tr>
<td>ceph_pct_used</td>
<td>%</td>
<td>使用量</td>
</tr>
<tr>
<td>ceph_op_per_sec</td>
<td></td>
<td>池每秒 IO 操作</td>
</tr>
<tr>
<td>ceph_apply_latency_ms</td>
<td>s</td>
<td>磁盘更新所需时间</td>
</tr>
<tr>
<td>ceph_commit_latency_ms</td>
<td>s</td>
<td>日志操作所需时间</td>
</tr>
</tbody>
</table>
<h2 id="jmx">JMX 插件</h2>
<h3 id="jmx_1">JMX 组件</h3>
<h4 id="_16">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>jvm_buffer_pool_used_bytes</td>
<td>MB</td>
<td>已使用缓冲池的大小</td>
</tr>
<tr>
<td>jvm_buffer_pool_capacity_bytes</td>
<td>MB</td>
<td>缓冲池的字节容量</td>
</tr>
<tr>
<td>jvm_buffer_pool_used_buffers</td>
<td></td>
<td>已经使用的缓冲数量</td>
</tr>
<tr>
<td>jmx_config_reload_success_total</td>
<td></td>
<td>已成功重新加载配置的次数</td>
</tr>
<tr>
<td>jvm_threads_current</td>
<td></td>
<td>当前线程数</td>
</tr>
<tr>
<td>jvm_threads_daemon</td>
<td></td>
<td>当前后台线程数</td>
</tr>
<tr>
<td>jvm_threads_peak</td>
<td></td>
<td>当前峰值线程数</td>
</tr>
<tr>
<td>jvm_threads_started_total</td>
<td></td>
<td>已经启动的线程计数</td>
</tr>
<tr>
<td>jvm_threads_deadlocked</td>
<td></td>
<td>等待获取对象监视器或自己的同步器的死锁线程数</td>
</tr>
<tr>
<td>jvm_threads_deadlocked_monitor</td>
<td></td>
<td>等待获取对象监视器的死锁线程数</td>
</tr>
<tr>
<td>jmx_scrape_duration_seconds</td>
<td>秒</td>
<td>scrape 的时间</td>
</tr>
<tr>
<td>jmx_scrape_error</td>
<td></td>
<td>scrape 失败次数</td>
</tr>
<tr>
<td>jvm_classes_loaded</td>
<td></td>
<td>当前加载的类数量</td>
</tr>
<tr>
<td>jvm_classes_loaded_total</td>
<td></td>
<td>从 JVM 开始执行以来已经加载的类的总数</td>
</tr>
<tr>
<td>jvm_classes_unloaded_total</td>
<td></td>
<td>从 JVM 开始执行以来未加载的类的总数</td>
</tr>
<tr>
<td>jvm_info</td>
<td></td>
<td>JVM 版本信息</td>
</tr>
<tr>
<td>jvm_memory_bytes_used</td>
<td>MB</td>
<td>已经使用的内存</td>
</tr>
<tr>
<td>jvm_memory_bytes_committed</td>
<td>MB</td>
<td>已经提交的内存</td>
</tr>
<tr>
<td>jvm_memory_bytes_max</td>
<td>MB</td>
<td>最大内存</td>
</tr>
<tr>
<td>jvm_memory_bytes_init</td>
<td>MB</td>
<td>初始化内存</td>
</tr>
<tr>
<td>jvm_memory_pool_bytes_used</td>
<td>MB</td>
<td>内存池中已经使用的内存</td>
</tr>
<tr>
<td>jvm_memory_pool_bytes_committed</td>
<td>MB</td>
<td>内存池中已经提交的内存</td>
</tr>
<tr>
<td>jvm_memory_pool_bytes_max</td>
<td>MB</td>
<td>内存池中最大内存</td>
</tr>
<tr>
<td>jvm_memory_pool_bytes_init</td>
<td>MB</td>
<td>内存池中初始化内存</td>
</tr>
<tr>
<td>jmx_config_reload_failure_total</td>
<td></td>
<td>配置 reload 失败的次数</td>
</tr>
<tr>
<td>jvm_gc_collection_seconds_count</td>
<td>秒</td>
<td>gc 时间</td>
</tr>
</tbody>
</table>
<h3 id="tomcat">Tomcat 插件</h3>
<h4 id="_17">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>tomcat.bytes_rcvd</td>
<td>bytes/second</td>
<td>每秒接收的字节数</td>
</tr>
<tr>
<td>tomcat.bytes_sent</td>
<td>bytes/second</td>
<td>每秒发送的字节数</td>
</tr>
<tr>
<td>tomcat.cache.access_count</td>
<td>gets/second</td>
<td>每秒访问缓存的次数</td>
</tr>
<tr>
<td>tomcat.cache.hits_count</td>
<td>hits/second</td>
<td>每秒缓冲命中的次数</td>
</tr>
<tr>
<td>tomcat.error_count</td>
<td>errors/second</td>
<td>发生错误的请求数</td>
</tr>
<tr>
<td>tomcat.jsp.count</td>
<td>pages/second</td>
<td>web 模块中加载的 JSP 数量</td>
</tr>
<tr>
<td>tomcat.jsp.reload_count</td>
<td>pages/second</td>
<td>web 模块中重新加载的 JSP 数量</td>
</tr>
<tr>
<td>tomcat.max_time</td>
<td>milliseconds</td>
<td>最长的请求处理时间 (milliseconds)</td>
</tr>
<tr>
<td>tomcat.processing_time</td>
<td></td>
<td>每秒所有请求的处理时间之和</td>
</tr>
<tr>
<td>tomcat.request_count</td>
<td>requests/second</td>
<td>每秒总请求数</td>
</tr>
<tr>
<td>tomcat.servlet.error_count</td>
<td>errors/second</td>
<td>servlet 接收的错误请求数 /s</td>
</tr>
<tr>
<td>tomcat.servlet.processing_time</td>
<td></td>
<td>每秒经过 servlet 的所有请求的处理时间之和</td>
</tr>
<tr>
<td>tomcat.servlet.request_count</td>
<td>requests/second</td>
<td>每秒经过 servlet 的总请求数</td>
</tr>
<tr>
<td>tomcat.threads.busy</td>
<td>threads</td>
<td>正在使用的线程数</td>
</tr>
<tr>
<td>tomcat.threads.count</td>
<td>threads</td>
<td>当前线程池的线程数</td>
</tr>
<tr>
<td>tomcat.threads.max</td>
<td>threads</td>
<td>线程池最大可以产生的线程数</td>
</tr>
</tbody>
</table>
<h2 id="datadog">DataDog 插件</h2>
<h2 id="bk-pull">BK-Pull 插件</h2>
<h3 id="weblogic">Weblogic 插件</h3>
<h4 id="_18">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>weblogic.config.webapp_config_deployment_state</td>
<td></td>
<td>部署状态，当前应用的部署状态，如正在部署、部署失败、部署成功等</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_jsppage_check_secs</td>
<td></td>
<td>检查 JSP 文件是否发生更改并需要重新编译的频率</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_open_sessions_current_count</td>
<td></td>
<td>应用程序当前会话数</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_open_sessions_high_count</td>
<td></td>
<td>应用程序最高会话数</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_servlet_reload_check_secs</td>
<td></td>
<td>检查 servlet 是否已被修改的频率</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_session_cookie_max_age_secs</td>
<td>s</td>
<td>会话缓存保留时长</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_session_idlength</td>
<td></td>
<td>会话 id 长度(数字位数)</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_session_invalidation_interval_secs</td>
<td>s</td>
<td>将超时和无效会话释放前等待的时间</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_session_timeout_secs</td>
<td>s</td>
<td>会话超时设置</td>
</tr>
<tr>
<td>weblogic.config.webapp_config_sessions_opened_total_count</td>
<td></td>
<td>应用程序会话打开数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_execution_time_average</td>
<td>s</td>
<td>执行各个 servlet 调用的平均时长</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_execution_time_high</td>
<td>s</td>
<td>执行最长 servlet 调用的时长</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_execution_time_low</td>
<td>s</td>
<td>执行最短 servlet 调用的时长</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_execution_time_total</td>
<td>s</td>
<td>执行完所有 servlet 调用的时长</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_invocation_total_count</td>
<td></td>
<td>servlet 调用总次数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_pool_max_capacity</td>
<td></td>
<td>servlet 池的线程最大容量</td>
</tr>
<tr>
<td>weblogic.wls_servlet.weblogic_servlet_reload_total_count</td>
<td></td>
<td>servlet 重载的次数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.workmanager.workmanager_completed_daemon_requests</td>
<td></td>
<td>已处理的守护请求数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.workmanager.workmanager_completed_requests</td>
<td></td>
<td>已处理的请求数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.workmanager.workmanager_pending_daemon_requests</td>
<td></td>
<td>挂起的守护请求数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.workmanager.workmanager_pending_requests</td>
<td></td>
<td>挂起的请求数/周期，周期指设置的数据采集周期</td>
</tr>
<tr>
<td>weblogic.workmanager.workmanager_stuck_thread_count</td>
<td></td>
<td>假死的线程数</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_heap_free_current</td>
<td>MB</td>
<td>堆内存空闲量</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_heap_free_percent</td>
<td>%</td>
<td>堆内存使用百分比</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_heap_size_current</td>
<td>MB</td>
<td>堆内存使用量</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_heap_size_max</td>
<td>MB</td>
<td>堆内存最大允许值</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_process_cpu_load</td>
<td></td>
<td>jvm 的 cpu 负载</td>
</tr>
<tr>
<td>weblogic.jvm.jvm_uptime</td>
<td>s</td>
<td>jvm 运行时长</td>
</tr>
</tbody>
</table>
<h3 id="consul">Consul 插件</h3>
<h4 id="_19">指标说明</h4>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>consul_net_node_latency_max</td>
<td>ms</td>
<td>从该节点到其他节点的最大延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_p25</td>
<td>ms</td>
<td>从该节点到其他节点的 p25 延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_p95</td>
<td>ms</td>
<td>从该节点到其他节点的 p95 延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_p90</td>
<td>ms</td>
<td>从该节点到其他节点的 p90 延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_p99</td>
<td>ms</td>
<td>从该节点到其他节点的 p99 延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_min</td>
<td>ms</td>
<td>从该节点到其他节点的最小延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_p75</td>
<td>ms</td>
<td>从该节点到其他节点的 p75 延迟</td>
</tr>
<tr>
<td>consul_net_node_latency_median</td>
<td>ms</td>
<td>从该节点到其他节点的中等延迟</td>
</tr>
<tr>
<td>consul_peers</td>
<td></td>
<td>对等体的数量</td>
</tr>
<tr>
<td>consul_catalog_nodes_warning</td>
<td></td>
<td>警告节点数量</td>
</tr>
<tr>
<td>consul_catalog_nodes_passing</td>
<td></td>
<td>传递节点数量</td>
</tr>
<tr>
<td>consul_catalog_nodes_up</td>
<td></td>
<td>节点数</td>
</tr>
<tr>
<td>consul_catalog_nodes_critical</td>
<td></td>
<td>关键节点数量</td>
</tr>
<tr>
<td>consul_catalog_services_critical</td>
<td></td>
<td>关键服务总数</td>
</tr>
<tr>
<td>consul_catalog_services_passing</td>
<td></td>
<td>传递服务总量</td>
</tr>
<tr>
<td>consul_catalog_services_up</td>
<td></td>
<td>服务总量</td>
</tr>
<tr>
<td>consul_catalog_services_warning</td>
<td></td>
<td>警告服务总数</td>
</tr>
</tbody>
</table>
<h2 id="iis">IIS 插件</h2>
<h3 id="_20">指标说明</h3>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>iis_httpd_request_method_options</td>
<td></td>
<td>options 方法请求数</td>
</tr>
<tr>
<td>iis_httpd_request_method_head</td>
<td></td>
<td>head 方法请求数</td>
</tr>
<tr>
<td>iis_httpd_request_method_del</td>
<td></td>
<td>del 方法请求数</td>
</tr>
<tr>
<td>iis_requests_cgi</td>
<td></td>
<td>cgi 请求执行数</td>
</tr>
<tr>
<td>iis_requests_isapi</td>
<td></td>
<td>isapi 请求执行数</td>
</tr>
<tr>
<td>iis_errors_not_found</td>
<td></td>
<td>文档未找到导致错误的速数</td>
</tr>
<tr>
<td>iis_net_files_rcvd</td>
<td></td>
<td>每秒接收的文件数</td>
</tr>
<tr>
<td>iis_httpd_request_method_put</td>
<td></td>
<td>put 方法请求数</td>
</tr>
<tr>
<td>iis_httpd_request_method_trace</td>
<td></td>
<td>trace 方法请求数</td>
</tr>
<tr>
<td>iis_net_connection_attempts</td>
<td></td>
<td>每秒尝试连接数</td>
</tr>
<tr>
<td>iis_users_nonanon</td>
<td></td>
<td>每秒非匿名用户的请求数</td>
</tr>
<tr>
<td>iis_net_bytes_total</td>
<td></td>
<td>每秒传输的字节总数</td>
</tr>
<tr>
<td>iis_net_bytes_rcvd</td>
<td></td>
<td>每秒接收的字节数</td>
</tr>
<tr>
<td>iis_net_bytes_sent</td>
<td></td>
<td>每秒发送的字节数</td>
</tr>
<tr>
<td>iis_net_num_connections</td>
<td></td>
<td>活跃连接数</td>
</tr>
<tr>
<td>iis_errors_locked</td>
<td></td>
<td>文档锁定导致的错误数</td>
</tr>
<tr>
<td>iis_users_anon</td>
<td></td>
<td>每秒匿名用户的请求数</td>
</tr>
<tr>
<td>iis_net_files_sent</td>
<td></td>
<td>每秒发送的文件数</td>
</tr>
<tr>
<td>iis_httpd_request_method_post</td>
<td></td>
<td>post 方法请求数</td>
</tr>
<tr>
<td>iis_httpd_request_method_get</td>
<td></td>
<td>get 方法请求数</td>
</tr>
<tr>
<td>iis_uptime</td>
<td></td>
<td>iis 服务器运行时间</td>
</tr>
</tbody>
</table>
<h2 id="active_directory">Active_Directory 插件</h2>
<h3 id="_21">指标说明</h3>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>active_directory_dra_outbound_values_dns_persec</td>
<td></td>
<td>发到复制伙伴 DN 属性值数量/s</td>
</tr>
<tr>
<td>active_directory_dra_outbound_bytes_total</td>
<td></td>
<td>发送到复制伙伴的总字节数</td>
</tr>
<tr>
<td>active_directory_ldap_searches_persec</td>
<td></td>
<td>LDAP 客户端执行搜索操作速率</td>
</tr>
<tr>
<td>active_directory_dra_inbound_values_dns_persec</td>
<td></td>
<td>从复制伙伴接收 DN 属性值数/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_bytes_total</td>
<td></td>
<td>从复制伙伴接收的总字节数</td>
</tr>
<tr>
<td>active_directory_dra_outbound_values_total_persec</td>
<td></td>
<td>发送到复制伙伴对象属性值数/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_objects_remaining</td>
<td></td>
<td>未完成同步的对象数量</td>
</tr>
<tr>
<td>active_directory_dra_inbound_properties_filtered_p</td>
<td></td>
<td>不需要进行更新的对象数量</td>
</tr>
<tr>
<td>active_directory_dra_outbound_objects_persec</td>
<td></td>
<td>发送到复制伙伴的对象数量/s</td>
</tr>
<tr>
<td>active_directory_ds_threads_in_use</td>
<td></td>
<td>目录服务当前使用的线程数</td>
</tr>
<tr>
<td>active_directory_dra_inbound_properties_total_pers</td>
<td></td>
<td>从复制伙伴接收的对象属性总数</td>
</tr>
<tr>
<td>active_directory_dra_inbound_objects_applied_perse</td>
<td></td>
<td>从复制伙伴接收更新的应用速率</td>
</tr>
<tr>
<td>active_directory_dra_outbound_properties_persec</td>
<td></td>
<td>发送到复制伙伴的属性值数量/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_objects_remaining_in</td>
<td></td>
<td>未应用于本地服务器的对象更新数</td>
</tr>
<tr>
<td>active_directory_dra_inbound_bytes_after_compressi</td>
<td>Byte</td>
<td>从其他站点(每秒)的目录系统代理(DSA)入站的压缩复制数据的压缩大小(以字节为单位)</td>
</tr>
<tr>
<td>active_directory_dra_inbound_properties_applied_pe</td>
<td></td>
<td>入站复制应用对象属性更改数/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_values_total_persec</td>
<td></td>
<td>从复制伙伴接收对象属性值数/s</td>
</tr>
<tr>
<td>active_directory_ldap_successful_binds_persec</td>
<td></td>
<td>成功发生的 LDAP 绑定数/s</td>
</tr>
<tr>
<td>active_directory_dra_outbound_bytes_after_compress</td>
<td>Byte</td>
<td>压缩复制数据的压缩大小(以字节为单位)，其出站到其他站点中的 DSA(每秒)</td>
</tr>
<tr>
<td>active_directory_dra_replication_pending_synchroni</td>
<td></td>
<td>等待此服务器未处理目录同步数</td>
</tr>
<tr>
<td>active_directory_dra_outbound_objects_filtered_per</td>
<td></td>
<td>出站复制伙伴确认的对象数/s</td>
</tr>
<tr>
<td>active_directory_dra_outbound_bytes_before_compres</td>
<td>Byte</td>
<td>出站到其他站点的 DSA 数据/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_objects_persec</td>
<td></td>
<td>复制伙伴入站复制接收对象数/s</td>
</tr>
<tr>
<td>active_directory_dra_inbound_bytes_not_compressed</td>
<td>KB</td>
<td>同一站点其他 DSA 入站数据/s</td>
</tr>
<tr>
<td>active_directory_dra_sync_requests_made</td>
<td></td>
<td>启动后向复制伙伴发出同步请求数</td>
</tr>
<tr>
<td>active_directory_ldap_bind_time</td>
<td>ms</td>
<td>上次成功 LDAP 绑定所需时间</td>
</tr>
<tr>
<td>active_directory_dra_inbound_objects_filtered_pers</td>
<td></td>
<td>从复制伙伴接收的对象数/s</td>
</tr>
<tr>
<td>active_directory_dra_outbound_bytes_not_compressed</td>
<td>Byte</td>
<td>向同一站点中 DSA 出站数据大小</td>
</tr>
<tr>
<td>active_directory_ldap_client_sessions</td>
<td></td>
<td>已连接 LDAP 客户端的会话数</td>
</tr>
<tr>
<td>active_directory_dra_inbound_bytes_before_compress</td>
<td>Byte</td>
<td>其他站点 DSA 入站数据大小/s</td>
</tr>
</tbody>
</table>
<h2 id="exchange">Exchange 插件</h2>
<h3 id="_22">指标说明</h3>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>exchange_database_io_reads_avg_latency</td>
<td>ms</td>
<td>数据库读取操作的平均时间</td>
</tr>
<tr>
<td>exchange_database_io_db_reads_attached_persec</td>
<td></td>
<td>附加数据库每秒数据库读取操作数</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_waiters</td>
<td></td>
<td>正在等待获取信号的线程数量</td>
</tr>
<tr>
<td>exchange_adaccess_processes_ldap_search</td>
<td>ms</td>
<td>发送 LDAP 搜索请求响应的时间</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_hold_time</td>
<td>s</td>
<td>在上个示例中信号停留的平均时间</td>
</tr>
<tr>
<td>exchange_network_outbound_errors</td>
<td></td>
<td>因错误而无法传输的出站数据包数</td>
</tr>
<tr>
<td>exchange_adaccess_domain_controllers_ldap_search</td>
<td>ms</td>
<td>将 LDAP 读请求发送至域控制器接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_db_writes_attached_persec</td>
<td></td>
<td>显示每个附加数据库实例的每秒数据库写入操作数量</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_acquires</td>
<td></td>
<td>在安全通道连接的整个生命周期或自系统为 _Total 启动以来，获取信号的总次数</td>
</tr>
<tr>
<td>exchange_ws_current_connections_default_website</td>
<td></td>
<td>显示对默认网站建立的当前连接数，此数目对应于命中前端 CAS 服务器角色的连接数</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_timeouts</td>
<td></td>
<td>线程在安全通道连接的整个生命周期或自系统为 _Total 启动以来等待信号期间，线程超时的总次数</td>
</tr>
<tr>
<td>exchange_adaccess_processes_ldap_read</td>
<td></td>
<td>显示将 LDAP 读请求接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_log_writes_avg_latency</td>
<td></td>
<td>显示每个数据库实例每秒写入的日志数量。</td>
</tr>
<tr>
<td>exchange_database_io_db_writes_recovery_avg_latenc</td>
<td>ms</td>
<td>显示每个被动数据库写入操作的平均时间长度(毫秒)</td>
</tr>
<tr>
<td>exchange_adaccess_domain_controllers_ldap_read</td>
<td>ms</td>
<td>显示将 LDAP 读请求发送至指定域控制器并接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_log_writes_persec</td>
<td></td>
<td>显示每个数据库实例每秒写入的日志数量</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_holders</td>
<td></td>
<td>存放信号的线程数量</td>
</tr>
<tr>
<td>exchange_database_io_db_reads_recovery_avg_latency</td>
<td>ms</td>
<td>显示每个被动数据库读取操作的平均时间长度</td>
</tr>
<tr>
<td>exchange_database_io_writes_avg_latency</td>
<td>ms</td>
<td>显示每个数据库写入操作的平均时间长度(毫秒)</td>
</tr>
<tr>
<td>exchange_is_store_rpc_latency</td>
<td>ms</td>
<td>RPC Latency average (msec) 是每个数据库的 RPC 请求的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_is_clienttype_rpc_latency</td>
<td>ms</td>
<td>显示针对某个特定客户端协议，过去 1024 个数据包的平均服务器 RPC 延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_is_clienttype_rpc_ops_persec</td>
<td>ms</td>
<td>显示每个客户端类型连接每秒的 RPC 操作数</td>
</tr>
<tr>
<td>exchange_is_store_rpc_requests</td>
<td>ms</td>
<td>指示当前在信息存储进程中执行的全部 RPC 请求</td>
</tr>
<tr>
<td>exchange_is_store_rpc_ops_persec</td>
<td>ms</td>
<td>显示每个数据库实例每秒的 RPC 操作数</td>
</tr>
<tr>
<td>exchange_activemanager_database_mounted</td>
<td></td>
<td>服务器上活动数据库副本的数量。</td>
</tr>
<tr>
<td>exchange_ws_requests_persec</td>
<td></td>
<td>显示服务器上活动数据库副本的数量</td>
</tr>
<tr>
<td>exchange_network_tcpv6_connection_failures</td>
<td></td>
<td>显示当前状态为 ESTABLISHED 或 CLOSE-WAIT 的 TCP 连接的数目</td>
</tr>
<tr>
<td>exchange_memory_available</td>
<td>MB</td>
<td>显示可立即分配给进程或供系统使用的物理内存量 (MB)</td>
</tr>
<tr>
<td>exchange_ws_current_connections_total</td>
<td></td>
<td>当前与 Web 服务建立连接的数量</td>
</tr>
<tr>
<td>exchange_rpc_ops_persec</td>
<td></td>
<td>显示 RPC 操作发生的速率(每秒)</td>
</tr>
<tr>
<td>exchange_autodiscover_requests_persec</td>
<td></td>
<td>每秒处理自动发现服务请求数</td>
</tr>
<tr>
<td>exchange_memory_committed</td>
<td>%</td>
<td>显示 Memory\Committed Bytes 与 Memory\Commit Limit 的比率</td>
</tr>
<tr>
<td>exchange_rpc_conn_count</td>
<td></td>
<td>显示所维护的客户端连接总数。</td>
</tr>
<tr>
<td>exchange_rpc_requests</td>
<td></td>
<td>显示 RPC 客户端访问服务当前正处理的客户端请求数</td>
</tr>
<tr>
<td>exchange_rpc_averaged_latency</td>
<td></td>
<td>显示过去 1024 个数据包的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_processor_queue_length</td>
<td></td>
<td>表示每个处理器所服务的线程数</td>
</tr>
<tr>
<td>exchange_network_tcpv4_conns_reset</td>
<td></td>
<td>显示 TCP 连接直接从 ESTABLISHED 状态或 CLOSE-WAIT 状态转换为 CLOSED 状态的次数</td>
</tr>
<tr>
<td>exchange_activesync_sync_persec</td>
<td></td>
<td>显示每秒处理的同步命令数</td>
</tr>
<tr>
<td>exchange_activesync_ping_pending</td>
<td></td>
<td>显示队列中当前挂起的 ping 命令数</td>
</tr>
<tr>
<td>exchange_ws_other_attempts</td>
<td></td>
<td>显示没有使用 OPTIONS、GET、HEAD、POST、PUT、DELETE、TRACE、MOVE、COPY、MKCOL、PROPFIND、PROPPATCH、SEARCH、LOCK 或 UNLOCK 方法发出 HTTP 请求的速率</td>
</tr>
<tr>
<td>exchange_ws_connection_attempts</td>
<td></td>
<td>显示尝试连接到 Web 服务的速率</td>
</tr>
<tr>
<td>exchange_processor_cpu_time</td>
<td></td>
<td>显示处理器执行应用程序或操作系统进程的时间的百分比</td>
</tr>
<tr>
<td>exchange_activesync_requests_persec</td>
<td></td>
<td>显示每秒通过 ASP.NET 从客户端接收到的 HTTP 请求数</td>
</tr>
<tr>
<td>exchange_rpc_active_user_count</td>
<td></td>
<td>显示最近 2 分钟之内进行过某些活动的唯一用户数</td>
</tr>
<tr>
<td>exchange_processor_cpu_privileged</td>
<td></td>
<td>显示花在特权模式上的处理器时间的百分比</td>
</tr>
<tr>
<td>exchange_owa_unique_users</td>
<td></td>
<td>显示当前登录到 Outlook Web App 的唯一用户数</td>
</tr>
<tr>
<td>exchange_owa_requests_persec</td>
<td></td>
<td>显示每秒由 Outlook Web App 处理的请求数</td>
</tr>
<tr>
<td>exchange_network_tcpv6_conns_reset</td>
<td></td>
<td>TCP 连接直接从 ESTABLISHED 状态或 CLOSE-WAIT 状态转换为 CLOSED 状态的次数</td>
</tr>
<tr>
<td>exchange_processor_cpu_user</td>
<td>%</td>
<td>在用户模式上处理器时间的百分比</td>
</tr>
<tr>
<td>exchange_rpc_user_count</td>
<td></td>
<td>显示连接到服务的用户数</td>
</tr>
<tr>
<td>exchange_ab_nspi_rpc_browse_requests_avg_latency</td>
<td>ms</td>
<td>采样完成浏览请求平均时间</td>
</tr>
<tr>
<td>exchange_ab_nspi_rpc_requests_avg_latency</td>
<td>ms</td>
<td>采样完成 NSPI 请求平均时间</td>
</tr>
<tr>
<td>exchange_ab_referral_rpc_requests_avg_latency</td>
<td>ms</td>
<td>采样完成引用请求平均时间</td>
</tr>
<tr>
<td>exchange_ab_nspi_connections_current</td>
<td></td>
<td>当前连接服务器 NSPI 客户端数</td>
</tr>
<tr>
<td>exchange_ab_nspi_connections_per</td>
<td></td>
<td>每秒连接服务器 NSPI 客户端数</td>
</tr>
<tr>
<td>exchange_ab_nspi_rpc_requests_per</td>
<td></td>
<td>NSPI 请求发生的速率/s</td>
</tr>
<tr>
<td>exchange_ab_referral_rpc_requests_per</td>
<td></td>
<td>引用请求发生的速率/s</td>
</tr>
<tr>
<td>exchange_is_store_rpc_client_backoff_per</td>
<td></td>
<td>指示发生客户端回退的速率</td>
</tr>
<tr>
<td>exchange_availability_service_avg_time_to_Process</td>
<td>s</td>
<td>处理忙/闲请求的平均时间</td>
</tr>
<tr>
<td>exchange_panel_asp_net_request_failures_per</td>
<td></td>
<td>控制面板中的 ASP.NET 每秒所检测到的失败数</td>
</tr>
<tr>
<td>exchange_panel_sign_on_inbound_proxy_requests_per</td>
<td></td>
<td>显示从主客户端访问服务器每秒接收到的显式登录请求数</td>
</tr>
<tr>
<td>exchange_panel_sign_on_inbound_proxy_sessions_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒加载的显式登录入站代理会话数</td>
</tr>
<tr>
<td>exchange_panel_sign_on_outbound_proxy_requests_per</td>
<td></td>
<td>显示向辅助客户端访问服务器每秒发送的显式登录请求数。</td>
</tr>
<tr>
<td>exchange_panel_inbound_proxy_requests_per</td>
<td></td>
<td>显示从主客户端访问服务器每秒接收到的请求数。</td>
</tr>
<tr>
<td>exchange_panel_inbound_proxy_sessions_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒加载的入站代理会话数</td>
</tr>
<tr>
<td>exchange_panel_outbound_proxy_requests_avg_time</td>
<td></td>
<td>显示采样期间完成发送给辅助客户端访问服务器的请求所花费的平均时间(毫秒)。</td>
</tr>
<tr>
<td>exchange_panel_outbound_proxy_requests_per</td>
<td></td>
<td>显示向辅助客户端访问服务器每秒发送的请求数。</td>
</tr>
<tr>
<td>exchange_panel_outbound_proxy_sessions_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒加载的出站代理会话数</td>
</tr>
<tr>
<td>exchange_panel_powershell_runspace_activations_per</td>
<td></td>
<td>显示在 Windows 控制面板中每秒激活的 Exchange PowerShell 运行空间数</td>
</tr>
<tr>
<td>exchange_panel_powershell_runspace_avg_active_time</td>
<td></td>
<td>显示采样期间在 Exchange 控制面板中执行 cmdlet 时，Windows PowerShell 运行空间处于活动状态的平均时间(秒)</td>
</tr>
<tr>
<td>exchange_panel_powershell_runspaces_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒创建的 Windows PowerShell 运行空间数</td>
</tr>
<tr>
<td>exchange_panel_rbac_sessions_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒加载的 RBAC 会话数</td>
</tr>
<tr>
<td>exchange_panel_requests_activations_per</td>
<td></td>
<td>显示在 Exchange 控制面板中每秒激活的请求数。</td>
</tr>
<tr>
<td>exchange_panel_requests_avg_response_time</td>
<td></td>
<td>期间 Exchange 控制面板响应请求所花费的平均时间(毫秒)。</td>
</tr>
</tbody>
</table>
<h3 id="exchange-2013">Exchange 2013 指标说明</h3>
<table>
<thead>
<tr>
<th>指标</th>
<th>单位</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>exchange_database_io_reads_avg_latency</td>
<td>ms</td>
<td>数据库读取操作的平均时间</td>
</tr>
<tr>
<td>exchange_database_io_db_reads_attached_persec</td>
<td></td>
<td>附加数据库每秒数据库读取操作数</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_waiters</td>
<td></td>
<td>正在等待获取信号的线程数量</td>
</tr>
<tr>
<td>exchange_adaccess_processes_ldap_search</td>
<td>ms</td>
<td>发送 LDAP 搜索请求响应的时间</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_hold_time</td>
<td>s</td>
<td>在上个示例中信号停留的平均时间</td>
</tr>
<tr>
<td>exchange_network_outbound_errors</td>
<td></td>
<td>因错误而无法传输的出站数据包数</td>
</tr>
<tr>
<td>exchange_adaccess_domain_controllers_ldap_search</td>
<td>ms</td>
<td>将 LDAP 读请求发送至域控制器接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_db_writes_attached_persec</td>
<td></td>
<td>显示每个附加数据库实例的每秒数据库写入操作数量</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_acquires</td>
<td></td>
<td>在安全通道连接的整个生命周期或自系统为 _Total 启动以来，获取信号的总次数</td>
</tr>
<tr>
<td>exchange_ws_current_connections_default_website</td>
<td></td>
<td>显示对默认网站建立的当前连接数，此数目对应于命中前端 CAS 服务器角色的连接数</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_timeouts</td>
<td></td>
<td>线程在安全通道连接的整个生命周期或自系统为 _Total 启动以来等待信号期间，线程超时的总次数</td>
</tr>
<tr>
<td>exchange_adaccess_processes_ldap_read</td>
<td></td>
<td>显示将 LDAP 读请求接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_log_writes_avg_latency</td>
<td></td>
<td>显示每个数据库实例每秒写入的日志数量。</td>
</tr>
<tr>
<td>exchange_database_io_db_writes_recovery_avg_latenc</td>
<td>ms</td>
<td>显示每个被动数据库写入操作的平均时间长度(毫秒)</td>
</tr>
<tr>
<td>exchange_adaccess_domain_controllers_ldap_read</td>
<td>ms</td>
<td>显示将 LDAP 读请求发送至指定域控制器并接收响应的时间</td>
</tr>
<tr>
<td>exchange_database_io_log_writes_persec</td>
<td></td>
<td>显示每个数据库实例每秒写入的日志数量</td>
</tr>
<tr>
<td>exchange_netlogon_semaphore_holders</td>
<td></td>
<td>存放信号的线程数量</td>
</tr>
<tr>
<td>exchange_database_io_db_reads_recovery_avg_latency</td>
<td>ms</td>
<td>显示每个被动数据库读取操作的平均时间长度</td>
</tr>
<tr>
<td>exchange_database_io_writes_avg_latency</td>
<td>ms</td>
<td>显示每个数据库写入操作的平均时间长度(毫秒)</td>
</tr>
<tr>
<td>exchange_httpproxy_server_locator_latency</td>
<td>ms</td>
<td>显示 MailboxServerLocator Web 服务调用的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_httpproxy_clientaccess_processing_latency</td>
<td>ms</td>
<td>显示最近 200 个请求中 CAS 处理时间(不包括代理所花费时间)的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_httpproxy_proxy_requests_persec</td>
<td>ms</td>
<td>显示每秒处理的代理请求数</td>
</tr>
<tr>
<td>exchange_httpproxy_requests_persec</td>
<td>ms</td>
<td>显示每秒处理的请求数</td>
</tr>
<tr>
<td>exchange_httpproxy_mailbox_proxy_failure_rate</td>
<td>ms</td>
<td>显示最近 200 个示例中涉及此客户端访问服务器和 MBX 服务器之间失败的连接百分比</td>
</tr>
<tr>
<td>exchange_httpproxy_avg_auth_latency</td>
<td>ms</td>
<td>显示最近 200 个示例中对 CAS 请求进行身份验证所花费的平均时间</td>
</tr>
<tr>
<td>exchange_httpproxy_outstanding_requests</td>
<td>ms</td>
<td>显示并发未处理代理请求的数量</td>
</tr>
<tr>
<td>exchange_is_store_rpc_latency</td>
<td>ms</td>
<td>RPC Latency average (msec) 是每个数据库的 RPC 请求的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_is_clienttype_rpc_latency</td>
<td>ms</td>
<td>显示针对某个特定客户端协议，过去 1024 个数据包的平均服务器 RPC 延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_is_clienttype_rpc_ops_persec</td>
<td>ms</td>
<td>显示每个客户端类型连接每秒的 RPC 操作数</td>
</tr>
<tr>
<td>exchange_is_store_rpc_requests</td>
<td>ms</td>
<td>指示当前在信息存储进程中执行的全部 RPC 请求</td>
</tr>
<tr>
<td>exchange_is_store_rpc_ops_persec</td>
<td>ms</td>
<td>显示每个数据库实例每秒的 RPC 操作数</td>
</tr>
<tr>
<td>exchange_workload_management_completed_tasks</td>
<td>ms</td>
<td>显示当前正在排队等待处理的工作负载管理任务数</td>
</tr>
<tr>
<td>exchange_workload_management_queued_tasks</td>
<td>ms</td>
<td>显示已经完成的工作负载管理任务数</td>
</tr>
<tr>
<td>exchange_workload_management_active_tasks</td>
<td>ms</td>
<td>显示当前工作负载管理在后台运行的活动任务数</td>
</tr>
<tr>
<td>exchange_activemanager_database_mounted</td>
<td></td>
<td>服务器上活动数据库副本的数量。</td>
</tr>
<tr>
<td>exchange_ws_requests_persec</td>
<td></td>
<td>显示服务器上活动数据库副本的数量</td>
</tr>
<tr>
<td>exchange_network_tcpv6_connection_failures</td>
<td></td>
<td>显示当前状态为 ESTABLISHED 或 CLOSE-WAIT 的 TCP 连接的数目</td>
</tr>
<tr>
<td>exchange_memory_available</td>
<td>MB</td>
<td>显示可立即分配给进程或供系统使用的物理内存量 (MB)</td>
</tr>
<tr>
<td>exchange_ws_current_connections_total</td>
<td></td>
<td>当前与 Web 服务建立连接的数量</td>
</tr>
<tr>
<td>exchange_rpc_ops_persec</td>
<td></td>
<td>显示 RPC 操作发生的速率(每秒)</td>
</tr>
<tr>
<td>exchange_autodiscover_requests_persec</td>
<td></td>
<td>每秒处理自动发现服务请求数</td>
</tr>
<tr>
<td>exchange_memory_committed</td>
<td>%</td>
<td>显示 Memory\Committed Bytes 与 Memory\Commit Limit 的比率</td>
</tr>
<tr>
<td>exchange_rpc_conn_count</td>
<td></td>
<td>显示所维护的客户端连接总数。</td>
</tr>
<tr>
<td>exchange_rpc_requests</td>
<td></td>
<td>显示 RPC 客户端访问服务当前正处理的客户端请求数</td>
</tr>
<tr>
<td>exchange_rpc_averaged_latency</td>
<td></td>
<td>显示过去 1024 个数据包的平均延迟(毫秒)</td>
</tr>
<tr>
<td>exchange_processor_queue_length</td>
<td></td>
<td>表示每个处理器所服务的线程数</td>
</tr>
<tr>
<td>exchange_network_tcpv4_conns_reset</td>
<td></td>
<td>显示 TCP 连接直接从 ESTABLISHED 状态或 CLOSE-WAIT 状态转换为 CLOSED 状态的次数</td>
</tr>
<tr>
<td>exchange_activesync_sync_persec</td>
<td></td>
<td>显示每秒处理的同步命令数</td>
</tr>
<tr>
<td>exchange_activesync_ping_pending</td>
<td></td>
<td>显示队列中当前挂起的 ping 命令数</td>
</tr>
<tr>
<td>exchange_ws_other_attempts</td>
<td></td>
<td>显示没有使用 OPTIONS、GET、HEAD、POST、PUT、DELETE、TRACE、MOVE、COPY、MKCOL、PROPFIND、PROPPATCH、SEARCH、LOCK 或 UNLOCK 方法发出 HTTP 请求的速率</td>
</tr>
<tr>
<td>exchange_ws_connection_attempts</td>
<td></td>
<td>显示尝试连接到 Web 服务的速率</td>
</tr>
<tr>
<td>exchange_processor_cpu_time</td>
<td></td>
<td>显示处理器执行应用程序或操作系统进程的时间的百分比</td>
</tr>
<tr>
<td>exchange_activesync_requests_persec</td>
<td></td>
<td>显示每秒通过 ASP.NET 从客户端接收到的 HTTP 请求数</td>
</tr>
<tr>
<td>exchange_rpc_active_user_count</td>
<td></td>
<td>显示最近 2 分钟之内进行过某些活动的唯一用户数</td>
</tr>
<tr>
<td>exchange_processor_cpu_privileged</td>
<td></td>
<td>显示花在特权模式上的处理器时间的百分比</td>
</tr>
<tr>
<td>exchange_owa_unique_users</td>
<td></td>
<td>显示当前登录到 Outlook Web App 的唯一用户数</td>
</tr>
<tr>
<td>exchange_owa_requests_persec</td>
<td></td>
<td>显示每秒由 Outlook Web App 处理的请求数</td>
</tr>
<tr>
<td>exchange_network_tcpv6_conns_reset</td>
<td></td>
<td>TCP 连接直接从 ESTABLISHED 状态或 CLOSE-WAIT 状态转换为 CLOSED 状态的次数</td>
</tr>
<tr>
<td>exchange_processor_cpu_user</td>
<td>%</td>
<td>在用户模式上处理器时间的百分比</td>
</tr>
<tr>
<td>exchange_rpc_user_count</td>
<td></td>
<td>显示连接到服务的用户数</td>
</tr>
</tbody>
</table><h1 id="_1">内置策略</h1>
<ul>
<li>默认<code>主机-操作系统</code>策略详情：(需要调整，设置默认告警组)</li>
</ul>
<table>
<thead>
<tr>
<th>监控名称</th>
<th>类型</th>
<th>Linux</th>
<th>Windows</th>
<th>检测阈值</th>
<th>触发条件</th>
<th>收敛规则</th>
<th>通知</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU 总使用率</td>
<td>CPU</td>
<td>✔️</td>
<td>✔️</td>
<td>95%</td>
<td>5 周期 3 次</td>
<td>告警未恢复，24 小时内不再产生告警</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>磁盘使用率</td>
<td>磁盘</td>
<td>✔️</td>
<td>✔️</td>
<td>95%</td>
<td>5 周期 1 次</td>
<td>同上</td>
<td>微信、邮件、电话</td>
</tr>
<tr>
<td>磁盘 IO 使用率</td>
<td>磁盘</td>
<td>✔️</td>
<td>✔️</td>
<td>80%</td>
<td>5 周期 3 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>应用内存使用率</td>
<td>内存</td>
<td>✔️</td>
<td>✔️</td>
<td>90%</td>
<td>5 周期 3 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>Corefile 产生</td>
<td>事件</td>
<td>✔️</td>
<td>X</td>
<td></td>
<td>5 分钟 1 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>进程端口</td>
<td>事件</td>
<td>✔️</td>
<td>✔️</td>
<td></td>
<td>5 周期 1 次</td>
<td>同上</td>
<td>微信、邮件、电话</td>
</tr>
<tr>
<td>自定义字符型</td>
<td>事件</td>
<td>✔️</td>
<td>✔️</td>
<td></td>
<td>5 分钟 1 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>系统重新启动</td>
<td>事件</td>
<td>✔️</td>
<td>✔️</td>
<td></td>
<td>5 周期 1 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
<tr>
<td>磁盘只读</td>
<td>事件</td>
<td>✔️</td>
<td>X</td>
<td></td>
<td>20 分钟 1 次</td>
<td>同上</td>
<td>微信、邮件、电话</td>
</tr>
<tr>
<td>PING 不可达告警</td>
<td>事件</td>
<td>✔️</td>
<td>✔️</td>
<td></td>
<td>5 分钟 3 次</td>
<td>同上</td>
<td>微信、邮件、电话</td>
</tr>
<tr>
<td>Agent 心跳丢失</td>
<td>事件</td>
<td>✔️</td>
<td>✔️</td>
<td></td>
<td>10 分钟 1 次</td>
<td>同上</td>
<td>微信、邮件</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>事件类型告警逻辑说明</p>
<ul>
<li>Ping 告警：对所有纳入配置平台管理的主机定期进行 Ping 检查</li>
<li>磁盘只读告警：因某种故障原因导致磁盘呈只读状态，影响数据正常写入</li>
<li>Corefile 产生：程序异常 core 退出产生的相应 corefile 文件</li>
<li>磁盘写满：磁盘使用空间占比 100%</li>
<li>Agent 心跳丢失：GSE Server 无法正常监测到 Agent 的心跳产生的事件</li>
</ul>
</li>
<li>
<p>默认告警组</p>
<ul>
<li>default 默认包含 admin，告警通知渠道，邮件，微信。</li>
</ul>
</li>
</ul><h1 id="_1">算法说明</h1>
<p>检测算法是通过公式计算数据判断是否符合，符合即为异常点。当前提供了 8 种算法。本篇将介绍每种算法的工作原理，适用的场景和配置的方法。</p>
<ul>
<li>静态阈值</li>
<li>同比策略（简易）</li>
<li>同比策略（高级）</li>
<li>环比策略（简易）</li>
<li>环比策略（高级）</li>
<li>同比振幅</li>
<li>周比区间</li>
<li>环比振幅</li>
</ul>
<blockquote>
<p>注意： 一种检测算法只能添加一次。</p>
</blockquote>
<h2 id="_2">算法适用场景概览</h2>
<p>针对大部分的固定值类或者变化无周期性变化的可以使用静态阈值。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808205114651.jpg" /></p>
<p>针对周期性的曲线，不能以固定的值来进行判断的，可以根据周期特点选择适当的同比算法：</p>
<table>
<thead>
<tr>
<th>周期</th>
<th>算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>周</td>
<td>同比策略（简易）</td>
</tr>
<tr>
<td>日</td>
<td>同比策略（高级），同比区间，同比振幅</td>
</tr>
</tbody>
</table>
<p>不能以固定的值来进行判断，针对实时突增突降需求，可以选择环比算法：
- 环比策略（简易）
- 环比策略（高级）
- 环比振幅</p>
<ol>
<li>温水煮青蛙型 - 数据缓慢上升或下降使用 【同比区间】</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15807168374571.jpg" /></p>
<ol>
<li>突然爆发型 – 数据出现 5 分钟陡升或陡降 使用 【环比策略】或 【同比振幅】</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15807168458438.jpg" /></p>
<ol>
<li>水平限制型 – 数据不能上升或下降到某个数值 使用 【环比区间】</li>
</ol>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15807168553132.jpg" /></p>
<h2 id="_3">具体检测算法说明</h2>
<h3 id="_4">静态阈值</h3>
<p>静态阈值是最简单也是使用最普遍的检测算法，只要值满足条件即为异常。是一种固定的设定方法。大多数的都是以静态阈值为主。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808205114651.jpg" /></p>
<h4 id="_5">适用场景</h4>
<p>适用于许多场景，适用可以通过固定值进行异常判断的。如磁盘使用率检测，机器负载等。</p>
<h4 id="_6">配置方法</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15730238076864.jpg" /></p>
<h4 id="_7">实现原理</h4>
<pre class="codehilite"><code class="language-python">{value} {method} {threshold}

# value：当前值
# method：比较运算符(=，&gt;， &gt;=， &lt;， &lt;=, !=)
# threshold： 阈值
# 当前值 (value) 和阈值 (threshold) 进行比较运算

多条件时，使用and或or关联。 判断规则：or 之前为一组
例：
&gt;= 10 and &lt;= 100 or = 0 or &gt;= 120 and &lt;= 200
(&gt;= 10 and &lt;= 100) or (= 0)  or (&gt;= 120 and &lt;= 200)</code></pre>


<h3 id="_8">同比策略（简易）/同比策略（高级）</h3>
<h4 id="_9">适用场景</h4>
<p>适用于以周为周期的曲线场景。比如 pv、在线人数等</p>
<h4 id="_10">配置方法</h4>
<h4 id="_11">实现原理</h4>
<ul>
<li>同比策略（简易）</li>
</ul>
<pre class="codehilite"><code class="language-python">{value} &gt;= {history_value} * (100 + ceil) * 0.01)
or
{value} &lt;= {history_value} * (100 - floor) * 0.01)

# value：当前值
# history_value：上周同一时刻值
# ceil：升幅
# floor：降幅
# 当前值(value) 与上周同一时刻值 (history_value)进行升幅/降幅计算</code></pre>


<ul>
<li>
<p>示例：当 value(90)，ceil(100)，history_value(40)时，则判断为异常</p>
</li>
<li>
<p>同比策略（高级）</p>
</li>
</ul>
<pre class="codehilite"><code class="language-python"># 算法原理和同比策略（简易）一致，只是用来做比较的历史值含义不一样。
{value} &gt;= {history_value} * (100 + ceil) * 0.01)
or
{value} &lt;= {history_value} * (100 - floor) * 0.01)

# value：当前值
# history_value：前n天同一时刻绝对值的均值
# ceil：升幅
# floor：降幅
# 当前值(value) 与前n天同一时刻绝对值的均值 (history_value)进行升幅/降幅计算

# 前n天同一时刻绝对值的均值计算示例
以日期2019-08-26 12:00:00为例，如果n为7，历史时刻和对应值如下：</code></pre>


<table>
<thead>
<tr>
<th></th>
<th>时间</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2019-8-25 12:00:00</td>
<td>12</td>
</tr>
<tr>
<td>2</td>
<td>2019-8-24 12:00:00</td>
<td>-22</td>
</tr>
<tr>
<td>3</td>
<td>2019-8-23 12:00:00</td>
<td>32</td>
</tr>
<tr>
<td>4</td>
<td>2019-8-22 12:00:00</td>
<td>42</td>
</tr>
<tr>
<td>5</td>
<td>2019-8-21 12:00:00</td>
<td>52</td>
</tr>
<tr>
<td>6</td>
<td>2019-8-20 12:00:00</td>
<td>62</td>
</tr>
<tr>
<td>7</td>
<td>2019-8-19 12:00:00</td>
<td>72</td>
</tr>
</tbody>
</table>
<pre class="codehilite"><code class="language-python">取绝对值，因此所有的值为正数
history_value = (12 + 22 + 32 + 42 + 52 + 62 +72) / 7 = 42</code></pre>


<ul>
<li>示例：当 value(90)，ceil(100)，history_value(42)时，则判断为异常</li>
</ul>
<h3 id="_12">环比策略（简易）/环比策略（高级）</h3>
<h4 id="_13">适用场景</h4>
<ul>
<li>适用于需要检测数据陡增或陡降的场景。如交易成功率、接口访问成功率等</li>
</ul>
<h4 id="_14">配置方法</h4>
<h4 id="_15">实现原理</h4>
<ul>
<li>环比策略（简易）</li>
</ul>
<pre class="codehilite"><code class="language-python"># 算法原理和同比策略（简易）一致，只是用来做比较的历史值含义不一样。
{value} &gt;= {history_value} * (100 + ceil) * 0.01)
or
{value} &lt;= {history_value} * (100 - floor) * 0.01)

# value：当前值
# history_value：前一时刻值
# ceil：升幅
# floor：降幅
# 当前值(value) 与前一时刻值 (history_value)进行升幅/降幅计算</code></pre>


<ul>
<li>示例：当 value(90)，ceil(100)，history_value(40)时，则判断为异常</li>
<li>
<p>场景：适用于需要检测数据陡增或陡降的场景。如交易成功率、接口访问成功率等</p>
</li>
<li>
<p>环比策略（高级）</p>
</li>
<li>
<p>实现原理：</p>
</li>
</ul>
<pre class="codehilite"><code class="language-python"># 算法原理和同比策略（简易）一致，只是用来做比较的历史值含义不一样。
{value} &gt;= {history_value} * (100 + ceil) * 0.01)
or
{value} &lt;= {history_value} * (100 - floor) * 0.01)

# value：当前值
# history_value：前n个时间点的均值
# ceil：升幅
# floor：降幅
# 当前值(value) 与前个时间点的均值 (history_value)进行升幅/降幅计算

# 前n个时间点的均值计算示例（数据周期1分钟）
以日期2019-08-26 12:00:00为例，如果n为5，历史时刻和对应值如下：</code></pre>


<table>
<thead>
<tr>
<th></th>
<th>时间</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2019-8-26 11:59:00</td>
<td>12</td>
</tr>
<tr>
<td>2</td>
<td>2019-8-26 11:58:00</td>
<td>22</td>
</tr>
<tr>
<td>3</td>
<td>2019-8-26 11:57:00</td>
<td>32</td>
</tr>
<tr>
<td>4</td>
<td>2019-8-26 11:56:00</td>
<td>42</td>
</tr>
<tr>
<td>5</td>
<td>2019-8-26 11:55:00</td>
<td>52</td>
</tr>
</tbody>
</table>
<pre class="codehilite"><code class="language-python">history_value = (12 + 22 + 32 + 42 + 52) / 5 = 32</code></pre>


<ul>
<li>示例：当 value(90)，ceil(100)，history_value(32)时，则判断为异常</li>
</ul>
<h3 id="_16">同比振幅</h3>
<h4 id="_17">适用场景</h4>
<ul>
<li>
<p>场景：适用于监控以天为周期的事件，该事件会明确导致指标的升高或者下降，但需要监控<code>超过合理范围幅度变化</code>的场景。</p>
<p>比如每天上午 10 点有一个抢购活动，活动内容不变，因此请求量每天 10:00 相比 09:59 会有一定的升幅。因为活动内容不变，所以请求量的升幅是在一定范围内的。使用该策略可以发现异常的请求量。</p>
</li>
</ul>
<h4 id="_18">配置方法</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15730233179624.jpg" /></p>
<h4 id="_19">工作原理</h4>
<pre class="codehilite"><code class="language-python"># 算法示例：
当前值 − 前一时刻值 &gt;= 过去 5 天内任意一天同时刻差值 × 2 + 3

以日期2019-08-26 12:00:00为例，如果n为5，历史时刻和对应值如下：</code></pre>


<table>
<thead>
<tr>
<th></th>
<th>时间</th>
<th>值</th>
<th>前一时刻</th>
<th>前一时刻值</th>
<th>差值</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2019-8-26 12:00:00</td>
<td>26</td>
<td>2019-8-26 11:59:00</td>
<td>10</td>
<td>16</td>
</tr>
<tr>
<td>1</td>
<td>2019-8-25 12:00:00</td>
<td>25</td>
<td>2019-8-25 11:59:00</td>
<td>18</td>
<td>7</td>
</tr>
<tr>
<td>2</td>
<td>2019-8-24 12:00:00</td>
<td>24</td>
<td>2019-8-24 11:59:00</td>
<td>30</td>
<td>6</td>
</tr>
<tr>
<td>3</td>
<td>2019-8-23 12:00:00</td>
<td>23</td>
<td>2019-8-23 11:59:00</td>
<td>31</td>
<td>8</td>
</tr>
<tr>
<td>4</td>
<td>2019-8-22 12:00:00</td>
<td>22</td>
<td>2019-8-22 11:59:00</td>
<td>32</td>
<td>10</td>
</tr>
<tr>
<td>5</td>
<td>2019-8-21 12:00:00</td>
<td>21</td>
<td>2019-8-21 11:59:00</td>
<td>33</td>
<td>12</td>
</tr>
</tbody>
</table>
<pre class="codehilite"><code class="language-python"># 当前值
value = 26
# 前一时刻值
prev_value = 10
# 比较运算符(=，&gt;， &gt;=， &lt;， &lt;=, !=)
method = &quot;&gt;=&quot;
# 波动率
ratio = 2
# 振幅
shock = 3
# 当前值一前一时刻值的差值
current_diff = 16
# 5天内同时刻差值
prev5_diffs = [7, 6, 8, 10, 12]

前第二天(2019-8-24)同时刻差值： 6 * ratio(2) + shock(3) = 15
current_diff(16) &gt;= 15

# 当前值(26) - 前一时刻值(10) &gt;= 2天前的同一时刻差值6 * 2 + 3
此时算法检测判定为检测结果为异常：</code></pre>


<h3 id="_20">同比区间</h3>
<h4 id="_21">适用场景</h4>
<p>温水煮青蛙型 - 数据缓慢上升或下降</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15807168374571.jpg" /></p>
<p>适用于以天为周期的曲线场景。</p>
<p>由于该模型中数据是缓慢变化的，所以使用【环比策略】、【同比振几幅】都检测不出告警，因为这两种模型主要使用于突升、突降、大于或小于指定值的情况。</p>
<p>【同比区间】才适用于这种情况，因为随着数据的变化，当前值和模型值差距越来越大，而区间比较主要就是那当前值和历史模型值做比较。</p>
<h4 id="_22">配置方法</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15892524354204.jpg" /></p>
<h4 id="_23">工作原理</h4>
<ul>
<li>实现原理&amp;示例：</li>
</ul>
<pre class="codehilite"><code class="language-python"># 算法示例：
当前值 &gt;= 过去 5 天内同时刻绝对值 × 2 + 3

以日期2019-08-26 12:00:00为例，如果n为5，历史时刻和对应值如下：</code></pre>


<table>
<thead>
<tr>
<th></th>
<th>时间</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2019-8-26 12:00:00</td>
<td>26</td>
</tr>
<tr>
<td>1</td>
<td>2019-8-25 12:00:00</td>
<td>16</td>
</tr>
<tr>
<td>2</td>
<td>2019-8-24 12:00:00</td>
<td>14</td>
</tr>
<tr>
<td>3</td>
<td>2019-8-23 12:00:00</td>
<td>13</td>
</tr>
<tr>
<td>4</td>
<td>2019-8-22 12:00:00</td>
<td>16</td>
</tr>
<tr>
<td>5</td>
<td>2019-8-21 12:00:00</td>
<td>15</td>
</tr>
</tbody>
</table>
<pre class="codehilite"><code class="language-python"># 当前值
value = 11
# 比较运算符(=，&gt;， &gt;=， &lt;， &lt;=, !=)
method = &quot;&gt;=&quot;
# 波动率
ratio = 2
# 振幅
shock = 3

前第3天(2019-8-23)同时刻值： 13 * ratio(2) + shock(3) = 26
value(26) &gt;= 26

# 当前值(26) &gt;= 3天前的同一时刻绝对值13 * 2 + 3
此时算法检测判定为检测结果为异常：</code></pre>


<h3 id="_24">环比振幅</h3>
<h4 id="_25">适用场景</h4>
<ul>
<li>适用于指标陡增或陡降的场景，如果陡降场景，ratio(波动率)配置的值需要 &lt; -1</li>
<li>该算法将环比算法自由开放，可以通过配置 波动率 和 振幅，来达到对数据陡变的监控。同时最小阈值可以过滤无效的数据</li>
</ul>
<h4 id="_26">配置方法</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15892523996558.jpg" /></p>
<h4 id="_27">工作原理</h4>
<pre class="codehilite"><code class="language-python"># 当前值(value) 与前一时刻值 (prev_value)均&gt;= (threshold)，且之间差值&gt;=前一时刻值 (prev_value) * (ratio) + (shock)

# value：当前值
# prev_value：前一时刻值
# threshold：阈值下限
# ratio：波动率
# shock：振幅

以日期2019-08-26 12:00:00为例：</code></pre>


<table>
<thead>
<tr>
<th></th>
<th>时间</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2019-8-26 12:00:00</td>
<td>46</td>
</tr>
<tr>
<td>1</td>
<td>2019-8-26 11:59:00</td>
<td>12</td>
</tr>
</tbody>
</table>
<pre class="codehilite"><code class="language-python"># 当前值
value = 46
# 前一时刻值
prev_value = 12
# 波动率
ratio = 2
# 振幅
shock = 3

value(46) &gt;= 10  and prev_value(12) &gt;=10
value(46) &gt;= prev_value(12) * (ratio(2) + 1) + shock(3)

此时算法检测判定为检测结果为异常：
# 当前值(46)与前一时刻值(12)均&gt;= (10)，且之间差值&gt;=前一时刻值 (12) * (2) + (3)</code></pre>


<h2 id="_28">内置特殊检测算法</h2>
<p>内置特殊算法无需配置，默认绑定对应的指标。</p>
<h3 id="_29">系统重启</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808763663402.png" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808761025636.png" /></p>
<p>内置检测算法：基于时序数据 system.env.uptime 进行判断。</p>
<pre class="codehilite"><code class="language-python"># 主机运行时长在0到600秒之间
# 主机当前运行时长比前一周期值小，或者前一个周期值为空</code></pre>


<h3 id="_30">进程端口</h3>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808764472574.png" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15808764814964.png" /></p>
<p>内置检测算法：基于时序数据 system.proc_port.exists 及 nonlisten，not_accurate_listen 判断</p>
<pre class="codehilite"><code class="language-python"># exists != 1 进程不存在
# nonlisten != [] 端口不存在
# not_accurate_listen != [] 进程存在，但端口和cmdb注册端口不一致</code></pre>


<h2 id="_31">日志关键字检测算法</h2>
<p>仅支持静态阈值</p><h1 id="_1">通知收敛和汇总机制</h1>
<p>为了避免短时间内大量产生告警事件导致的告警风暴，监控平台对告警通知进行了收敛及汇总处理。</p>
<h2 id="_2">告警收敛</h2>
<p>为了避免相同的告警在每个检测周期都产生通知，策略配置中可以设置通知间隔，两次通知之间的告警将会被收敛。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/image-20200206210333199.png" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/image-20200206211833279.png" /></p>
<h2 id="_3">告警抑制</h2>
<p>高级别的告警会抑制低级别的告警。</p>
<ol>
<li>如果产生了高级别告警，同维度低级别告警会立即恢复。</li>
<li>如果存在高级别告警，低级别告警不会产生</li>
</ol>
<h2 id="_4">告警汇总</h2>
<p>对一段时间内的多条告警通知按一定规则进行分类后汇总发送。</p>
<h3 id="_5">通知分配</h3>
<p>告警通知将会被进行两级分类。</p>
<p>首先，单条的告警通知会按以下信息分类，信息相同的会被分配到相同分类。</p>
<p>同策略产生的同级别同维度的告警通知将会被归为一类，这里我们把它称为<strong>同维度组</strong>。</p>
<ol>
<li>业务 ID(bk_biz_id)</li>
<li>通知接收人(notice_receivers)</li>
<li>通知方式(notice_way)</li>
<li>通知类型(notice_type)</li>
<li>告警策略(strategy_id)</li>
<li>告警级别(level)</li>
<li>维度哈希(dimension_hash)</li>
</ol>
<p>然后，上述的分类再按以下信息分类，统计每个分类中的有多少个同维度组。</p>
<p>同业务、同数据来源、同级别的类会被归为一类，这里我们把它称为<strong>多策略组</strong>。</p>
<ol>
<li>通知类型(notice_type)</li>
<li>通知接收人(notice_receivers)</li>
<li>通知方式(notice_way)</li>
<li>业务 ID(bk_biz_id)</li>
<li>数据源类型(data_source)</li>
<li>告警级别(level)</li>
</ol>
<h3 id="_6">触发发送任务</h3>
<p>通知分类完毕后，会尝试触发发送任务，有下列三种发送任务：</p>
<ol>
<li>立即发送</li>
</ol>
<p>当同维度组的通知没有进入任何汇总状态时，直接触发延迟一秒的发送任务。之所以不是直接发送单条的告警，是为了当短时间内涌入大量告警时，发出的第一条告警能够带上足够多的告警。</p>
<p>任务执行时汇总发送这个同维度组中的 120 秒内的未发送通知。</p>
<ol>
<li>同维度汇总发送</li>
</ol>
<p>当同维度组中的待发送通知数达到<strong>同维度汇总阈值</strong>时，该同维度组进入汇总发送状态，触发一次延迟 60 秒的发送任务，任务未执行时，该同维度组将不会触发<strong>立即发送</strong>。</p>
<p>任务执行时汇总发送该同维度组中的<strong>同维度汇总时间窗口</strong>秒内的未发送通知，然后将发送的通知标记为已发送。</p>
<ol>
<li>多策略汇总发送</li>
</ol>
<p>当多策略组中的同维度组数量达到阈值<strong>多策略汇总阈值</strong>时，该多策略组进入汇总发送状态，触发一次延迟 60 秒的发送任务，任务未执行时，该多策略组中的同维度组将不会触发任何发送任务。</p>
<p>任务执行时汇总该多策略组中的所有同维度组中<strong>多策略汇总时间窗口</strong>秒内的未发送通知，然后将通知标记为已发送。</p>
<blockquote>
<p>上述说明中提到的<strong>汇总阈值</strong>及<strong>汇总时间窗口</strong>，管理员可以在动态全局配置中进行调整。</p>
</blockquote>
<h3 id="_7">通知内容</h3>
<ol>
<li>同维度汇总和多策略汇总的通知模板是不同。</li>
<li>某些通知渠道(如：短信)的单条消息长度受限。当通知消息达到单条消息长度限制时，某些通知模板变量会进入省略模式，尽量减少通知消息的长度，但并不能保证通知消息一定小于单条消息长度限制。</li>
<li>content.target</li>
<li>alarm.target</li>
<li>content.dimension</li>
<li>alarm.dimension</li>
</ol>
<h2 id="_8">语音告警</h2>
<p>由于语言告警的特殊性，语音告警的汇总逻辑比较特殊，它会保证 2 分钟内，无论有多少语音告警通知，同一组人只会接到一条电话告警，其余的语言告警会被丢弃。</p>
<p>因此只有重要的告警才建议配置电话告警。</p><h1 id="_1">变量列表</h1>
<p>监控平台提供了一些变量的使用场景，如采集的参数，告警的通知模版，与 CMDB 打通获取相关的一些变量数据，可以更加方便的进行配置和管理。</p>
<h2 id="_2">变量格式说明</h2>
<p>Jinja2 是一个现代的，设计者友好的，仿照 Django 模板的 Python 模板语言。它速度快，被广泛使用，并且提供了可选的沙箱模板执行环境保证安全：</p>
<pre class="codehilite"><code class="language-html">&lt;title&gt;{% block title %}{% endblock %}&lt;/title&gt;
&lt;ul&gt;
{% for user in users %}
  &lt;li&gt;&lt;a href=&quot;{{ user.url }}&quot;&gt;{{ user.username }}&lt;/a&gt;&lt;/li&gt;
{% endfor %}
&lt;/ul&gt;</code></pre>


<h2 id="_3">模板变量</h2>
<h3 id="alarm">Alarm/告警变量</h3>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>alarm.target_string</td>
<td>告警目标</td>
<td>10.0.1.10,10.0.1.11</td>
</tr>
<tr>
<td>alarm.dimension_string</td>
<td>告警维度(除目标)</td>
<td>磁盘=C，主机名=xxx</td>
</tr>
<tr>
<td>alarm.collect_count</td>
<td>汇总事件数量</td>
<td>10</td>
</tr>
<tr>
<td>alarm.notice_from</td>
<td>消息来源</td>
<td>监控平台</td>
</tr>
<tr>
<td>alarm.company</td>
<td>企业标识</td>
<td>蓝鲸</td>
</tr>
<tr>
<td>alarm.data_source_name</td>
<td>数据来源名称</td>
<td>数据平台</td>
</tr>
<tr>
<td>alarm.data_source</td>
<td>数据来源</td>
<td>BKMONITOR</td>
</tr>
<tr>
<td>alarm.detail_url</td>
<td>详情链接</td>
<td></td>
</tr>
<tr>
<td>alarm.current_value</td>
<td>当前值</td>
<td>1.1</td>
</tr>
<tr>
<td>alarm.target_type</td>
<td>目标类型</td>
<td>IP/INSTANCE/TOPO</td>
</tr>
<tr>
<td>alarm.target_type_name</td>
<td>目标类型名称</td>
<td>IP/实例/节点</td>
</tr>
</tbody>
</table>
<h3 id="strategy">Strategy/策略变量</h3>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>strategy.strategy_id</td>
<td>策略 ID</td>
<td>1</td>
</tr>
<tr>
<td>strategy.strategy_name</td>
<td>策略名称</td>
<td>CPU 总使用率</td>
</tr>
<tr>
<td>strategy.scenario</td>
<td>场景</td>
<td>os</td>
</tr>
<tr>
<td>strategy.source_type</td>
<td>数据来源</td>
<td>BKMONITOR</td>
</tr>
<tr>
<td>strategy.bk_biz_id</td>
<td>业务 ID</td>
<td>2</td>
</tr>
<tr>
<td>strategy.item.result_table_id</td>
<td>结果表名称</td>
<td>system.cpu_detail</td>
</tr>
<tr>
<td>strategy.item.name</td>
<td>指标名称</td>
<td>空闲率</td>
</tr>
<tr>
<td>strategy.item.metric_field</td>
<td>指标字段</td>
<td>idle</td>
</tr>
<tr>
<td>strategy.item.unit</td>
<td>单位</td>
<td>%</td>
</tr>
<tr>
<td>strategy.item.agg_interval</td>
<td>周期</td>
<td>60</td>
</tr>
<tr>
<td>strategy.item.agg_method</td>
<td>聚合方法</td>
<td>AVG</td>
</tr>
</tbody>
</table>
<h4 id="content">Content / 通知内容变量</h4>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>content.level</td>
<td>告警级别</td>
<td></td>
</tr>
<tr>
<td>content.time</td>
<td>告警时间</td>
<td></td>
</tr>
<tr>
<td>content.duration</td>
<td>告警持续时间</td>
<td></td>
</tr>
<tr>
<td>content.target_type</td>
<td>告警目标类型</td>
<td></td>
</tr>
<tr>
<td>content.data_source</td>
<td>告警数据来源</td>
<td></td>
</tr>
<tr>
<td>content.content</td>
<td>告警内容</td>
<td></td>
</tr>
<tr>
<td>content.biz</td>
<td>告警业务</td>
<td></td>
</tr>
<tr>
<td>content.target</td>
<td>告警目标</td>
<td></td>
</tr>
<tr>
<td>content.dimension</td>
<td>告警维度</td>
<td></td>
</tr>
<tr>
<td>content.detail</td>
<td>告警详情</td>
<td></td>
</tr>
<tr>
<td>content.current_value</td>
<td>告警当前值</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="cmdb">CMDB 变量</h3>
<p>CMDB 变量在采集的参数中也是可以使用的。</p>
<h4 id="business">Business / 业务变量</h4>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>target.business.bk_biz_id</td>
<td>业务 ID</td>
<td>2</td>
</tr>
<tr>
<td>target.business.bk_biz_name</td>
<td>业务名称</td>
<td>蓝鲸</td>
</tr>
<tr>
<td>target.business.bk_biz_developer_string</td>
<td>开发人员字符串</td>
<td>admin,user1,user2</td>
</tr>
<tr>
<td>target.business.bk_biz_maintainer_string</td>
<td>运维人员字符串</td>
<td>admin,user1</td>
</tr>
<tr>
<td>target.business.bk_biz_tester_string</td>
<td>测试人员字符串</td>
<td>admin,user1</td>
</tr>
<tr>
<td>target.business.bk_biz_productor_string</td>
<td>产品人员字符串</td>
<td>admin,user1</td>
</tr>
<tr>
<td>target.business.operator_string</td>
<td>操作人员字符串</td>
<td>admin,user1</td>
</tr>
</tbody>
</table>
<h4 id="host">Host / 主机变量</h4>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>target.host.bk_host_id</td>
<td>主机 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.host.bk_biz_id</td>
<td>业务 ID</td>
<td>2</td>
</tr>
<tr>
<td>target.host.bk_cloud_id</td>
<td>云区域 ID</td>
<td>0</td>
</tr>
<tr>
<td>target.host.bk_cloud_name</td>
<td>云区域名称</td>
<td>默认区域</td>
</tr>
<tr>
<td>target.host.bk_host_innerip</td>
<td>内网 IP</td>
<td>10.0.0.1</td>
</tr>
<tr>
<td>target.host.bk_host_outerip</td>
<td>外网 IP</td>
<td>10.0.1.11</td>
</tr>
<tr>
<td>target.host.bk_host_name</td>
<td>主机名</td>
<td></td>
</tr>
<tr>
<td>target.host.bk_os_name</td>
<td>操作系统名称</td>
<td>Linux</td>
</tr>
<tr>
<td>target.host.bk_os_type</td>
<td>操作系统类型(枚举数值)</td>
<td>1</td>
</tr>
<tr>
<td>target.host.operator_string</td>
<td>负责人</td>
<td>admin,user1</td>
</tr>
<tr>
<td>target.host.bk_bak_operator_string</td>
<td>备份负责人</td>
<td>admin,user1</td>
</tr>
</tbody>
</table>
<h4 id="process">Process / 进程变量</h4>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>target.process.["process_name"].bk_process_id</td>
<td>进程 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.process.["process_name"].bk_process_name</td>
<td>进程名称</td>
<td>进程 1</td>
</tr>
<tr>
<td>target.process.["process_name"].bk_func_name</td>
<td>进程功能名称</td>
<td>java</td>
</tr>
<tr>
<td>target.process.["process_name"].bind_ip</td>
<td>绑定 IP</td>
<td>10.0.1.10</td>
</tr>
<tr>
<td>target.process.["process_name"].port</td>
<td>绑定端口</td>
<td>1,2,3-5,7-10</td>
</tr>
<tr>
<td>target.process.["process_name"].process_template_id</td>
<td>进程模板 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.process.["process_name"].service_instance_id</td>
<td>服务实例 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.process.["process_name"].bk_host_id</td>
<td>主机 ID</td>
<td>1</td>
</tr>
</tbody>
</table>
<h4 id="serviceinstance">ServiceInstance / 服务实例变量</h4>
<table>
<thead>
<tr>
<th>变量</th>
<th>名称</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>target.service_instance.service_instance_id</td>
<td>服务实例 ID</td>
<td>!</td>
</tr>
<tr>
<td>target.service_instance.name</td>
<td>服务实例名</td>
<td>xxx_10.0.1.11</td>
</tr>
<tr>
<td>target.service_instance.bk_host_id</td>
<td>主机 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.service_instance.bk_module_id</td>
<td>模块 ID</td>
<td>1</td>
</tr>
<tr>
<td>target.service_instance.service_category_id</td>
<td>服务分类 id</td>
<td>1</td>
</tr>
</tbody>
</table><h1 id="_1">插件配置文件说明</h1>
<p>插件制作有线上制作方法，如果要快速线下制作也是非常的方便，需要了解下所有的插件配置说明。</p>
<h2 id="exporter">Exporter</h2>
<pre class="codehilite"><code class="language-bash">./                       # 压缩包根目录
|-- external_plugin_aix_powerpc            # aix 系统 power CPU 架构的插件集合
|-- extarnal_plugin_windows_x86_64         # windows 系统 x86 64位 CPU 架构的插件集合
    `-- mysql_exporter            # 插件名称
        |-- info                  # 插件信息
            |-- description.md    # 插件描述
            |-- logo.png          # 插件 logo
            |-- config.json       # 插件参数配置 schema
            |-- meta.yaml         # 插件元信息
            `-- metrics.json      # 插件结果表配置
        |-- mysql_exporter.exe    # exporter 二进制文件，与插件文件夹同名，后缀名保留
        `-- VERSION               # 版本信息文件
`-- external_plugin_linux_x86_64           # linux 系统 x86 64位 CPU 架构的插件集合
    `-- mysql_exporter            # 插件名称
        |-- info                  # 插件信息
            |-- description.md    # 插件描述
            |-- logo.png          # 插件 logo
            |-- config.json       # 插件参数配置 schema
            |-- meta.yaml         # 插件元信息
            `-- metrics.json      # 插件结果表配置
        |-- mysql_exporter        # exporter 二进制文件，与插件文件夹同名，后缀名保留
        \-- VERSION               # 版本信息文件</code></pre>


<h3 id="metayaml">meta.yaml</h3>
<pre class="codehilite"><code class="language-yaml">plugin_id: mysql_exporter  # 插件 ID
plugin_display_name: Mysql Exporter  # 插件显示名称
type: Exporter  # 插件类型
tag: xxxx       # 插件标签</code></pre>


<h2 id="script">script</h2>
<pre class="codehilite"><code class="language-bash">./                       # 压缩包根目录
|-- external_plugin_windows_x86_64         # windows 系统 x86 64位 CPU 架构的插件集合
`-- external_plugin_linux_x86_64           # linux 系统 x86 64位 CPU 架构的插件集合
    `-- ios_online                # 插件名称
        |-- info                  # 插件信息
            |-- description.md    # 插件描述
            |-- logo.png          # 插件 logo
            |-- config.json       # 插件参数配置 schema
            |-- meta.yaml         # 插件元信息
            `-- metrics.json      # 插件结果表配置
        |-- ios_online.sh         # 脚本文件，文件名与脚本类型由 meta.yaml 的配置确定
        `-- VERSION               # 版本信息文件</code></pre>


<h3 id="metayaml_1">meta.yaml</h3>
<pre class="codehilite"><code class="language-yaml">plugin_id: mysql_exporter  # 插件 ID
plugin_display_name: Mysql Exporter  # 插件显示名称
type: Exporter  # 插件类型
tag: xxxx       # 插件标签
scripts:
    type: sh    # 脚本类型
    filename: ios_online.sh  # 脚本名称</code></pre>


<h2 id="jmx">JMX</h2>
<pre class="codehilite"><code class="language-bash">./                       # 压缩包根目录
|-- external_plugin_windows_x86_64         # windows 系统 x86 64位 CPU 架构的插件集合
`-- external_plugin_linux_x86_64           # linux 系统 x86 64位 CPU 架构的插件集合
    `-- tomcat_exporter           # 插件名称
        |-- etc
              `-- config.yaml.tpl   # JMX 配置文件
        |-- info                  # 插件信息
            |-- description.md    # 插件描述
            |-- logo.png          # 插件 logo
            |-- config.json       # 插件参数配置 schema
            |-- meta.yaml         # 插件元信息
            `-- metrics.json      # 插件结果表配置
        |-- VERSION               # 版本信息文件</code></pre>


<h3 id="metayaml_2">meta.yaml</h3>
<pre class="codehilite"><code class="language-yaml">plugin_id: mysql_exporter  # 插件 ID
plugin_display_name: Mysql Exporter  # 插件显示名称
type: Exporter  # 插件类型
tag: xxxx       # 插件标签</code></pre>


<h2 id="pushgateway-datadog-built-in">PushGateway &amp; DataDog &amp; Built-In</h2>
<pre class="codehilite"><code class="language-bash">./                       # 压缩包根目录
|-- external_plugin_windows_x86_64         # windows 系统 x86 64位 CPU 架构的插件集合
`-- external_plugin_linux_x86_64           # linux 系统 x86 64位 CPU 架构的插件集合
    `-- tomcat_exporter           # 插件名称
        |-- info                  # 插件信息
            |-- description.md    # 插件描述
            |-- logo.png          # 插件 logo
            |-- config.json       # 插件参数配置 schema
            |-- meta.yaml         # 插件元信息
            `-- metrics.json      # 插件结果表配置
        `-- VERSION               # 版本信息文件</code></pre>


<h3 id="metayaml_3">meta.yaml</h3>
<pre class="codehilite"><code class="language-yaml">plugin_id: mysql_exporter  # 插件 ID
plugin_display_name: Mysql Exporter  # 插件显示名称
type: Exporter  # 插件类型
tag: xxxx       # 插件标签</code></pre><h1 id="_1">各种进程配置方法</h1>
<p>进程有很多种启动方式，也有各种的使用场景。在多种进程配置下如何在 CMDB 中配置来满足进程监控的需求。</p>
<p>如下介绍了多种进程配置案例，并且给出配置方法和可行性。</p>
<h3 id="_2">情况一：同机同二进制名(相同路径)不同参数启动</h3>
<p>如 Java、Python 解释器类的启动方式.</p>
<pre class="codehilite"><code class="language-bash">root     13670  0.9 17.8 48339468 17593272 ?   Sl   1月01 290:11 java -server -Xms24g -Xmx24g -XX:MaxDirectMemorySize=32g -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -cp /data/mapleleaf/druid/conf/druid/cluster/query/broker:/data/mapleleaf/druid/conf/druid/cluster/query/_common:/data/mapleleaf/druid/conf/druid/cluster/query/_common/hadoop-xml:/data/mapleleaf/druid/conf/druid/cluster/query/../_common:/data/mapleleaf/druid/conf/druid/cluster/query/../_common/hadoop-xml:/data/mapleleaf/druid/bin/../lib/* org.apache.druid.cli.Main server broker
root     27012  0.2  0.5 14885784 538188 ?     Sl   1月15  24:30 java -server -Xms512m -Xmx512m -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -cp /data/mapleleaf/druid/conf/druid/cluster/data/middleManager:/data/mapleleaf/druid/conf/druid/cluster/data/_common:/data/mapleleaf/druid/conf/druid/cluster/data/_common/hadoop-xml:/data/mapleleaf/druid/conf/druid/cluster/data/../_common:/data/mapleleaf/druid/conf/druid/cluster/data/../_common/hadoop-xml:/data/mapleleaf/druid/bin/../lib/* org.apache.druid.cli.Main server middleManager</code></pre>


<ul>
<li>配置方法：<ul>
<li>进程名称：不带路径的二进制名称，如<code>java</code></li>
<li>进程别名：显示的可识别的，如<code>druid-broker</code></li>
<li>启动参数：能够唯一区分的参数名称，如<code>/data/mapleleaf/druid/conf/druid/cluster/query/broker</code></li>
</ul>
</li>
</ul>
<h3 id="_3">情况二：同二进制名称，不同路径，无参数</h3>
<p>这类要么不需要启用端口，要么配置采用和二进制同工作目录等。</p>
<pre class="codehilite"><code class="language-bash">/opt/gosuv
/usr/local/gosuv</code></pre>


<ul>
<li>配置方法：暂时不支持，功能待完善。</li>
</ul>
<h3 id="_4">情况三：同机同二进制名，不同路径，参数相同</h3>
<p>如 Nginx,MySQL,Redis 等支持相对路径参数的服务。</p>
<pre class="codehilite"><code class="language-bash">/usr/local/bin/redis-server ./redis.conf
/usr/bin/redis-server ./redis.conf</code></pre>


<ul>
<li>配置方法：暂时不支持，功能待完善。</li>
</ul>
<h3 id="_5">情况四：同机同二进制名，不同路径，同进程显示，参数相同</h3>
<p>如 Nginx,MySQL,Redis 等支持相对路径参数的服务。因为使用了 cd 到目的目录再进行启动，这类是不建议配置的，因为导致管理的复杂度。</p>
<pre class="codehilite"><code class="language-bash">./redis-server ./redis.conf
./redis-server ./redis.conf</code></pre>


<ul>
<li>配置方法：暂时不支持，功能待完善。</li>
</ul>
<h3 id="_6">情况五：进程的维度标识无法定义，是由程序动态生成的</h3>
<p>其他都是一样的，只有 containers 的部分不一样：</p>
<pre class="codehilite"><code class="language-bash">    /bin/java -Xms30720m -Xmx30720m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+DisableExplicitGC -XX:+AlwaysPreTouch -server -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Dlog4j.skipJansi=true -XX:+HeapDumpOnOutOfMemoryError -Des.path.home=/data1/containers/1495608881000003411/es -cp /data1/containers/1495608881000003411/es/lib/* org.elasticsearch.bootstrap.Elasticsearch -d</code></pre>


<p>想要最终上报的维度名有一个为<code>/containers/1495608881000003411</code>。</p>
<p>进程是动态由主程序 fork 出来的，如游戏开房。</p>
<p>这种情况的属于程序动态生成的进程程序不管是监控本身还是人工检测都是保证不了的，只能由主程序来提供性能数据。</p>
<ul>
<li>配置方法：暂时不支持，待完善。</li>
</ul>
<h3 id="windows">情况六：windows 的进程是大小写</h3>
<ul>
<li>配置方法：进程名全部改为小写，功能待完善。</li>
</ul>
<h3 id="_7">情况七：软连接的进程</h3>
<pre class="codehilite"><code class="language-bash">mysql    26921  0.0  0.1 116352  1876 ?        Ss   00:41   0:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr
mysql    27120  0.0  8.0 1103564 82072 ?       Sl   00:41   0:24 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mariadb/mariadb.log --pid-file=/var/run/mariadb/mariadb.pid --socket=/var/lib/mysql/mysql.sock</code></pre>


<p>mysqld_safe 进程是 sh 其实是软链接 所以当前只能配置 bash。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/guide/media/15809113169064.jpg" /></p>
<p>功能待完善。</p>
<h3 id="_8">情况八：只有端口没有进程名</h3>
<p>这种情况的不属于进程监控，是属于本地端口的探活。</p>
<ul>
<li>配置方法：通过插件写脚本方式实现。</li>
</ul><h1 id="_1">其他小功能</h1>
<p>介绍一些有用的小功能。</p>
<h3 id="_2">在桌面安装监控应用</h3>
<ul>
<li>Q：在桌面安装监控应用有什么好处？</li>
<li>A：好处有三<ul>
<li>1）不用打开浏览器就可以直接登陆了</li>
<li>2）配置操作系统的快捷方式打开更是方便</li>
<li>3）更简洁没有浏览器的菜单导航等。</li>
</ul>
</li>
</ul>
<h4 id="step1">step1 找到监控的域名地址</h4>
<p>方法 1：在打开监控后，通过右键的检查或者是 debug 找一个页面的地址，复制到 bk_monitor 就可以了。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806358666354.jpg" /></p>
<p>方法 2：直接拼接，一般的域名都是  <code>https://${主域名}/o/bk_monitor</code></p>
<h4 id="step2">step2 安装应用</h4>
<p>使用 URL 在浏览器上打开，如：<code>https://dev.blueking.com/o/bk_monitor</code></p>
<p>在输入框将看到，点击安装就可以了。</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806360558705.jpg" /></p>
<blockquote>
<p>提醒：Windows 和 Mac 都是可以安装的。</p>
</blockquote>
<h4 id="step3-app">step3 从 app 打开</h4>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806368035193.jpg" /></p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806361577834.jpg" /></p>
<p>就可以看到一个独立的监控平台 app 了</p>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806362187846.jpg" /></p>
<blockquote>
<p>提醒：app 还可以拖动到桌面。</p>
</blockquote>
<h3 id="_3">窗口不够用，拖就是了</h3>
<p>界面里面有很多是左右分栏的，当数据比较多，显示不完时，拖就对了。</p>
<ul>
<li>主机详情的主机视角和进程视角</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806364233920.jpg" /></p>
<ul>
<li>监控目标选择器</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806364871265.jpg" /></p>
<ul>
<li>新建采集配置的插件描述</li>
</ul>
<p><img alt="-w2021" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/functions/addenda/media/15806365875507.jpg" /></p><h1 id="exporter">监控平台 Exporter 开发</h1>
<p>当市面上没有找到相应的 Exporter 采集器，或者现有的 Exporter 不满足需求，可以自行修改或者重新开发一个 Exporter，也是相对比较简单的事情。</p>
<p>接下来简单介绍下如何开发一个 Exporter 插件。</p>
<h2 id="_1">基础</h2>
<h3 id="exporter_1">Exporter 简介</h3>
<p><strong>Exporter 本质上就是将收集的数据，转化为对应的文本格式，并提供 http 接口，供监控平台采集器定期采集数据</strong></p>
<h3 id="exporter_2">Exporter 基础</h3>
<p><strong>指标介绍</strong></p>
<p>Prometheus 中主要使用的四类指标类型，如下所示</p>
<ul>
<li>Counter (累加指标)</li>
<li>Gauge (测量指标)</li>
<li>Summary (概略图)</li>
<li>Histogram (直方图)</li>
</ul>
<p>最常使用的是 Gauge，Gauge 代表了采集的一个单一数据，这个数据可以增加也可以减少，比如 CPU 使用情况，内存使用量，硬盘当前的空间容量等。</p>
<p>Counter 一个累加指标数据，这个值随着时间只会逐渐的增加，比如程序完成的总任务数量，运行错误发生的总次数等，代表了持续增加的数据包或者传输字节累加值。</p>
<blockquote>
<p>【<strong>注</strong>】：所有指标的值仅支持 float64 类型</p>
</blockquote>
<p><strong>文本格式</strong></p>
<p>以下面得输出为例：</p>
<pre class="codehilite"><code class="language-bash"># metric:
sample_metric1 12.47
sample_metric2{partition=&quot;c:&quot;} 0.44</code></pre>


<p><strong>其中</strong>：</p>
<ul>
<li>`#表示注释</li>
<li><code>sample_metric1</code>和<code>sample_metric2</code>表示指标名称</li>
<li><code>partition</code>表示指标得作用维度，例如磁盘分区使用率，维度就是磁盘分区，即每个磁盘分区都有一个磁盘分区使用率的值</li>
<li><code>xxx</code>表示维度的值，例如磁盘分区的 C 盘/D 盘等</li>
<li><code>12.47</code>和<code>0.44</code>表示对应指标的值</li>
</ul>
<h2 id="_2">依赖</h2>
<ul>
<li>
<p>Golang 语言环境</p>
</li>
<li>
<p>引入 Prometheus 的依赖库</p>
<p><code>bash
go get github.com/prometheus/client_golang/prometheus</code></p>
</li>
</ul>
<h3 id="_3">开发实例</h3>
<ul>
<li>
<p>(1)新建一个 Exporter 项目：</p>
<p>一个 Exporter 只需要一个文件即可；新建一个 test_Exporter 目录和一个 test_Exporter.go 文件：</p>
</li>
</ul>
<p><img alt="e1" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/media/e1-1.png" /></p>
<ul>
<li>
<p>(2)导入依赖模块</p>
<p><code>go
import (
    "flag"
    "log"
    "net/http"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)</code></p>
</li>
<li>
<p>(3)定义 Exporter 的版本(Version)、监听地址(listenAddress)、采集 url(metricPath)以及首页(landingPage)</p>
<p><code>go
var (
    Version       = "1.0.0.dev"
    listenAddress = flag.String("web.listen-address", ":9601", "Address to listen on for web interface and telemetry.")
    metricPath    = flag.String("web.telemetry-path", "/metrics", "Path under which to expose metrics.")
    landingPage   = []byte("&lt;html&gt;&lt;head&gt;&lt;title&gt;SYS Exporter " + Version +
        "&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;SYS Exporter " + Version + "&lt;/h1&gt;&lt;p&gt;&lt;a href='" + *metricPath + "'&gt;Metrics&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;")
)</code></p>
</li>
<li>
<p>(4)定义 Exporter 结构体</p>
<p><code>go
type Exporter struct {
    error        prometheus.Gauge
    scrapeErrors *prometheus.CounterVec
}</code></p>
</li>
<li>
<p>(5)定义结构体实例化的函数 NewExporter</p>
<p><code>go
func NewExporter() *Exporter {
    return &amp;Exporter{
    }
}</code></p>
</li>
<li>
<p>(6)Describe 函数，传递指标描述符到 channel，这个函数不用动，直接使用即可，用来生成采集指标的描述信息</p>
<p>```go
func (e <em>Exporter) Describe(ch chan&lt;- </em>prometheus.Desc) {
    metricCh := make(chan prometheus.Metric)
    doneCh := make(chan struct{})</p>
<pre class="codehilite"><code>go func() {
    for m := range metricCh {
        ch &lt;- m.Desc()
    }
    close(doneCh)
}()

e.Collect(metricCh)
close(metricCh)
&lt;-doneCh</code></pre>


<p>}
```</p>
</li>
<li>
<p>(7)Collect 函数将执行抓取函数并返回数据，返回的数据传递到 channel 中，并且传递的同时绑定原先的指标描述符，以及指标的类型(Guage)；需要将所有的指标获取函数在这里写入。</p>
<p><code>go
//collect函数，采集数据的入口
func (e *Exporter) Collect(ch chan&lt;- prometheus.Metric) {
    var err error
    //每个指标值的采集逻辑，在对应的采集函数中
    if err = ScrapeMem(ch); err != nil {
        e.scrapeErrors.WithLabelValues("Mssql_Connections per sec").Inc()
    }
    if err = ScrapeDisk(ch); err != nil {
        e.scrapeErrors.WithLabelValues("localtime").Inc()
    }
}</code></p>
</li>
<li>
<p>(8)指标仅有单条数据，不带维度信息示例如下：</p>
<p><code>go
func ScrapeMem(ch chan&lt;- prometheus.Metric) error {
    //指标获取逻辑，此处不做具体操作，仅仅赋值进行示例
    mem_usage := float64(60)
    //生成采集的指标名
    metric_name := prometheus.BuildFQName("sys", "", "mem_usage")
    //生成NewDesc类型的数据格式，该指标无维度，[]string{}为空
    new_desc := prometheus.NewDesc(metric_name, "Gauge metric with mem_usage", []string{}, nil)
    //生成具体的采集信息并写入ch通道
    metric_mes := prometheus.MustNewConstMetric(new_desc, prometheus.GaugeValue, mem_usage)
    ch &lt;- metric_mes
    return nil
}</code></p>
</li>
<li>
<p>(9)指标有多条数据，带维度信息示例如下：</p>
<p>```go
func ScrapeDisk(ch chan&lt;- prometheus.Metric) error {
    disks_mes := []interface{}{
        map[string]interface{}{
            "name":      "C:/",
            "disk_size": float64(100),
        },
        map[string]interface{}{
            "name":      "D:/",
            "disk_size": float64(200),
        },
    }
    for _, disk_mes := range disks_mes {
        disk_name := disk_mes.(map[string]interface{})["name"].(string)
        disk_size := disk_mes.(map[string]interface{})["disk_size"].(float64)
        metric_name := prometheus.BuildFQName("sys", "", "disk_size")
        //该例子具有disk_name的维度，须在[]string{"disk_name"}
        new_desc := prometheus.NewDesc(metric_name, "Gauge metric with disk_size", []string{"disk_name"}, nil)
        metric_mes := prometheus.MustNewConstMetric(new_desc, prometheus.GaugeValue, disk_size, disk_name)
        ch &lt;- metric_mes
    }
    return nil
}</p>
<p>```</p>
</li>
<li>
<p>(10)主函数</p>
<p><code>go
func main() {
    //解析定义的监听端口等信息
    flag.Parse()
    //生成一个Exporter类型的对象，该Exporter需具有collect和Describe方法
    Exporter := NewExporter()
    //将Exporter注册入prometheus，prometheus将定期从Exporter拉取数据
    prometheus.MustRegister(Exporter)
    //接收http请求时，触发collect函数，采集数据
    http.Handle(*metricPath, promhttp.Handler())
    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        w.Write(landingPage)
    })
    log.Fatal(http.ListenAndServe(*listenAddress, nil))
}</code></p>
</li>
<li>
<p>(11)编译 Exporter</p>
<p><code>go
go build test_Exporter.go</code></p>
</li>
<li>
<p>(12)cmd/shell 中运行即可，访问 <code>http://127.0.0.1:9601/metrics</code> 即可验证</p>
<p><img alt="e2" src="F:\v_awjliu\BKDocs\ZH/6.0/监控平台/产品白皮书/media/e2-1.png" /></p>
</li>
</ul>
<p>至此 Exporter 开发完成，其中 8，9 两步中的函数是重点，目前仅仅写了一些数据进行示例，其中的监控指标获取数据就是该部分的主要功能，需要编写对应逻辑获取指标的值。</p>
<h3 id="exporter_3">Exporter 编译</h3>
<p><strong>监控平台 Exporter 默认只支持 64 位机器运行 Exporter。</strong></p>
<ul>
<li>Windows</li>
</ul>
<p><code>env CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build -o ./Exporter-windows.exe test_Exporter.go</code></p>
<ul>
<li>Linux</li>
</ul>
<p><code>env CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ./Exporter-linux test_Exporter.go</code></p>
<h3 id="_4">封装监控平台插件</h3>
<ul>
<li>定义 Exporter 插件</li>
</ul>
<p>(1) 基本信息填写并上传 Exporter 文件</p>
<p>(2) 设置参数</p>
<p>(3) 定义指标和维度</p>
<p>(4) 补充 logo.png 和描述文件</p>
<ul>
<li>调试，验证插件的正确性</li>
</ul>
<p>具体参考 <a href="../guide/import_Exporter.md">如何在线制作 Exporter 插件</a>。</p>
<p>还可以线下制作 Exporter 插件包，具体查看 <a href="../functions/addenda/plugins_explain.md">插件配置文件说明</a>。</p><h1 id="datadog-integrations">DataDog Integrations 开发指南</h1>
<p>官方 Integrations： <a href="https://github.com/DataDog/integrations-core.git">https://github.com/DataDog/integrations-core.git</a></p>
<p>社区 Integrations： <a href="https://github.com/DataDog/integrations-extras.git">https://github.com/DataDog/integrations-extras.git</a></p>
<p>如果在以上两个渠道没有找到相应的 Integrations，或者不满足个人的需求，可以自己修改或者重新开发一个 DataDog Integrations。</p>
<p>监控平台支持符合 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/">DataDog Integrations 开发规范</a> 的插件，因此开发完成后，既可以在监控平台使用，也能回馈 DataDog 社区。</p>
<h3 id="_1">环境要求</h3>
<p>Python 2.7 或以上的版本</p>
<h3 id="_2">第一步：安装开发者工具</h3>
<p>2.x 版本将不再支持 Python 2，因此这里将版本固定为 1.4。</p>
<pre class="codehilite"><code class="language-bash">pip install &quot;datadog-checks-dev[cli]&quot;==1.4</code></pre>


<h3 id="_3">第二步：生成项目脚手架</h3>
<p>要将当前目录设置为工作目录，先拉取 integrations-extras 的代码。</p>
<pre class="codehilite"><code class="language-bash">git clone https://github.com/DataDog/integrations-extras.git</code></pre>


<p>然后将默认路径设置为 integrations-extras 所在的文件夹。</p>
<pre class="codehilite"><code class="language-bash">ddev config set extras &quot;/path/to/integrations-extras&quot;
ddev config set repo extras</code></pre>


<p>假如要开发一个采集 <strong>操作系统 CPU</strong> 指标的 Integrations，我们把它命名为 <code>system_cpu</code></p>
<p><code>ddev</code>命令提供了一个脚手架，用于快速创建一个完整的 Integrations 所需的所有文件及目录结构。创建命令如下：</p>
<pre class="codehilite"><code class="language-bash">ddev create system_cpu</code></pre>


<p>执行命令并填写简单的信息后，将会在 <code>integrations-extras</code> 目录创建一个名称为 <code>system_cpu</code> 的文件夹，目录结构如下：</p>
<pre class="codehilite"><code class="language-bash">system_cpu
├── assets
│   └── service_checks.json
├── datadog_checks
│   └── system_cpu
│       └── data
│           └── conf.yaml.example
│       ├── __about__.py
│       ├── __init__.py
│       └── system_cpu.py
│   └── __init__.py
├── tests
│   ├── __init__.py
│   ├── conftest.py
│   └── test_system_cpu.py
├── CHANGELOG.md
├── MANIFEST.in
├── README.md
├── manifest.json
├── metadata.csv
├── requirements-dev.txt
├── requirements.in
├── setup.py
└── tox.ini</code></pre>


<h3 id="_4">第三步：完善采集逻辑</h3>
<p>采集逻辑需要定义在 <code>system_cpu/datadog_checks/system_cpu/system_cpu.py</code>，要求：</p>
<ul>
<li>实现一个 <code>Check</code> 类</li>
<li>这个类必须继承自 <code>AgentCheck</code> 类</li>
<li>这个类必须实现一个方法，签名为 <code>check(self, instance)</code></li>
<li>代码必须同时兼容 Python 2 和 Python 3</li>
</ul>
<p>以下为脚手架生成的代码，我们需要完善 check 方法即可。</p>
<pre class="codehilite"><code class="language-python">from datadog_checks.base import AgentCheck


class SystemCpuCheck(AgentCheck):
    def check(self, instance):
        # 这里需要补充采集逻辑
        pass</code></pre>


<h4 id="_5">指标命名规范</h4>
<p><a href="https://docs.datadoghq.com/developers/metrics/#naming-custom-metrics">https://docs.datadoghq.com/developers/metrics/#naming-custom-metrics</a></p>
<h4 id="_6">如何上报一个指标</h4>
<p><a href="https://docs.datadoghq.com/developers/metrics/agent_metrics_submission/?tab=count">https://docs.datadoghq.com/developers/metrics/agent_metrics_submission/?tab=count</a></p>
<p>以下是示例的采集逻辑</p>
<pre class="codehilite"><code class="language-python"># coding=utf-8

import psutil
from datadog_checks.base import AgentCheck


class SystemCpuCheck(AgentCheck):
    def check(self, instance):
        # 如果实例配置中包含其他tags，上报数据的时候也需要带进去
        instance_tags = instance.get('tags', [])

        cpu_times = psutil.cpu_times(percpu=True)

        # 数据收集
        # gauge 为类型
        # 'system.cpu.count' 为指标名
        # len(cpu_times) 为指标值
        # instance_tags 为维度列表
        self.gauge('system.cpu.count', len(cpu_times), tags=instance_tags)

        for i, cpu in enumerate(cpu_times):
            tags = instance_tags + ['core:{0}'.format(i)]
            for key, value in cpu._asdict().items():
                self.rate('system.cpu.{0}'.format(key), 100.0 * value, tags=tags)</code></pre>


<p>由于使用到第三方库 <code>psutil</code>，因此需要在 <code>system_cpu/requirements.in</code> 添加以下依赖声明。</p>
<pre class="codehilite"><code class="language-bash">psutil==5.6.2</code></pre>


<h3 id="_7">第四步：编写测试</h3>
<p>为验证插件逻辑，需要编写单元测试。脚手架已生成测试脚本 <code>system_cpu/tests/test_system_cpu.py</code>，可以直接在上面开始编写单元测试。</p>
<p>以下为 <code>system_cpu</code> 的单元测试示例代码：</p>
<pre class="codehilite"><code class="language-python"># coding=utf-8

import mock
import psutil

from datadog_checks.system_cpu import SystemCpuCheck

# mock data
MOCK_PSUTIL_CPU_TIMES = [
    psutil._psosx.scputimes(user=7877.29, nice=0.0, system=7469.72, idle=38164.81),
    psutil._psosx.scputimes(user=3826.74, nice=0.0, system=2701.6, idle=46981.39),
    psutil._psosx.scputimes(user=7486.51, nice=0.0, system=5991.36, idle=40031.88),
    psutil._psosx.scputimes(user=3964.85, nice=0.0, system=2862.37, idle=46682.5),
]


def test_check(aggregator, instance):
    check = SystemCpuCheck('system_cpu', {}, {})

    # mock
    psutil_mock = mock.MagicMock(return_value=MOCK_PSUTIL_CPU_TIMES)
    with mock.patch('datadog_checks.system_cpu.system_cpu.psutil.cpu_times', psutil_mock):
        check.check(instance)

    # 断言数据上报数量及取值
    aggregator.assert_metric('system.cpu.count', value=4, count=1)

    for i in range(4):
        aggregator.assert_metric('system.cpu.user', count=1, tags=['core:{0}'.format(i)])</code></pre>


<p>单元测试编写完成后，执行以下命令启动测试程序。</p>
<pre class="codehilite"><code class="language-bash">ddev test system_cpu</code></pre>


<p>当控制台显示 <code>Passed!</code> 字样，说明单元测试通过。</p>
<blockquote>
<p>参考资料：<a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#writing-tests">https://docs.datadoghq.com/developers/integrations/new_check_howto/#writing-tests</a></p>
</blockquote>
<h3 id="_8">第五步：其他信息的完善</h3>
<p>至此，一个能用的插件就诞生了。但是如果要进一步符合社区规范，需要继续完善以下文件。</p>
<ul>
<li>
<p>采集逻辑用到的第三方库依赖： <code>requirements.in</code></p>
</li>
<li>
<p>插件说明文档 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#populate-the-readme">README.md</a></p>
</li>
<li>插件配置文件样例 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#configuration-file">conf.yaml.example</a></li>
<li>插件元信息 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#manifest-file">manifest.json</a></li>
<li>声明采集指标 <a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#metrics-metadata-file">metadata.csv</a></li>
</ul>
<blockquote>
<p>参考资料：<a href="https://docs.datadoghq.com/developers/integrations/new_check_howto/#configuration">https://docs.datadoghq.com/developers/integrations/new_check_howto/#configuration</a></p>
</blockquote>
<h3 id="_9">第六步：在监控平台中使用</h3>
<p>参考文档：</p>
<ul>
<li>
<p><a href="../guide/import_datadog_online.md">制作监控平台 DataDog 插件 (线上)</a></p>
</li>
<li>
<p><a href="../guide/import_datadog_offline.md">制作监控平台 DataDog 插件 (线下)</a></p>
</li>
</ul><h1 id="_1">插件和采集相关</h1>
<p>涉及到插件的制作和采集任务下发相关的功能。 </p>
<h3 id="exit-code-non-zero">采集失败 exit code non-zero</h3>
<p>采集下发查看更新详情发现类似如下报错：</p>
<pre class="codehilite"><code class="language-bash">[2020-03-18 20:32:07 ERROR] GSE restart process failed. task_id-&gt;[GSETASK:20200318203203:57196] task_result-&gt;[{&quot;failed&quot;: [{&quot;content&quot;: &quot;{\n   \&quot;value\&quot; : [\n      {\n         \&quot;funcID\&quot; : \&quot;\&quot;,\n         \&quot;instanceID\&quot; : \&quot;\&quot;,\n         \&quot;procName\&quot; : \&quot;bkmonitorbeat\&quot;,\n         \&quot;result\&quot; : \&quot;Script exit code non-zero. Error msessage: []\&quot;,\n         \&quot;setupPath\&quot; : \&quot;/usr/local/gse/plugins/bin\&quot;\n      }\n   ]\n}\n&quot;, &quot;bk_supplier_id&quot;: &quot;0&quot;, &quot;ip&quot;: &quot;10.21.64.14&quot;, &quot;error_code&quot;: 65535, &quot;error_msg&quot;: &quot;Script exit code non-zero. Error msessage: []&quot;, &quot;bk_cloud_id&quot;: &quot;415&quot;}], &quot;pending&quot;: [], &quot;success&quot;: []}]</code></pre>


<p>排除方法： </p>
<ul>
<li>本机是否有对应的进程 </li>
<li>如果存在进程，查看是否存在 bkmonitorbeat 进程和对应的配置</li>
</ul>
<h3 id="_2">无进程相关的数据</h3>
<ol>
<li>先确认 CMDB 是否配置了进程信息</li>
<li>再确认 processbeat 在节点管理中的版本和是否已经启用</li>
</ol>
<h3 id="_3">采集任务下发后在检查视图和仪表盘中出现了断点的数据</h3>
<ol>
<li>先检查是不是所有的数据都有断点</li>
<li>如果是所有指标数据都有断点，查看采集周期是否不为 1 分钟，如果是大于 1 分钟的在仪表盘中需要以 2 分钟为一个点进行画图</li>
<li>如果是部分指标数据有断点，那么就和采集没有关系，检查采集的程序逻辑</li>
</ol>
<h3 id="_4">无数据排查文档</h3>
<p>具体查看<a href="./nodata_faq.md">无数据排查文档</a></p><h1 id="faq">主机监控相关的 FAQ</h1>
<h3 id="cpu">CPU 指标如何计算的</h3>
<ul>
<li>蓝鲸监控： (user + system + nice + iowait + irq + softirq + steal + guest + guestnice + stolen total )/
(user + sys + nice + iowait + irq + softirq + steal + guest + guestnice + stolen total +idle)</li>
</ul>
<p>更多指标计算查看 <a href="../functions/addenda/host-metrics.md">主机-操作系统-指标</a>。</p>
<h3 id="_1">应用内存使用率指标如何计算的</h3>
<p>「应用内存使用率」：读取 /proc/meminfo 文件 (MemTotal-MemAvailable)/(MemTotal*100.0)，如果没有 MemAvailable 字段，则 MemAvailable=MemFree+Buffers+Cached</p>
<p>具体的解释查看 kernel 文档 <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea69ff85ec700722c9da773">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea69ff85ec700722c9da773</a>。</p>
<p>更多指标计算查看 <a href="../functions/addenda/host-metrics.md">主机-操作系统-指标</a>。</p><h1 id="_1">结语</h1>
<p>监控平台 能够监控服务器主机/容器资源的基础性能指标，同时也支持用户自定义指标数据的采集上报做监控；</p>
<p>借助监控系统，您可以全方位了解主机的资源使用情况和运行状态，并对应用程序的日志数据做监控以保障业务的可用性。</p>
<p>通过告警服务和自动处理功能，您可以及时作出响应，保证应用程序顺畅运行，业务无忧。</p>
    </body>
    </html>
    